<!-- doc/src/sgml/textsearch.sgml -->

<chapter id="textsearch">
<!--==========================orignal english content==========================
 <title>Full Text Search</title>
____________________________________________________________________________-->
 <title>全文搜索</title>

<!--==========================orignal english content==========================
  <indexterm zone="textsearch">
   <primary>full text search</primary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm zone="textsearch">
   <primary>全文搜索</primary>
  </indexterm>

<!--==========================orignal english content==========================
  <indexterm zone="textsearch">
   <primary>text search</primary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm zone="textsearch">
   <primary>文本搜索</primary>
  </indexterm>

 <sect1 id="textsearch-intro">
<!--==========================orignal english content==========================
  <title>Introduction</title>
____________________________________________________________________________-->
  <title>介绍</title>

<!--==========================orignal english content==========================
  <para>
   Full Text Searching (or just <firstterm>text search</firstterm>) provides
   the capability to identify natural-language <firstterm>documents</> that
   satisfy a <firstterm>query</firstterm>, and optionally to sort them by
   relevance to the query.  The most common type of search
   is to find all documents containing given <firstterm>query terms</firstterm>
   and return them in order of their <firstterm>similarity</firstterm> to the
   query.  Notions of <varname>query</varname> and
   <varname>similarity</varname> are very flexible and depend on the specific
   application. The simplest search considers <varname>query</varname> as a
   set of words and <varname>similarity</varname> as the frequency of query
   words in the document.
  </para>
____________________________________________________________________________-->
  <para>
   全文搜索（或者<firstterm>文本搜索</firstterm>）提供了确定满足一个<firstterm>查询</firstterm>的自然语言<firstterm>文档</>的能力，并可以选择将它们按照与查询的相关度排序。最常用的搜索类型是找到所有包含给定<firstterm>查询词</firstterm>的文档并按照它们与查询的<firstterm>相似性</firstterm>顺序返回它们。<varname>查询</varname>和<varname>相似性</varname>的概念非常灵活并且依赖于特定的应用。最简单的搜索认为<varname>查询</varname>是一组词而<varname>相似性</varname>是查询词在文档中的频度。
  </para>

<!--==========================orignal english content==========================
  <para>
   Textual search operators have existed in databases for years.
   <productname>PostgreSQL</productname> has
   <literal>~</literal>, <literal>~*</literal>, <literal>LIKE</literal>, and
   <literal>ILIKE</literal> operators for textual data types, but they lack
   many essential properties required by modern information systems:
  </para>
____________________________________________________________________________-->
  <para>
  文本搜索操作符已经在数据库中存在很多年了。<productname>PostgreSQL</productname>对文本数据类型提供了<literal>~</literal>、<literal>~*</literal>、<literal>LIKE</literal>和<literal>ILIKE</literal>操作符，但是它们缺少现代信息系统所要求的很多基本属性：
  </para>

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!--==========================orignal english content==========================
    <para>
     There is no linguistic support, even for English.  Regular expressions
     are not sufficient because they cannot easily handle derived words, e.g.,
     <literal>satisfies</literal> and <literal>satisfy</literal>. You might
     miss documents that contain <literal>satisfies</literal>, although you
     probably would like to find them when searching for
     <literal>satisfy</literal>. It is possible to use <literal>OR</literal>
     to search for multiple derived forms, but this is tedious and error-prone
     (some words can have several thousand derivatives).
    </para>
____________________________________________________________________________-->
    <para>
     即使对英语也缺乏语言的支持。正则表达式是不够的，因为它们不能很容易地处理派生词，例如<literal>satisfies</literal>和<literal>satisfy</literal>。你可能会错过包含<literal>satisfies</literal>的文档，尽管你可能想要在对于<literal>satisfy</literal>的搜索中找到它们。可以使用<literal>OR</literal>来搜索多个派生形式，但是这样做太罗嗦也容易出错（有些词可能有数千种派生）。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     They provide no ordering (ranking) of search results, which makes them
     ineffective when thousands of matching documents are found.
    </para>
____________________________________________________________________________-->
    <para>
     它们不提供对搜索结果的排序（排名），这使它们面对数以千计被找到的文档时变得无效。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     They tend to be slow because there is no index support, so they must
     process all documents for every search.
    </para>
____________________________________________________________________________-->
    <para>
     它们很慢因为没有索引支持，因此它们必须为每次搜索处理所有的文档。
    </para>
   </listitem>
  </itemizedlist>

<!--==========================orignal english content==========================
  <para>
   Full text indexing allows documents to be <emphasis>preprocessed</emphasis>
   and an index saved for later rapid searching. Preprocessing includes:
  </para>
____________________________________________________________________________-->
  <para>
   全文索引允许文档被<emphasis>预处理</emphasis>并且保存一个索引用于以后快速的搜索。预处理包括：
  </para>

  <itemizedlist  mark="none">
   <listitem>
<!--==========================orignal english content==========================
    <para>
     <emphasis>Parsing documents into <firstterm>tokens</></emphasis>. It is
     useful to identify various classes of tokens, e.g., numbers, words,
     complex words, email addresses, so that they can be processed
     differently.  In principle token classes depend on the specific
     application, but for most purposes it is adequate to use a predefined
     set of classes.
     <productname>PostgreSQL</productname> uses a <firstterm>parser</> to
     perform this step.  A standard parser is provided, and custom parsers
     can be created for specific needs.
    </para>
____________________________________________________________________________-->
    <para>
     <emphasis>将文档解析成<firstterm>记号</></emphasis>。标识出多种类型的记号是有所帮助的，例如数字、词、复杂的词、电子邮件地址，这样它们可以被以不同的方式处理。原则上记号分类取决于相关的应用，但是对于大部分目的都可以使用一套预定义的分类。<productname>PostgreSQL</productname>使用一个<firstterm>解析器</>来执行这个步骤。其中提供了一个标准的解析器，并且为特定的需要也可以创建定制的解析器。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     <emphasis>Converting tokens into <firstterm>lexemes</></emphasis>.
     A lexeme is a string, just like a token, but it has been
     <firstterm>normalized</> so that different forms of the same word
     are made alike.  For example, normalization almost always includes
     folding upper-case letters to lower-case, and often involves removal
     of suffixes (such as <literal>s</> or <literal>es</> in English).
     This allows searches to find variant forms of the
     same word, without tediously entering all the possible variants.
     Also, this step typically eliminates <firstterm>stop words</>, which
     are words that are so common that they are useless for searching.
     (In short, then, tokens are raw fragments of the document text, while
     lexemes are words that are believed useful for indexing and searching.)
     <productname>PostgreSQL</productname> uses <firstterm>dictionaries</> to
     perform this step.  Various standard dictionaries are provided, and
     custom ones can be created for specific needs.
    </para>
____________________________________________________________________________-->
    <para>
     <emphasis>将记号转换成<firstterm>词位</></emphasis>。和一个记号一样，一个词位是一个字符串，但是它已经被<firstterm>正规化</>，这样同一个词的不同形式被变成一样。例如，正规化几乎总是包括将大写字母转换成小写形式，并且经常涉及移除后缀（例如英语中的<literal>s</>或<literal>es</>）。这允许搜索找到同一个词的变体形式，而不需要冗长地输入所有可能的变体。此外，这个步骤通常会消除<firstterm>停用词</>，它们是那些太普通的词，它们对于搜索是无用的（简而言之，记号是文档文本的原始片段，而词位是那些被认为对索引和搜索有用的词）。<productname>PostgreSQL</productname>使用<firstterm>词典</>来执行这个步骤。已经提供了多种标准词典，并且为特定的需要也可以创建定制的词典。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     <emphasis>Storing preprocessed documents optimized for
     searching</emphasis>.  For example, each document can be represented
     as a sorted array of normalized lexemes. Along with the lexemes it is
     often desirable to store positional information to use for
     <firstterm>proximity ranking</firstterm>, so that a document that
     contains a more <quote>dense</> region of query words is
     assigned a higher rank than one with scattered query words.
    </para>
____________________________________________________________________________-->
    <para>
     <emphasis>为搜索优化存储预处理好的文档</emphasis>。例如，每一个文档可以被表示为正规化的词位的一个有序数组。与词位一起，通常还想要存储用于<firstterm>近似排名</firstterm>的位置信息，这样一个包含查询词更<quote>密集</>区域的文档要比那些包含分散的查询词的文档有更高的排名。
    </para>
   </listitem>
  </itemizedlist>

<!--==========================orignal english content==========================
  <para>
   Dictionaries allow fine-grained control over how tokens are normalized.
   With appropriate dictionaries, you can:
  </para>
____________________________________________________________________________-->
  <para>
   词典允许对记号如何被正规化进行细粒度的控制。使用合适的词典，你可以：
  </para>

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!--==========================orignal english content==========================
    <para>
     Define stop words that should not be indexed.
    </para>
____________________________________________________________________________-->
    <para>
     定义不应该被索引的停用词。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     Map synonyms to a single word using <application>Ispell</>.
    </para>
____________________________________________________________________________-->
    <para>
     使用<application>Ispell</>把同义词映射到一个单一词。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     Map phrases to a single word using a thesaurus.
    </para>
____________________________________________________________________________-->
    <para>
     使用一个分类词典把短语映射到一个单一词。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     Map different variations of a word to a canonical form using
     an <application>Ispell</> dictionary.
    </para>
____________________________________________________________________________-->
    <para>
     使用一个<application>Ispell</>词典把一个词的不同变体映射到一种规范的形式。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     Map different variations of a word to a canonical form using
     <application>Snowball</> stemmer rules.
    </para>
____________________________________________________________________________-->
    <para>
     使用<application>Snowball</>词干分析器规则将一个词的不同变体映射到一种规范的形式。
    </para>
   </listitem>
  </itemizedlist>

<!--==========================orignal english content==========================
  <para>
   A data type <type>tsvector</type> is provided for storing preprocessed
   documents, along with a type <type>tsquery</type> for representing processed
   queries (<xref linkend="datatype-textsearch">).  There are many
   functions and operators available for these data types
   (<xref linkend="functions-textsearch">), the most important of which is
   the match operator <literal>@@</literal>, which we introduce in
   <xref linkend="textsearch-matching">.  Full text searches can be accelerated
   using indexes (<xref linkend="textsearch-indexes">).
  </para>
____________________________________________________________________________-->
  <para>
   我们提供了一种数据类型<type>tsvector</type>来存储预处理后的文档，还提供了一种类型<type>tsquery</type>来表示处理过的查询（<xref linkend="datatype-textsearch">）。有很多函数和操作符可以用于这些数据类型（<xref linkend="functions-textsearch">），其中最重要的是匹配操作符<literal>@@</literal>，它在<xref linkend="textsearch-matching">中介绍。全文搜索可以使用索引来加速（<xref linkend="textsearch-indexes">）。
  </para>


  <sect2 id="textsearch-document">
<!--==========================orignal english content==========================
   <title>What Is a Document?</title>
____________________________________________________________________________-->
   <title>什么是一个文档？</title>

<!--==========================orignal english content==========================
   <indexterm zone="textsearch-document">
    <primary>document</primary>
    <secondary>text search</secondary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm zone="textsearch-document">
    <primary>文档</primary>
    <secondary>全文搜索</secondary>
   </indexterm>

<!--==========================orignal english content==========================
   <para>
    A <firstterm>document</> is the unit of searching in a full text search
    system; for example, a magazine article or email message.  The text search
    engine must be able to parse documents and store associations of lexemes
    (key words) with their parent document. Later, these associations are
    used to search for documents that contain query words.
   </para>
____________________________________________________________________________-->
   <para>
    一个<firstterm>document</>是在一个全文搜索系统中进行搜索的单元，例如，一篇杂志文章或电子邮件消息。文本搜索引擎必须能够解析文档并存储词位（关键词）与它们的父文档之间的关联。随后，这些关联会被用来搜索包含查询词的文档。
   </para>

<!--==========================orignal english content==========================
   <para>
    For searches within <productname>PostgreSQL</productname>,
    a document is normally a textual field within a row of a database table,
    or possibly a combination (concatenation) of such fields, perhaps stored
    in several tables or obtained dynamically. In other words, a document can
    be constructed from different parts for indexing and it might not be
    stored anywhere as a whole. For example:

<programlisting>
SELECT title || ' ' ||  author || ' ' ||  abstract || ' ' || body AS document
FROM messages
WHERE mid = 12;

SELECT m.title || ' ' || m.author || ' ' || m.abstract || ' ' || d.body AS document
FROM messages m, docs d
WHERE mid = did AND mid = 12;
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    对于<productname>PostgreSQL</productname>中的搜索，一个文档通常是一个数据库表中一行内的一个文本形式的域，或者可能是这类域的一个组合（连接），这些域可能存储在多个表或者是动态获取。换句话说，一个文档可能从用于索引的不同部分构建，并且它可能被作为一个整体存储在某个地方。例如：

<programlisting>
SELECT title || ' ' ||  author || ' ' ||  abstract || ' ' || body AS document
FROM messages
WHERE mid = 12;

SELECT m.title || ' ' || m.author || ' ' || m.abstract || ' ' || d.body AS document
FROM messages m, docs d
WHERE mid = did AND mid = 12;
</programlisting>
   </para>

   <note>
<!--==========================orignal english content==========================
    <para>
     Actually, in these example queries, <function>coalesce</function>
     should be used to prevent a single <literal>NULL</literal> attribute from
     causing a <literal>NULL</literal> result for the whole document.
    </para>
____________________________________________________________________________-->
    <para>
     实际上在这些例子查询中，<function>coalesce</function>应该被用来防止一个单一<literal>NULL</literal>属性导致整个文档的一个<literal>NULL</literal>结果。
    </para>
   </note>

<!--==========================orignal english content==========================
   <para>
    Another possibility is to store the documents as simple text files in the
    file system. In this case, the database can be used to store the full text
    index and to execute searches, and some unique identifier can be used to
    retrieve the document from the file system.  However, retrieving files
    from outside the database requires superuser permissions or special
    function support, so this is usually less convenient than keeping all
    the data inside <productname>PostgreSQL</productname>.  Also, keeping
    everything inside the database allows easy access
    to document metadata to assist in indexing and display.
   </para>
____________________________________________________________________________-->
   <para>
    另一种存储文档的可能性是作为文件系统中的简单文本文件。在这种情况下，数据库可以被用来存储全文索引并执行搜索，并且某些唯一标识符可以被用来从文件系统检索文档。但是，从数据库的外面检索文件要求超级用户权限或者特殊函数支持，因此这种方法通常不如把所有数据放在<productname>PostgreSQL</productname>内部方便。另外，把所有东西放在数据库内部允许方便地访问文档元数据来协助索引和现实。
   </para>

<!--==========================orignal english content==========================
   <para>
    For text search purposes, each document must be reduced to the
    preprocessed <type>tsvector</> format.  Searching and ranking
    are performed entirely on the <type>tsvector</> representation
    of a document &mdash; the original text need only be retrieved
    when the document has been selected for display to a user.
    We therefore often speak of the <type>tsvector</> as being the
    document, but of course it is only a compact representation of
    the full document.
   </para>
____________________________________________________________________________-->
   <para>
    对于文本搜索目的，每一个文档必须被缩减成预处理后的<type>tsvector</>格式。搜索和排名被整个在一个文档的<type>tsvector</>表示上执行 &mdash; 只有当文档被选择来显示给用户时才需要检索原始文本。我们因此经常把<type>tsvector</>说成是文档，但是当然它只是完整文档的一种紧凑表示。
   </para>
  </sect2>

  <sect2 id="textsearch-matching">
<!--==========================orignal english content==========================
   <title>Basic Text Matching</title>
____________________________________________________________________________-->
   <title>基本文本匹配</title>

<!--==========================orignal english content==========================
   <para>
    Full text searching in <productname>PostgreSQL</productname> is based on
    the match operator <literal>@@</literal>, which returns
    <literal>true</literal> if a <type>tsvector</type>
    (document) matches a <type>tsquery</type> (query).
    It doesn't matter which data type is written first:

<programlisting>
SELECT 'a fat cat sat on a mat and ate a fat rat'::tsvector @@ 'cat &amp; rat'::tsquery;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t

SELECT 'fat &amp; cow'::tsquery @@ 'a fat cat sat on a mat and ate a fat rat'::tsvector;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>中的全文搜索基于匹配操作符<literal>@@</literal>，它在一个<type>tsvector</type>（文档）匹配一个<type>tsquery</type>（查询）时返回<literal>true</literal>。哪种数据类型写在前面没有影响：

<programlisting>
SELECT 'a fat cat sat on a mat and ate a fat rat'::tsvector @@ 'cat &amp; rat'::tsquery;
 ?column?
----------
 t

SELECT 'fat &amp; cow'::tsquery @@ 'a fat cat sat on a mat and ate a fat rat'::tsvector;
 ?column?
----------
 f
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    As the above example suggests, a <type>tsquery</type> is not just raw
    text, any more than a <type>tsvector</type> is.  A <type>tsquery</type>
    contains search terms, which must be already-normalized lexemes, and
    may combine multiple terms using AND, OR, NOT, and FOLLOWED BY operators.
    (For syntax details see <xref linkend="datatype-tsquery">.)  There are
    functions <function>to_tsquery</>, <function>plainto_tsquery</>,
    and <function>phraseto_tsquery</>
    that are helpful in converting user-written text into a proper
    <type>tsquery</type>, primarily by normalizing words appearing in
    the text.  Similarly, <function>to_tsvector</> is used to parse and
    normalize a document string.  So in practice a text search match would
    look more like this:

<programlisting>
SELECT to_tsvector('fat cats ate fat rats') @@ to_tsquery('fat &amp; rat');
 ?column? 
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
</programlisting>

    Observe that this match would not succeed if written as

<programlisting>
SELECT 'fat cats ate fat rats'::tsvector @@ to_tsquery('fat &amp; rat');
 ?column? 
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>

    since here no normalization of the word <literal>rats</> will occur.
    The elements of a <type>tsvector</> are lexemes, which are assumed
    already normalized, so <literal>rats</> does not match <literal>rat</>.
   </para>
____________________________________________________________________________-->
   <para>
    正如以上例子所建议的，一个<type>tsquery</type>并不只是一个未经处理的文本，
	顶多一个<type>tsvector</type>是这样。一个<type>tsquery</type>包含搜索术语，
	它们必须是已经正规化的词位，并且可以使用 AND 、OR、NOT 以及 FOLLOWED BY 操作符结合多个术语
	（语法细节请见<xref linkend="datatype-tsquery">）。有几个函数<function>to_tsquery</>、<function>plainto_tsquery</>以及<function>phraseto_tsquery</>可用于将用户书写的文本转换为正确的<type>tsquery</type>，它们会主要采用正则化出现在文本中的词的方法。相似地，<function>to_tsvector</>被用来解析和正规化一个文档字符串。因此在实际上一个文本搜索匹配可能看起来更像：

<programlisting>
SELECT to_tsvector('fat cats ate fat rats') @@ to_tsquery('fat &amp; rat');
 ?column? 
----------
 t
</programlisting>

    注意如果这个匹配被写成下面这样它将不会成功：

<programlisting>
SELECT 'fat cats ate fat rats'::tsvector @@ to_tsquery('fat &amp; rat');
 ?column? 
----------
 f
</programlisting>

    因为这里不会发生词<literal>rats</>的正规化。一个<type>tsvector</>的元素是词位，它被假定为已经正规化好，因此<literal>rats</>不匹配<literal>rat</>。
   </para>

<!--==========================orignal english content==========================
   <para>
    The <literal>@@</literal> operator also
    supports <type>text</type> input, allowing explicit conversion of a text
    string to <type>tsvector</type> or <type>tsquery</> to be skipped
    in simple cases.  The variants available are:

<programlisting>
tsvector @@ tsquery
tsquery  @@ tsvector
text @@ tsquery
text @@ text
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <literal>@@</literal>操作符也支持<type>text</type>输出，它允许在简单情况下跳过从文本字符串到<type>tsvector</type>或<type>tsquery</>的显式转换。可用的变体是：

<programlisting>
tsvector @@ tsquery
tsquery  @@ tsvector
text @@ tsquery
text @@ text
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    The first two of these we saw already.
    The form <type>text</type> <literal>@@</literal> <type>tsquery</type>
    is equivalent to <literal>to_tsvector(x) @@ y</literal>.
    The form <type>text</type> <literal>@@</literal> <type>text</type>
    is equivalent to <literal>to_tsvector(x) @@ plainto_tsquery(y)</literal>.
   </para>
____________________________________________________________________________-->
   <para>
    前两种我们已经见过。形式<type>text</type> <literal>@@</literal> <type>tsquery</type>等价于<literal>to_tsvector(x) @@ y</literal>。形式<type>text</type> <literal>@@</literal> <type>text</type>等价于<literal>to_tsvector(x) @@ plainto_tsquery(y)</literal>。
   </para>
   
<!--==========================orignal english content==========================
   <para>
    Within a <type>tsquery</>, the <literal>&amp;</literal> (AND) operator
    specifies that both its arguments must appear in the document to have a
    match.  Similarly, the <literal>|</literal> (OR) operator specifies that
    at least one of its arguments must appear, while the <literal>!</> (NOT)
    operator specifies that its argument must <emphasis>not</> appear in
    order to have a match.
    For example, the query <literal>fat &amp; ! rat</> matches documents that
    contain <literal>fat</> but not <literal>rat</>.
   </para>
____________________________________________________________________________-->
   <para>
    在<type>tsquery</>中，<literal>&amp;</literal>（AND）操作符指定它的两个参数都必须出现在文档中才表示匹配。类似地，<literal>|</literal>（OR）操作符指定至少一个参数必须出现，而<literal>!</>（NOT）操作符指定它的参数<emphasis>不</>出现才能匹配。
	例如，查询<literal>fat &amp; ! rat</>匹配包含<literal>fat</>但是不包含
	<literal>rat</>的文档。
   </para>

<!--==========================orignal english content==========================
   <para>
    Searching for phrases is possible with the help of
    the <literal>&lt;-&gt;</> (FOLLOWED BY) <type>tsquery</> operator, which
    matches only if its arguments have matches that are adjacent and in the
    given order.  For example:

<programlisting>
SELECT to_tsvector('fatal error') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column? 
-&minus;-&minus;-&minus;-&minus;-&minus;
 t

SELECT to_tsvector('error is not fatal') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column? 
-&minus;-&minus;-&minus;-&minus;-&minus;
 f
</programlisting>

    There is a more general version of the FOLLOWED BY operator having the
    form <literal>&lt;<replaceable>N</>&gt;</literal>,
    where <replaceable>N</> is an integer standing for the difference between
    the positions of the matching lexemes.  <literal>&lt;1&gt;</literal> is
    the same as <literal>&lt;-&gt;</>, while <literal>&lt;2&gt;</literal>
    allows exactly one other lexeme to appear between the matches, and so
    on.  The <literal>phraseto_tsquery</> function makes use of this
    operator to construct a <literal>tsquery</> that can match a multi-word
    phrase when some of the words are stop words.  For example:

<programlisting>
SELECT phraseto_tsquery('cats ate rats');
       phraseto_tsquery        
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'cat' &lt;-&gt; 'ate' &lt;-&gt; 'rat'

SELECT phraseto_tsquery('the cats ate the rats');
       phraseto_tsquery        
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'cat' &lt;-&gt; 'ate' &lt;2&gt; 'rat'
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    在<literal>&lt;-&gt;</>（FOLLOWED BY） <type>tsquery</>操作符的帮助下搜索可能的短语，只有该操作符的参数的匹配是相邻的并且符合给定顺序时，该操作符才算是匹配。例如：

<programlisting>
SELECT to_tsvector('fatal error') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column? 
----------
 t

SELECT to_tsvector('error is not fatal') @@ to_tsquery('fatal &lt;-&gt; error');
 ?column? 
----------
 f
</programlisting>

    FOLLOWED BY 操作符还有一种更一般的版本，形式是<literal>&lt;<replaceable>N</>&gt;</literal>，其中<replaceable>N</>是一个表示匹配词位位置之间的差。<literal>&lt;1&gt;</literal>和<literal>&lt;-&gt;</>相同，而<literal>&lt;2&gt;</literal>允许刚好一个其他词位出现在匹配之间，以此类推。当有些词是停用词时，<literal>phraseto_tsquery</>函数利用这个操作符来构造一个能够匹配多词短语的<literal>tsquery</>。例如：

<programlisting>
SELECT phraseto_tsquery('cats ate rats');
       phraseto_tsquery        
-------------------------------
 'cat' &lt;-&gt; 'ate' &lt;-&gt; 'rat'

SELECT phraseto_tsquery('the cats ate the rats');
       phraseto_tsquery        
-------------------------------
 'cat' &lt;-&gt; 'ate' &lt;2&gt; 'rat'
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    A special case that's sometimes useful is that <literal>&lt;0&gt;</literal>
    can be used to require that two patterns match the same word.
   </para>
____________________________________________________________________________-->
   <para>
    一种有时候有用的特殊情况是，<literal>&lt;0&gt;</literal>可以被用来要求两个匹配同一个词的模式。
   </para>

<!--==========================orignal english content==========================
   <para>
    Parentheses can be used to control nesting of the <type>tsquery</>
    operators.  Without parentheses, <literal>|</literal> binds least tightly,
    then <literal>&amp;</literal>, then <literal>&lt;-&gt;</literal>,
    and <literal>!</literal> most tightly.
   </para>
____________________________________________________________________________-->
   <para>
    圆括号可以被用来控制<type>tsquery</>操作符的嵌套。如果没有圆括号，<literal>|</literal>的计算优先级最低，然后从低到高依次是<literal>&amp;</literal>、<literal>&lt;-&gt;</literal>、<literal>!</literal>。
   </para>

<!--==========================orignal english content==========================
   <para>
    It's worth noticing that the AND/OR/NOT operators mean something subtly
    different when they are within the arguments of a FOLLOWED BY operator
    than when they are not, because within FOLLOWED BY the exact position of
    the match is significant.  For example, normally <literal>!x</> matches
    only documents that do not contain <literal>x</> anywhere.
    But <literal>!x &lt;-&gt; y</> matches <literal>y</> if it is not
    immediately after an <literal>x</>; an occurrence of <literal>x</>
    elsewhere in the document does not prevent a match.  Another example is
    that <literal>x &amp; y</> normally only requires that <literal>x</>
    and <literal>y</> both appear somewhere in the document, but
    <literal>(x &amp; y) &lt;-&gt; z</> requires <literal>x</>
    and <literal>y</> to match at the same place, immediately before
    a <literal>z</>.  Thus this query behaves differently from
    <literal>x &lt;-&gt; z &amp; y &lt;-&gt; z</>, which will match a
    document containing two separate sequences <literal>x z</> and
    <literal>y z</>.  (This specific query is useless as written,
    since <literal>x</> and <literal>y</> could not match at the same place;
    but with more complex situations such as prefix-match patterns, a query
    of this form could be useful.)
   </para>
____________________________________________________________________________-->
   <para>
    值得注意的是，AND/OR/NOT运算符意味着当它们在FOLLOWED BY运算符的参数范围内，
	与它们没有在范围内的时候有细微的不同，因为在FOLLOWED BY中，匹配的确切位置是很重要的。
	例如，通常<literal>!x</>仅匹配不包含<literal>x</>的文档。但是，如果不是紧跟在<literal>x</>之后，
	那么<literal>!x &lt;-&gt; y</>匹配<literal>y</>；文档中其他地方出现的<literal>x</>并不妨碍匹配。
	另一个例子是<literal>x &amp; y</>通常只要求<literal>x</>和<literal>y</>都出现在文档的某处，
	但是<literal>(x &amp; y) &lt;-&gt; z</>要求<literal>x</>和<literal>y</>匹配在<literal>z</>
	之前的相同位置。因此，这个查询的行为不同于<literal>x &lt;-&gt; z &amp; y &lt;-&gt; z</>，
	它将与包含两个单独的序列<literal>x z</>和<literal>y z</>的文档相匹配。
	（由于<literal>x</>和<literal>y</>无法在相同位置匹配，因此此特定查询没有任何用处；
	但是在更复杂的情况下（如前缀匹配模式），此形式的查询可能会有用。）
   </para>
   </sect2>

  <sect2 id="textsearch-intro-configurations">
<!--==========================orignal english content==========================
   <title>Configurations</title>
____________________________________________________________________________-->
   <title>配置</title>

<!--==========================orignal english content==========================
   <para>
    The above are all simple text search examples.  As mentioned before, full
    text search functionality includes the ability to do many more things:
    skip indexing certain words (stop words), process synonyms, and use
    sophisticated parsing, e.g., parse based on more than just white space.
    This functionality is controlled by <firstterm>text search
    configurations</>.  <productname>PostgreSQL</> comes with predefined
    configurations for many languages, and you can easily create your own
    configurations.  (<application>psql</>'s <command>\dF</> command
    shows all available configurations.)
   </para>
____________________________________________________________________________-->
   <para>
    前述的都是简单的文本搜索例子。正如前面所提到的，全文搜索功能包括做更多事情的能力：跳过索引特定词（停用词）、处理同义词并使用更高级的解析，例如基于空白之外的解析。这个功能由<firstterm>文本搜索配置</>控制。<productname>PostgreSQL</>中有多种语言的预定义配置，并且你可以很容易地创建你自己的配置（<application>psql</>的<command>\dF</>命令显示所有可用的配置）。
   </para>

<!--==========================orignal english content==========================
   <para>
    During installation an appropriate configuration is selected and
    <xref linkend="guc-default-text-search-config"> is set accordingly
    in <filename>postgresql.conf</>.  If you are using the same text search
    configuration for the entire cluster you can use the value in
    <filename>postgresql.conf</>.  To use different configurations
    throughout the cluster but the same configuration within any one database,
    use <command>ALTER DATABASE ... SET</>.  Otherwise, you can set
    <varname>default_text_search_config</varname> in each session.
   </para>
____________________________________________________________________________-->
   <para>
    在安装期间一个合适的配置将被选择并且<xref linkend="guc-default-text-search-config">也被相应地设置在<filename>postgresql.conf</>中。如果你正在对整个集簇使用相同的文本搜索配置，你可以使用在<filename>postgresql.conf</>中使用该值。要在集簇中使用不同的配置但是在任何一个数据库内部使用同一种配置，使用<command>ALTER DATABASE ... SET</>。否则，你可以在每个会话中设置<varname>default_text_search_config</varname>。
   </para>

<!--==========================orignal english content==========================
   <para>
    Each text search function that depends on a configuration has an optional
    <type>regconfig</> argument, so that the configuration to use can be
    specified explicitly.  <varname>default_text_search_config</varname>
    is used only when this argument is omitted.
   </para>
____________________________________________________________________________-->
   <para>
    依赖一个配置的每一个文本搜索函数都有一个可选的<type>regconfig</>参数，因此要使用的配置可以被显式指定。只有当这个参数被忽略时，<varname>default_text_search_config</varname>才被使用。
   </para>

<!--==========================orignal english content==========================
   <para>
    To make it easier to build custom text search configurations, a
    configuration is built up from simpler database objects.
    <productname>PostgreSQL</>'s text search facility provides
    four types of configuration-related database objects:
   </para>
____________________________________________________________________________-->
   <para>
    为了让建立自定义文本搜索配置更容易，一个配置可以从更简单的数据库对象来建立。<productname>PostgreSQL</>的文本搜索功能提供了四类配置相关的数据库对象：
   </para>

  <itemizedlist  spacing="compact" mark="bullet">
   <listitem>
<!--==========================orignal english content==========================
    <para>
     <firstterm>Text search parsers</> break documents into tokens
     and classify each token (for example, as words or numbers).
    </para>
____________________________________________________________________________-->
    <para>
     <firstterm>文本搜索解析器</>将文档拆分成记号并分类每个记号（例如，作为词或者数字）。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     <firstterm>Text search dictionaries</> convert tokens to normalized
     form and reject stop words.
    </para>
____________________________________________________________________________-->
    <para>
     <firstterm>文本搜索词典</>将记号转变成正规化的形式并拒绝停用词。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     <firstterm>Text search templates</> provide the functions underlying
     dictionaries.  (A dictionary simply specifies a template and a set
     of parameters for the template.)
    </para>
____________________________________________________________________________-->
    <para>
     <firstterm>文本搜索模板</>提供位于词典底层的函数（一个词典简单地指定一个模板和一组用于模板的参数）。
    </para>
   </listitem>

   <listitem>
<!--==========================orignal english content==========================
    <para>
     <firstterm>Text search configurations</> select a parser and a set
     of dictionaries to use to normalize the tokens produced by the parser.
    </para>
____________________________________________________________________________-->
    <para>
     <firstterm>文本搜索配置</>选择一个解析器和一组用于将解析器产生的记号正规化的词典。
    </para>
   </listitem>
  </itemizedlist>

<!--==========================orignal english content==========================
   <para>
    Text search parsers and templates are built from low-level C functions;
    therefore it requires C programming ability to develop new ones, and
    superuser privileges to install one into a database.  (There are examples
    of add-on parsers and templates in the <filename>contrib/</> area of the
    <productname>PostgreSQL</> distribution.)  Since dictionaries and
    configurations just parameterize and connect together some underlying
    parsers and templates, no special privilege is needed to create a new
    dictionary or configuration.  Examples of creating custom dictionaries and
    configurations appear later in this chapter.
   </para>
____________________________________________________________________________-->
   <para>
    文本搜索解析器和模板是从低层 C 函数构建而来，因此它要求 C 编程能力来开发新的解析器和模板，并且还需要超级用户权限来把它们安装到一个数据库中（在<productname>PostgreSQL</>发布的<filename>contrib/</>区域中有一些附加的解析器和模板的例子）。由于词典和配置只是对底层解析器和模板的参数化和连接，不需要特殊的权限来创建一个新词典或配置。创建定制词典和配置的例子将在本章稍后的部分给出。
   </para>

  </sect2>

 </sect1>

 <sect1 id="textsearch-tables">
<!--==========================orignal english content==========================
  <title>Tables and Indexes</title>
____________________________________________________________________________-->
  <title>表和索引</title>

<!--==========================orignal english content==========================
  <para>
   The examples in the previous section illustrated full text matching using
   simple constant strings.  This section shows how to search table data,
   optionally using indexes.
  </para>
____________________________________________________________________________-->
  <para>
   在前一节中的例子演示了使用简单常数字符串进行全文匹配。本节展示如何搜索表数据，以及可选择地使用索引。
  </para>

  <sect2 id="textsearch-tables-search">
<!--==========================orignal english content==========================
   <title>Searching a Table</title>
____________________________________________________________________________-->
   <title>搜索一个表</title>

<!--==========================orignal english content==========================
   <para>
    It is possible to do a full text search without an index.  A simple query
    to print the <structname>title</> of each row that contains the word
    <literal>friend</> in its <structfield>body</> field is:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector('english', body) @@ to_tsquery('english', 'friend');
</programlisting>

    This will also find related words such as <literal>friends</>
    and <literal>friendly</>, since all these are reduced to the same
    normalized lexeme.
   </para>
____________________________________________________________________________-->
   <para>
    可以在没有一个索引的情况下做一次全文搜索。一个简单的查询将打印每一个行的<structname>title</>，这些行在其<structfield>body</>域中包含词<literal>friend</>：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector('english', body) @@ to_tsquery('english', 'friend');
</programlisting>

    这将还会找到相关的词例如<literal>friends</>和<literal>friendly</>，因为这些都被约减到同一个正规化的词位。
   </para>

<!--==========================orignal english content==========================
   <para>
    The query above specifies that the <literal>english</> configuration
    is to be used to parse and normalize the strings.  Alternatively we
    could omit the configuration parameters:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(body) @@ to_tsquery('friend');
</programlisting>

    This query will use the configuration set by <xref
    linkend="guc-default-text-search-config">.
   </para>
____________________________________________________________________________-->
   <para>
    以上的查询指定要使用<literal>english</>配置来解析和正规化字符串。我们也可以忽略配置参数：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(body) @@ to_tsquery('friend');
</programlisting>

    这个查询将使用由<xref linkend="guc-default-text-search-config">设置的配置。
   </para>

<!--==========================orignal english content==========================
   <para>
    A more complex example is to
    select the ten most recent documents that contain <literal>create</> and
    <literal>table</> in the <structname>title</> or <structname>body</>:

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(title || ' ' || body) @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>

    For clarity we omitted the <function>coalesce</function> function calls
    which would be needed to find rows that contain <literal>NULL</literal>
    in one of the two fields.
   </para>
____________________________________________________________________________-->
   <para>
    一个更复杂的例子是选择 10 个最近的文档，要求它们在<structname>title</>或<structname>body</>中包含<literal>create</>和<literal>table</>：

<programlisting>
SELECT title
FROM pgweb
WHERE to_tsvector(title || ' ' || body) @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>

    为了清晰，我们忽略<function>coalesce</function>函数调用，它可能需要被用来查找在这两个域之中包含<literal>NULL</literal>的行。
   </para>

<!--==========================orignal english content==========================
   <para>
    Although these queries will work without an index, most applications
    will find this approach too slow, except perhaps for occasional ad-hoc
    searches.  Practical use of text searching usually requires creating
    an index.
   </para>
____________________________________________________________________________-->
   <para>
    尽管这些查询可以在没有索引的情况下工作，大部分应用会发现这种方法太慢了，除了偶尔的临时搜索。实际使用文本搜索通常要求创建一个索引。
   </para>

  </sect2>

  <sect2 id="textsearch-tables-index">
<!--==========================orignal english content==========================
   <title>Creating Indexes</title>
____________________________________________________________________________-->
   <title>创建索引</title>

<!--==========================orignal english content==========================
   <para>
    We can create a <acronym>GIN</acronym> index (<xref
    linkend="textsearch-indexes">) to speed up text searches:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', body));
</programlisting>

    Notice that the 2-argument version of <function>to_tsvector</function> is
    used.  Only text search functions that specify a configuration name can
    be used in expression indexes (<xref linkend="indexes-expressional">).
    This is because the index contents must be unaffected by <xref
    linkend="guc-default-text-search-config">.  If they were affected, the
    index contents might be inconsistent because different entries could
    contain <type>tsvector</>s that were created with different text search
    configurations, and there would be no way to guess which was which.  It
    would be impossible to dump and restore such an index correctly.
   </para>
____________________________________________________________________________-->
   <para>
    我们可以创建一个<acronym>GIN</acronym>索引（<xref linkend="textsearch-indexes">）来加速文本搜索：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector('english', body));
</programlisting>

    注意这里使用了<function>to_tsvector</function>的双参数版本。只有指定了一个配置名称的文本搜索函数可以被用在表达式索引（<xref linkend="indexes-expressional">）中。这是因为索引内容必须是没有被<xref linkend="guc-default-text-search-config">影响的。如果它们被影响，索引内容可能会不一致因为不同的项可能包含被使用不同文本搜索配置创建的<type>tsvector</>，并且没有办法猜测哪个是哪个。也没有可能正确地转储和恢复这样的一个索引。
   </para>

<!--==========================orignal english content==========================
   <para>
    Because the two-argument version of <function>to_tsvector</function> was
    used in the index above, only a query reference that uses the 2-argument
    version of <function>to_tsvector</function> with the same configuration
    name will use that index.  That is, <literal>WHERE
    to_tsvector('english', body) @@ 'a &amp; b'</> can use the index,
    but <literal>WHERE to_tsvector(body) @@ 'a &amp; b'</> cannot.
    This ensures that an index will be used only with the same configuration
    used to create the index entries.
   </para>
____________________________________________________________________________-->
   <para>
    由于<function>to_tsvector</function>的双参数版本被使用在上述的索引中，只有一个使用了带有相同配置名的双参数版<function>to_tsvector</function>的查询引用才能使用该索引。即，<literal>WHERE to_tsvector('english', body) @@ 'a &amp; b'</> 可以使用该索引，但<literal>WHERE to_tsvector(body) @@ 'a &amp; b'</>不能。这保证一个索引只能和创建索引项时所用的相同配置一起使用。
   </para>

<!--==========================orignal english content==========================
  <para>
    It is possible to set up more complex expression indexes wherein the
    configuration name is specified by another column, e.g.:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector(config_name, body));
</programlisting>

    where <literal>config_name</> is a column in the <literal>pgweb</>
    table.  This allows mixed configurations in the same index while
    recording which configuration was used for each index entry.  This
    would be useful, for example, if the document collection contained
    documents in different languages.  Again,
    queries that are meant to use the index must be phrased to match, e.g.,
    <literal>WHERE to_tsvector(config_name, body) @@ 'a &amp; b'</>.
   </para>
____________________________________________________________________________-->
  <para>
    可以建立更复杂的表达式索引，在其中配置名被另一个列指定，例如：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector(config_name, body));
</programlisting>

    这里<literal>config_name</>是<literal>pgweb</>表中的一个列。这允许在同一个索引中有混合配置，同时记录哪个配置被用于每一个索引项。例如，如果文档集合包含不同语言的文档，这就可能会有用。同样，要使用索引的查询必须被措辞成匹配，例如<literal>WHERE to_tsvector(config_name, body) @@ 'a &amp; b'</>。
   </para>

<!--==========================orignal english content==========================
   <para>
    Indexes can even concatenate columns:

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN (to_tsvector('english', title || ' ' || body));
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    索引甚至可以连接列：

<programlisting>
CREATE INDEX pgweb_idx ON pgweb USING GIN(to_tsvector('english', title || ' ' || body));
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    Another approach is to create a separate <type>tsvector</> column
    to hold the output of <function>to_tsvector</>.  This example is a
    concatenation of <literal>title</literal> and <literal>body</literal>,
    using <function>coalesce</> to ensure that one field will still be
    indexed when the other is <literal>NULL</>:

<programlisting>
ALTER TABLE pgweb ADD COLUMN textsearchable_index_col tsvector;
UPDATE pgweb SET textsearchable_index_col =
     to_tsvector('english', coalesce(title,'') || ' ' || coalesce(body,''));
</programlisting>

    Then we create a <acronym>GIN</acronym> index to speed up the search:

<programlisting>
CREATE INDEX textsearch_idx ON pgweb USING GIN (textsearchable_index_col);
</programlisting>

    Now we are ready to perform a fast full text search:

<programlisting>
SELECT title
FROM pgweb
WHERE textsearchable_index_col @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    另一种方法是创建一个单独的<type>tsvector</>列来保存<function>to_tsvector</>的输出。这个例子是<literal>title</literal>和<literal>body</literal>的连接，使用<function>coalesce</>来保证当其他域为<literal>NULL</>时一个域仍然能留在索引中：

<programlisting>
ALTER TABLE pgweb ADD COLUMN textsearchable_index_col tsvector;
UPDATE pgweb SET textsearchable_index_col =
     to_tsvector('english', coalesce(title,'') || ' ' || coalesce(body,''));
</programlisting>

    然后我们创建一个<acronym>GIN</acronym>索引来加速搜索：

<programlisting>
CREATE INDEX textsearch_idx ON pgweb USING GIN(textsearchable_index_col);
</programlisting>

    现在我们准备好执行一个快速的全文搜索了：

<programlisting>
SELECT title
FROM pgweb
WHERE textsearchable_index_col @@ to_tsquery('create &amp; table')
ORDER BY last_mod_date DESC
LIMIT 10;
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    When using a separate column to store the <type>tsvector</>
    representation,
    it is necessary to create a trigger to keep the <type>tsvector</>
    column current anytime <literal>title</> or <literal>body</> changes.
    <xref linkend="textsearch-update-triggers"> explains how to do that.
   </para>
____________________________________________________________________________-->
   <para>
    在使用一个单独的列来存储<type>tsvector</>表示时，有必要创建一个触发器在<literal>title</>或<literal>body</>改变时保证<type>tsvector</>列为当前值。<xref linkend="textsearch-update-triggers">解释了怎样去做。
   </para>

<!--==========================orignal english content==========================
   <para>
    One advantage of the separate-column approach over an expression index
    is that it is not necessary to explicitly specify the text search
    configuration in queries in order to make use of the index.  As shown
    in the example above, the query can depend on
    <varname>default_text_search_config</>.  Another advantage is that
    searches will be faster, since it will not be necessary to redo the
    <function>to_tsvector</> calls to verify index matches.  (This is more
    important when using a GiST index than a GIN index; see <xref
    linkend="textsearch-indexes">.)  The expression-index approach is
    simpler to set up, however, and it requires less disk space since the
    <type>tsvector</> representation is not stored explicitly.
   </para>
____________________________________________________________________________-->
   <para>
    单独列方法相对于表达式索引的一个优势在于，它不必为了利用索引而在查询中显式地指定文本搜索配置。如上述例子所示，查询可以依赖<varname>default_text_search_config</>。另一个优势是搜索将会更快，因为它不必重做<function>to_tsvector</>调用来验证索引匹配（在使用 GiST 索引时这一点比使用 GIN 索引时更重要；见<xref linkend="textsearch-indexes">）。表达式索引方法更容易建立，但是它要求更少的磁盘空间，因为<type>tsvector</>表示没有被显式地存储下来。
   </para>

  </sect2>

 </sect1>

 <sect1 id="textsearch-controls">
<!--==========================orignal english content==========================
  <title>Controlling Text Search</title>
____________________________________________________________________________-->
  <title>空值文本搜索</title>

<!--==========================orignal english content==========================
  <para>
   To implement full text searching there must be a function to create a
   <type>tsvector</type> from a document and a <type>tsquery</type> from a
   user query. Also, we need to return results in a useful order, so we need
   a function that compares documents with respect to their relevance to
   the query. It's also important to be able to display the results nicely.
   <productname>PostgreSQL</productname> provides support for all of these
   functions.
  </para>
____________________________________________________________________________-->
  <para>
   要实现全文搜索必须要有一个从文档创建<type>tsvector</type>以及从用户查询创建<type>tsquery</type>的函数。而且我们需要一种有用的顺序返回结果，因此我们需要一个函数能够根据文档与查询的相关性比较文档。还有一点重要的是要能够很好地显示结果。<productname>PostgreSQL</productname>对所有这些函数都提供了支持。
  </para>

  <sect2 id="textsearch-parsing-documents">
<!--==========================orignal english content==========================
   <title>Parsing Documents</title>
____________________________________________________________________________-->
   <title>解析文档</title>

<!--==========================orignal english content==========================
   <para>
    <productname>PostgreSQL</productname> provides the
    function <function>to_tsvector</function> for converting a document to
    the <type>tsvector</type> data type.
   </para>
____________________________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>提供了函数<function>to_tsvector</function>将一个文档转换成<type>tsvector</type>数据类型。
   </para>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>to_tsvector</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>to_tsvector</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
to_tsvector(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>) returns <type>tsvector</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
to_tsvector(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>) returns <type>tsvector</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>to_tsvector</function> parses a textual document into tokens,
    reduces the tokens to lexemes, and returns a <type>tsvector</type> which
    lists the lexemes together with their positions in the document.
    The document is processed according to the specified or default
    text search configuration.
    Here is a simple example:

<screen>
SELECT to_tsvector('english', 'a fat  cat sat on a mat - it ate a fat rats');
                  to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'ate':9 'cat':3 'fat':2,11 'mat':7 'rat':12 'sat':4
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    <function>to_tsvector</function>把一个文本文档解析成记号，把记号缩减成词位，并且返回一个<type>tsvector</type>，它列出了词位以及词位在文档中的位置。文档被根据指定的或默认的文本搜索配置来处理。下面是一个简单例子：

<screen>
SELECT to_tsvector('english', 'a fat  cat sat on a mat - it ate a fat rats');
                  to_tsvector
-----------------------------------------------------
 'ate':9 'cat':3 'fat':2,11 'mat':7 'rat':12 'sat':4
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    In the example above we see that the resulting <type>tsvector</type> does not
    contain the words <literal>a</literal>, <literal>on</literal>, or
    <literal>it</literal>, the word <literal>rats</literal> became
    <literal>rat</literal>, and the punctuation sign <literal>-</literal> was
    ignored.
   </para>
____________________________________________________________________________-->
   <para>
    在上面这个例子中我们看到，作为结果的<type>tsvector</type>不包含词<literal>a</literal>、<literal>on</literal>或<literal>it</literal>，词<literal>rats</literal>变成了<literal>rat</literal>，并且标点符号<literal>-</literal>被忽略了。
   </para>

<!--==========================orignal english content==========================
   <para>
    The <function>to_tsvector</function> function internally calls a parser
    which breaks the document text into tokens and assigns a type to
    each token.  For each token, a list of
    dictionaries (<xref linkend="textsearch-dictionaries">) is consulted,
    where the list can vary depending on the token type.  The first dictionary
    that <firstterm>recognizes</> the token emits one or more normalized
    <firstterm>lexemes</firstterm> to represent the token.  For example,
    <literal>rats</literal> became <literal>rat</literal> because one of the
    dictionaries recognized that the word <literal>rats</literal> is a plural
    form of <literal>rat</literal>.  Some words are recognized as
    <firstterm>stop words</> (<xref linkend="textsearch-stopwords">), which
    causes them to be ignored since they occur too frequently to be useful in
    searching.  In our example these are
    <literal>a</literal>, <literal>on</literal>, and <literal>it</literal>.
    If no dictionary in the list recognizes the token then it is also ignored.
    In this example that happened to the punctuation sign <literal>-</literal>
    because there are in fact no dictionaries assigned for its token type
    (<literal>Space symbols</literal>), meaning space tokens will never be
    indexed. The choices of parser, dictionaries and which types of tokens to
    index are determined by the selected text search configuration (<xref
    linkend="textsearch-configuration">).  It is possible to have
    many different configurations in the same database, and predefined
    configurations are available for various languages. In our example
    we used the default configuration <literal>english</literal> for the
    English language.
   </para>
____________________________________________________________________________-->
   <para>
    <function>to_tsvector</function>函数在内部调用了一个解析器，它把文档文本分解成记号并且为每一种记号分配一个类型。对于每一个记号，会去查询一个词典列表（<xref linkend="textsearch-dictionaries">），该列表会根据记号的类型而变化。第一个<firstterm>识别</>记号的词典产生一个或多个正规化的<firstterm>词位</firstterm>来表示该记号。例如，<literal>rats</literal>变成<literal>rat</literal>是因为一个词典识别到该词<literal>rats</literal>是<literal>rat</literal>的复数形式。一些词会被识别为<firstterm>停用词</>（<xref linkend="textsearch-stopwords">），这将导致它们被忽略，因为它们出现得太频繁以至于在搜索中起不到作用。在我们的例子中有<literal>a</literal>、<literal>on</literal>和<literal>it</literal>是停用词。如果在列表中没有词典能识别该记号，那它将也会被忽略。在这个例子中标点符号<literal>-</literal>就属于这种情况，因为事实上没有词典会给它分配记号类型（<literal>空间符号</literal>），即空间记号不会被索引。对于解析器、词典以及要索引哪些记号类型是由所选择的文本搜索配置（<xref linkend="textsearch-configuration">）决定的。可以在同一个数据库中有多种不同的配置，并且有用于很多种语言的预定义配置。在我们的例子中，我们使用用于英语的默认配置<literal>english</literal>。
   </para>

<!--==========================orignal english content==========================
   <para>
    The function <function>setweight</function> can be used to label the
    entries of a <type>tsvector</type> with a given <firstterm>weight</>,
    where a weight is one of the letters <literal>A</>, <literal>B</>,
    <literal>C</>, or <literal>D</>.
    This is typically used to mark entries coming from
    different parts of a document, such as title versus body.  Later, this
    information can be used for ranking of search results.
   </para>
____________________________________________________________________________-->
   <para>
    函数<function>setweight</function>可以被用来对<type>tsvector</type>中的项标注一个给定的<firstterm>权重</>，这里一个权重可以是四个字母之一：<literal>A</>、<literal>B</>、<literal>C</>或<literal>D</>。这通常被用来标记来自文档不同部分的项，例如标题对正文。稍后，这种信息可以被用来排名搜索结果。
   </para>

<!--==========================orignal english content==========================
   <para>
    Because <function>to_tsvector</function>(<literal>NULL</literal>) will
    return <literal>NULL</literal>, it is recommended to use
    <function>coalesce</function> whenever a field might be null.
    Here is the recommended method for creating
    a <type>tsvector</type> from a structured document:

<programlisting>
UPDATE tt SET ti =
    setweight(to_tsvector(coalesce(title,'')), 'A')    ||
    setweight(to_tsvector(coalesce(keyword,'')), 'B')  ||
    setweight(to_tsvector(coalesce(abstract,'')), 'C') ||
    setweight(to_tsvector(coalesce(body,'')), 'D');
</programlisting>

    Here we have used <function>setweight</function> to label the source
    of each lexeme in the finished <type>tsvector</type>, and then merged
    the labeled <type>tsvector</type> values using the <type>tsvector</>
    concatenation operator <literal>||</>.  (<xref
    linkend="textsearch-manipulate-tsvector"> gives details about these
    operations.)
   </para>
____________________________________________________________________________-->
   <para>
    因为<function>to_tsvector</function>(<literal>NULL</literal>) 将返回<literal>NULL</literal>，不论何时一个域可能为空时，我们推荐使用<function>coalesce</function>。下面是我们推荐的从一个结构化文档创建一个<type>tsvector</type>的方法：

<programlisting>
UPDATE tt SET ti =
    setweight(to_tsvector(coalesce(title,'')), 'A')    ||
    setweight(to_tsvector(coalesce(keyword,'')), 'B')  ||
    setweight(to_tsvector(coalesce(abstract,'')), 'C') ||
    setweight(to_tsvector(coalesce(body,'')), 'D');
</programlisting>

    这里我们已经使用了<function>setweight</function>在完成的<type>tsvector</type>标注每一个词位的来源，并且接着将标注过的<type>tsvector</type>值用<type>tsvector</type>连接操作符<literal>||</>合并在一起（<xref linkend="textsearch-manipulate-tsvector">给出了关于这些操作符的细节）。
   </para>

  </sect2>

  <sect2 id="textsearch-parsing-queries">
<!--==========================orignal english content==========================
   <title>Parsing Queries</title>
____________________________________________________________________________-->
   <title>解析查询</title>

<!--==========================orignal english content==========================
   <para>
    <productname>PostgreSQL</productname> provides the
    functions <function>to_tsquery</function>,
    <function>plainto_tsquery</function>, and
    <function>phraseto_tsquery</function>
    for converting a query to the <type>tsquery</type> data type.
    <function>to_tsquery</function> offers access to more features
    than either <function>plainto_tsquery</function> or
    <function>phraseto_tsquery</function>, but it is less forgiving
    about its input.
   </para>
____________________________________________________________________________-->
   <para>
    <productname>PostgreSQL</productname>提供了函数<function>to_tsquery</function>、<function>plainto_tsquery</function>和<function>phraseto_tsquery</function>用来把一个查询转换成<type>tsquery</type>数据类型。<function>to_tsquery</function>提供了比<function>plainto_tsquery</function>和<function>phraseto_tsquery</function>更多的特性，但是它对其输入要求更加严格。
   </para>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>to_tsquery</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>to_tsquery</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
to_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
to_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>to_tsquery</function> creates a <type>tsquery</> value from
    <replaceable>querytext</replaceable>, which must consist of single tokens
    separated by the <type>tsquery</> operators <literal>&amp;</literal> (AND),
    <literal>|</literal> (OR), <literal>!</literal> (NOT), and
    <literal>&lt;-&gt;</literal> (FOLLOWED BY), possibly grouped
    using parentheses.  In other words, the input to
    <function>to_tsquery</function> must already follow the general rules for
    <type>tsquery</> input, as described in <xref
    linkend="datatype-tsquery">.  The difference is that while basic
    <type>tsquery</> input takes the tokens at face value,
    <function>to_tsquery</function> normalizes each token into a lexeme using
    the specified or default configuration, and discards any tokens that are
    stop words according to the configuration.  For example:

<screen>
SELECT to_tsquery('english', 'The &amp; Fat &amp; Rats');
  to_tsquery   
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat'
</screen>

    As in basic <type>tsquery</> input, weight(s) can be attached to each
    lexeme to restrict it to match only <type>tsvector</> lexemes of those
    weight(s).  For example:

<screen>
SELECT to_tsquery('english', 'Fat | Rats:AB');
    to_tsquery    
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' | 'rat':AB
</screen>

    Also, <literal>*</> can be attached to a lexeme to specify prefix matching:

<screen>
SELECT to_tsquery('supern:*A &amp; star:A*B');
        to_tsquery        
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'supern':*A &amp; 'star':*AB
</screen>

    Such a lexeme will match any word in a <type>tsvector</> that begins
    with the given string.
   </para>
____________________________________________________________________________-->
   <para>
    <function>to_tsquery</function>从<replaceable>querytext</replaceable>创建一个<type>tsquery</>值，该值由被<type>tsquery</>操作符<literal>&amp;</literal>（AND）、<literal>|</literal>（OR）、<literal>!</literal>（NOT）和<literal>&lt;-&gt;</literal>（FOLLOWED BY）分隔的单个记号组成。 这些操作符可以使用圆括号分组。换句话说，<function>to_tsquery</function>的输入必须已经遵循<type>tsquery</>输入的一般规则，如<xref linkend="datatype-tsquery">所述。区别在于基本的<type>tsquery</>输入把记号当作表面值，而<function>to_tsquery</function> 会使用指定的或者默认的配置把每一个记号正规化成一个词位，并且丢弃掉任何根据配置是停用词的记号。例如：

<screen>
SELECT to_tsquery('english', 'The &amp; Fat &amp; Rats');
  to_tsquery   
---------------
 'fat' &amp; 'rat'
</screen>

    和在基本<type>tsquery</>输入中一样，权重可以被附加到每一个词位来限制它只匹配属于那些权重的<type>tsvector</>词位。例如：

<screen>
SELECT to_tsquery('english', 'Fat | Rats:AB');
    to_tsquery    
------------------
 'fat' | 'rat':AB
</screen>

    同样，<literal>*</>可以被附加到一个词位来指定前缀匹配：

<screen>
SELECT to_tsquery('supern:*A &amp; star:A*B');
        to_tsquery        
--------------------------
 'supern':*A &amp; 'star':*AB
</screen>

    这样一个词位将匹配一个<type>tsvector</>中的任意以给定字符串开头的词。
   </para>

<!--==========================orignal english content==========================
   <para>
    <function>to_tsquery</function> can also accept single-quoted
    phrases.  This is primarily useful when the configuration includes a
    thesaurus dictionary that may trigger on such phrases.
    In the example below, a thesaurus contains the rule <literal>supernovae
    stars : sn</literal>:

<screen>
SELECT to_tsquery('''supernovae stars'' &amp; !crab');
  to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn' &amp; !'crab'
</screen>

    Without quotes, <function>to_tsquery</function> will generate a syntax
    error for tokens that are not separated by an AND, OR, or FOLLOWED BY
    operator.
   </para>
____________________________________________________________________________-->
   <para>
    <function>to_tsquery</function>也能够接受单引号短语。当配置包括一个会在这种短语上触发的分类词典时就是它的主要用处。在下面的例子中，一个分类词典含规则<literal>supernovae stars : sn</literal>：

<screen>
SELECT to_tsquery('''supernovae stars'' &amp; !crab');
  to_tsquery
---------------
 'sn' &amp; !'crab'
</screen>

    在没有引号时，<function>to_tsquery</function>将为那些没有被 AND、OR 或者 FOLLOWED BY 操作符分隔的记号产生一个语法错误。
   </para>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>plainto_tsquery</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>plainto_tsquery</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
plainto_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
plainto_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>plainto_tsquery</> transforms the unformatted text
    <replaceable>querytext</replaceable> to a <type>tsquery</type> value.
    The text is parsed and normalized much as for <function>to_tsvector</>,
    then the <literal>&amp;</literal> (AND) <type>tsquery</type> operator is
    inserted between surviving words.
   </para>
____________________________________________________________________________-->
   <para>
    <function>plainto_tsquery</>将未格式化的文本<replaceable>querytext</replaceable>转换成一个<type>tsquery</type>值。该文本被解析并被正规化，很像<function>to_tsvector</>，然后<literal>&amp;</literal>（AND）布尔操作符被插入到留下来的词之间。
   </para>

<!--==========================orignal english content==========================
   <para>
    Example:

<screen>
SELECT plainto_tsquery('english', 'The Fat Rats');
 plainto_tsquery 
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat'
</screen>

    Note that <function>plainto_tsquery</> will not
    recognize <type>tsquery</type> operators, weight labels,
    or prefix-match labels in its input:

<screen>
SELECT plainto_tsquery('english', 'The Fat &amp; Rats:C');
   plainto_tsquery   
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &amp; 'rat' &amp; 'c'
</screen>

    Here, all the input punctuation was discarded as being space symbols.
   </para>
____________________________________________________________________________-->
   <para>
    例子：

<screen>
SELECT plainto_tsquery('english', 'The Fat Rats');
 plainto_tsquery 
-----------------
 'fat' &amp; 'rat'
</screen>

    注意<function>plainto_tsquery</>不会识其输入中的<type>tsquery</type>操作符、权重标签或前缀匹配标签：

<screen>
SELECT plainto_tsquery('english', 'The Fat &amp; Rats:C');
   plainto_tsquery   
---------------------
 'fat' &amp; 'rat' &amp; 'c'
</screen>

    这里，所有输入的标点都被作为空间符号并且丢弃。
   </para>
   
<!--==========================orignal english content==========================
   <indexterm>
    <primary>phraseto_tsquery</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>phraseto_tsquery</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
phraseto_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
phraseto_tsquery(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">querytext</replaceable> <type>text</>) returns <type>tsquery</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>phraseto_tsquery</> behaves much like
    <function>plainto_tsquery</>, except that it inserts
    the <literal>&lt;-&gt;</literal> (FOLLOWED BY) operator between
    surviving words instead of the <literal>&amp;</literal> (AND) operator.
    Also, stop words are not simply discarded, but are accounted for by
    inserting <literal>&lt;<replaceable>N</>&gt;</literal> operators rather
    than <literal>&lt;-&gt;</literal> operators.  This function is useful
    when searching for exact lexeme sequences, since the FOLLOWED BY
    operators check lexeme order not just the presence of all the lexemes.
   </para>
____________________________________________________________________________-->
   <para>
    <function>phraseto_tsquery</>的行为很像<function>plainto_tsquery</>，不过前者会在留下来的词之间插入<literal>&lt;-&gt;</literal>（FOLLOWED BY）操作符而不是<literal>&amp;</literal>（AND）操作符。还有，停用词也不是简单地丢弃掉，而是通过插入<literal>&lt;<replaceable>N</>&gt;</literal>操作符（而不是<literal>&lt;-&gt;</literal>操作符）来解释。在搜索准确的词位序列时这个函数很有用，因为 FOLLOWED BY 操作符不只是检查所有词位的存在性，还会检查词位的顺序。
   </para>

<!--==========================orignal english content==========================
   <para>
    Example:

<screen>
SELECT phraseto_tsquery('english', 'The Fat Rats');
 phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &lt;-&gt; 'rat'
</screen>

    Like <function>plainto_tsquery</>, the
    <function>phraseto_tsquery</> function will not
    recognize <type>tsquery</type> operators, weight labels,
    or prefix-match labels in its input:

<screen>
SELECT phraseto_tsquery('english', 'The Fat &amp; Rats:C');
      phraseto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &lt;-&gt; 'rat' &lt;-&gt; 'c'
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    例子：

<screen>
SELECT phraseto_tsquery('english', 'The Fat Rats');
 phraseto_tsquery
------------------
 'fat' &lt;-&gt; 'rat'
</screen>

    和<function>plainto_tsquery</>相似，<function>phraseto_tsquery</>函数不会识别其输入中的<type>tsquery</type>操作符、权重标签或者前缀匹配标签：

<screen>
SELECT phraseto_tsquery('english', 'The Fat &amp; Rats:C');
      phraseto_tsquery
-----------------------------
 'fat' &lt;-&gt; 'rat' &lt;-&gt; 'c'
</screen>
   </para>

  </sect2>

  <sect2 id="textsearch-ranking">
<!--==========================orignal english content==========================
   <title>Ranking Search Results</title>
____________________________________________________________________________-->
   <title>排名搜索结果</title>

<!--==========================orignal english content==========================
   <para>
    Ranking attempts to measure how relevant documents are to a particular
    query, so that when there are many matches the most relevant ones can be
    shown first.  <productname>PostgreSQL</productname> provides two
    predefined ranking functions, which take into account lexical, proximity,
    and structural information; that is, they consider how often the query
    terms appear in the document, how close together the terms are in the
    document, and how important is the part of the document where they occur.
    However, the concept of relevancy is vague and very application-specific.
    Different applications might require additional information for ranking,
    e.g., document modification time.  The built-in ranking functions are only
    examples.  You can write your own ranking functions and/or combine their
    results with additional factors to fit your specific needs.
   </para>
____________________________________________________________________________-->
   <para>
    排名处理尝试度量文档和一个特定查询的接近程度，这样当有很多匹配时最相关的那些可以被先显示。<productname>PostgreSQL</productname>提供了两种预定义的排名函数，它们考虑词法、临近性和结构信息；即，它们考虑查询词在文档中出现得有多频繁，文档中的词有多接近，以及词出现的文档部分有多重要。不过，相关性的概念是模糊的并且与应用非常相关。不同的应用可能要求额外的信息用于排名，例如，文档修改时间。内建的排名函数只是例子。你可以编写你自己的排名函数和/或把它们的结果与附加因素整合在一起来适应你的特定需求。
   </para>

<!--==========================orignal english content==========================
   <para>
    The two ranking functions currently available are:

    <variablelist>

     <varlistentry>

      <term>
       <indexterm>
        <primary>ts_rank</primary>
       </indexterm>

       <literal>ts_rank(<optional> <replaceable class="PARAMETER">weights</replaceable> <type>float4[]</>, </optional> <replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">normalization</replaceable> <type>integer</> </optional>) returns <type>float4</></literal>
      </term>

      <listitem>
       <para>
        Ranks vectors based on the frequency of their matching lexemes.
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>

      <term>
      <indexterm>
       <primary>ts_rank_cd</primary>
      </indexterm>

       <literal>ts_rank_cd(<optional> <replaceable class="PARAMETER">weights</replaceable> <type>float4[]</>, </optional> <replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">normalization</replaceable> <type>integer</> </optional>) returns <type>float4</></literal>
      </term>

      <listitem>
       <para>
        This function computes the <firstterm>cover density</firstterm>
        ranking for the given document vector and query, as described in
        Clarke, Cormack, and Tudhope's "Relevance Ranking for One to Three
        Term Queries" in the journal "Information Processing and Management",
        1999.  Cover density is similar to <function>ts_rank</> ranking
        except that the proximity of matching lexemes to each other is
        taken into consideration.
       </para>

       <para>
        This function requires lexeme positional information to perform
        its calculation.  Therefore, it ignores any <quote>stripped</>
        lexemes in the <type>tsvector</>.  If there are no unstripped
        lexemes in the input, the result will be zero.  (See <xref
        linkend="textsearch-manipulate-tsvector"> for more information
        about the <function>strip</> function and positional information
        in <type>tsvector</>s.)
       </para>
      </listitem>
     </varlistentry>

    </variablelist>

   </para>
____________________________________________________________________________-->
   <para>
    目前可用的两种排名函数是：

    <variablelist>

     <varlistentry>
     <term>
      <indexterm>
       <primary>ts_rank</primary>
      </indexterm>

       <literal>ts_rank(<optional> <replaceable class="PARAMETER">weights</replaceable> <type>float4[]</>, </optional> <replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">normalization</replaceable> <type>integer</> </optional>) returns <type>float4</></literal>
      </term>

      <listitem>
       <para>
        基于向量的匹配词位的频率来排名向量。
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>

      <term>
      <indexterm>
       <primary>ts_rank_cd</primary>
      </indexterm>

       <literal>ts_rank_cd(<optional> <replaceable class="PARAMETER">weights</replaceable> <type>float4[]</>, </optional> <replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">normalization</replaceable> <type>integer</> </optional>) returns <type>float4</></literal>
      </term>

      <listitem>
       <para>
        这个函数为给定文档向量和查询计算<firstterm>覆盖密度</firstterm>排名，该方法在 Clarke、Cormack 和 Tudhope 于 1999 年在期刊 "Information Processing and Management" 上的文章  "Relevance Ranking for One to Three Term Queries" 文章中有描述。覆盖密度类似于<function>ts_rank</>排名，不过它会考虑匹配词位相互之间的接近度。
       </para>

       <para>
        这个函数要求词位的位置信息来执行其计算。因此它会忽略<type>tsvector</>中任何<quote>被剥离的</>词位。如果在输入中有未被剥离的词位，结果将会是零（<function>strip</>函数和<type>tsvector</>中的位置信息的更多内容请见<xref linkend="textsearch-manipulate-tsvector">）。
       </para>
      </listitem>
     </varlistentry>

    </variablelist>

   </para>

<!--==========================orignal english content==========================
   <para>
    For both these functions,
    the optional <replaceable class="PARAMETER">weights</replaceable>
    argument offers the ability to weigh word instances more or less
    heavily depending on how they are labeled.  The weight arrays specify
    how heavily to weigh each category of word, in the order:

<synopsis>
{D-weight, C-weight, B-weight, A-weight}
</synopsis>

    If no <replaceable class="PARAMETER">weights</replaceable> are provided,
    then these defaults are used:

<programlisting>
{0.1, 0.2, 0.4, 1.0}
</programlisting>

    Typically weights are used to mark words from special areas of the
    document, like the title or an initial abstract, so they can be
    treated with more or less importance than words in the document body.
   </para>
____________________________________________________________________________-->
   <para>
    对这两个函数，可选的<replaceable class="PARAMETER">权重</replaceable>参数提供了为词实例赋予更多或更少权重的能力，这种能力是依据它们被标注的情况的。权重数组指定每一类词应该得到多重的权重，按照如下的顺序：

<synopsis>
{D-权重, C-权重, B-权重, A-权重}
</synopsis>

    如果没有提供<replaceable class="PARAMETER">权重</replaceable>，那么将使用这些默认值：

<programlisting>
{0.1, 0.2, 0.4, 1.0}
</programlisting>

    通常权重被用来标记来自文档特别区域的词，如标题或一个初始的摘要，这样它们可以被认为比来自文档正文的词更重要或更不重要。
   </para>

<!--==========================orignal english content==========================
   <para>
    Since a longer document has a greater chance of containing a query term
    it is reasonable to take into account document size, e.g., a hundred-word
    document with five instances of a search word is probably more relevant
    than a thousand-word document with five instances.  Both ranking functions
    take an integer <replaceable>normalization</replaceable> option that
    specifies whether and how a document's length should impact its rank.
    The integer option controls several behaviors, so it is a bit mask:
    you can specify one or more behaviors using
    <literal>|</literal> (for example, <literal>2|4</literal>).

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       0 (the default) ignores the document length
      </para>
     </listitem>
     <listitem>
      <para>
       1 divides the rank by 1 + the logarithm of the document length
      </para>
     </listitem>
     <listitem>
      <para>
       2 divides the rank by the document length
      </para>
     </listitem>
     <listitem>
      <para>
       4 divides the rank by the mean harmonic distance between extents
       (this is implemented only by <function>ts_rank_cd</>)
      </para>
     </listitem>
     <listitem>
      <para>
       8 divides the rank by the number of unique words in document
      </para>
     </listitem>
     <listitem>
      <para>
       16 divides the rank by 1 + the logarithm of the number
       of unique words in document
      </para>
     </listitem>
     <listitem>
      <para>
       32 divides the rank by itself + 1
      </para>
     </listitem>
    </itemizedlist>

    If more than one flag bit is specified, the transformations are
    applied in the order listed.
   </para>
____________________________________________________________________________-->
   <para>
    由于一个较长的文档有更多的机会包含一个查询术语，因此考虑文档的尺寸是合理的，例如一个一百个词的文档中有一个搜索词的五个实例而零一个一千个词的文档中有该搜索词的五个实例，则前者比后者更相关。两种排名函数都采用一个整数<replaceable>正规化</replaceable>选项，它指定文档长度是否影响其排名以及如何影响。该整数选项控制多个行为，因此它是一个位掩码：你可以使用<literal>|</literal>指定一个或多个行为（例如，<literal>2|4</literal>）。

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       0（默认值）忽略文档长度
      </para>
     </listitem>
     <listitem>
      <para>
       1 用 1 + 文档长度的对数除排名
      </para>
     </listitem>
     <listitem>
      <para>
       2 用文档长度除排名
      </para>
     </listitem>
     <listitem>
      <para>
       4 用长度之间的平均调和距离除排名（只被<function>ts_rank_cd</>实现）
      </para>
     </listitem>
     <listitem>
      <para>
       8 用文档中唯一词的数量除排名
      </para>
     </listitem>
     <listitem>
      <para>
       16 用 1 + 文档中唯一词数量的对数除排名
      </para>
     </listitem>
     <listitem>
      <para>
       32 用排名 + 1 除排名
      </para>
     </listitem>
    </itemizedlist>

    如果多于一个标志位被指定，转换将根据列出的顺序被应用。
   </para>

<!--==========================orignal english content==========================
   <para>
    It is important to note that the ranking functions do not use any global
    information, so it is impossible to produce a fair normalization to 1% or
    100% as sometimes desired.  Normalization option 32
    (<literal>rank/(rank+1)</literal>) can be applied to scale all ranks
    into the range zero to one, but of course this is just a cosmetic change;
    it will not affect the ordering of the search results.
   </para>
____________________________________________________________________________-->
   <para>
    值得注意的是排名函数并不使用任何全局信息，因此它不可能按照某些时候期望地产生一个公平的正规化，从 1% 或 100%。正规化选项 32 （<literal>rank/(rank+1)</literal>）可以被应用来缩放所有的排名到范围零到一，但是当然这只是一个外观上的改变；它不会影响搜索结果的顺序。
   </para>

<!--==========================orignal english content==========================
   <para>
    Here is an example that selects only the ten highest-ranked matches:

<screen>
SELECT title, ts_rank_cd(textsearch, query) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |   rank
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;
 Neutrinos in the Sun                          |      3.1
 The Sudbury Neutrino Detector                 |      2.4
 A MACHO View of Galactic Dark Matter          |  2.01317
 Hot Gas and Dark Matter                       |  1.91171
 The Virgo Cluster: Hot Plasma and Dark Matter |  1.90953
 Rafting for Solar Neutrinos                   |      1.9
 NGC 4650A: Strange Galaxy and Dark Matter     |  1.85774
 Hot Gas and Dark Matter                       |   1.6123
 Ice Fishing for Cosmic Neutrinos              |      1.6
 Weak Lensing Distorts the Universe            | 0.818218
</screen>

    This is the same example using normalized ranking:

<screen>
SELECT title, ts_rank_cd(textsearch, query, 32 /* rank/(rank+1) */ ) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE  query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |        rank
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Neutrinos in the Sun                          | 0.756097569485493
 The Sudbury Neutrino Detector                 | 0.705882361190954
 A MACHO View of Galactic Dark Matter          | 0.668123210574724
 Hot Gas and Dark Matter                       |  0.65655958650282
 The Virgo Cluster: Hot Plasma and Dark Matter | 0.656301290640973
 Rafting for Solar Neutrinos                   | 0.655172410958162
 NGC 4650A: Strange Galaxy and Dark Matter     | 0.650072921219637
 Hot Gas and Dark Matter                       | 0.617195790024749
 Ice Fishing for Cosmic Neutrinos              | 0.615384618911517
 Weak Lensing Distorts the Universe            | 0.450010798361481
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    这里是一个例子，它只选择十个最高排名的匹配：

<screen>
SELECT title, ts_rank_cd(textsearch, query) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |   rank
-----------------------------------------------+----------
 Neutrinos in the Sun                          |      3.1
 The Sudbury Neutrino Detector                 |      2.4
 A MACHO View of Galactic Dark Matter          |  2.01317
 Hot Gas and Dark Matter                       |  1.91171
 The Virgo Cluster: Hot Plasma and Dark Matter |  1.90953
 Rafting for Solar Neutrinos                   |      1.9
 NGC 4650A: Strange Galaxy and Dark Matter     |  1.85774
 Hot Gas and Dark Matter                       |   1.6123
 Ice Fishing for Cosmic Neutrinos              |      1.6
 Weak Lensing Distorts the Universe            | 0.818218
</screen>

    这是相同的例子使用正规化的排名：

<screen>
SELECT title, ts_rank_cd(textsearch, query, 32 /* rank/(rank+1) */ ) AS rank
FROM apod, to_tsquery('neutrino|(dark &amp; matter)') query
WHERE  query @@ textsearch
ORDER BY rank DESC
LIMIT 10;
                     title                     |        rank
-----------------------------------------------+-------------------
 Neutrinos in the Sun                          | 0.756097569485493
 The Sudbury Neutrino Detector                 | 0.705882361190954
 A MACHO View of Galactic Dark Matter          | 0.668123210574724
 Hot Gas and Dark Matter                       |  0.65655958650282
 The Virgo Cluster: Hot Plasma and Dark Matter | 0.656301290640973
 Rafting for Solar Neutrinos                   | 0.655172410958162
 NGC 4650A: Strange Galaxy and Dark Matter     | 0.650072921219637
 Hot Gas and Dark Matter                       | 0.617195790024749
 Ice Fishing for Cosmic Neutrinos              | 0.615384618911517
 Weak Lensing Distorts the Universe            | 0.450010798361481
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    Ranking can be expensive since it requires consulting the
    <type>tsvector</type> of each matching document, which can be I/O bound and
    therefore slow. Unfortunately, it is almost impossible to avoid since
    practical queries often result in large numbers of matches.
   </para>
____________________________________________________________________________-->
   <para>
    排名可能会非常昂贵，因为它要求查询每一个匹配文档的<type>tsvector</type>，这可能会涉及很多I/O因而很慢。不幸的是，这几乎不可能避免，因为实际查询常常导致巨大数目的匹配。
   </para>

  </sect2>

  <sect2 id="textsearch-headline">
<!--==========================orignal english content==========================
   <title>Highlighting Results</title>
____________________________________________________________________________-->
   <title>加亮结果</title>

<!--==========================orignal english content==========================
   <para>
    To present search results it is ideal to show a part of each document and
    how it is related to the query. Usually, search engines show fragments of
    the document with marked search terms.  <productname>PostgreSQL</>
    provides a function <function>ts_headline</function> that
    implements this functionality.
   </para>
____________________________________________________________________________-->
   <para>
    要表示搜索结果，理想的方式是显示每一个文档的一个部分并且显示它是怎样与查询相关的。通常，搜索引擎显示文档片段时会对其中的搜索术语进行标记。<productname>PostgreSQL</>提供了一个函数<function>ts_headline</function>来实现这个功能。
   </para>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>ts_headline</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>ts_headline</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
ts_headline(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">options</replaceable> <type>text</> </optional>) returns <type>text</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_headline(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>, <replaceable class="PARAMETER">query</replaceable> <type>tsquery</> <optional>, <replaceable class="PARAMETER">options</replaceable> <type>text</> </optional>) returns <type>text</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>ts_headline</function> accepts a document along
    with a query, and returns an excerpt from
    the document in which terms from the query are highlighted.  The
    configuration to be used to parse the document can be specified by
    <replaceable>config</replaceable>; if <replaceable>config</replaceable>
    is omitted, the
    <varname>default_text_search_config</varname> configuration is used.
   </para>
____________________________________________________________________________-->
   <para>
    <function>ts_headline</function>接受一个文档和一个查询，并且从该文档返回一个引用，在其中来自查询的术语会被加亮。被用来解析该文档的配置可以用<replaceable>config</replaceable>指定；如果<replaceable>config</replaceable>被忽略，将会使用<varname>default_text_search_config</varname>配置。
   </para>

<!--==========================orignal english content==========================
   <para>
    If an <replaceable>options</replaceable> string is specified it must
    consist of a comma-separated list of one or more
    <replaceable>option</><literal>=</><replaceable>value</> pairs.
    The available options are:

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>StartSel</>, <literal>StopSel</literal>: the strings with
       which to delimit query words appearing in the document, to distinguish
       them from other excerpted words.  You must double-quote these strings
       if they contain spaces or commas.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxWords</>, <literal>MinWords</literal>: these numbers
       determine the longest and shortest headlines to output.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>ShortWord</literal>: words of this length or less will be
       dropped at the start and end of a headline. The default
       value of three eliminates common English articles.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>HighlightAll</literal>: Boolean flag;  if
       <literal>true</literal> the whole document will be used as the
       headline, ignoring the preceding three parameters.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxFragments</literal>: maximum number of text excerpts
       or fragments to display.  The default value of zero selects a
       non-fragment-oriented headline generation method.  A value greater than
       zero selects fragment-based headline generation.  This method
       finds text fragments with as many query words as possible and
       stretches those fragments around the query words.  As a result
       query words are close to the middle of each fragment and have words on
       each side. Each fragment will be of at most <literal>MaxWords</> and
       words of length <literal>ShortWord</> or less are dropped at the start
       and end of each fragment. If not all query words are found in the
       document, then a single fragment of the first <literal>MinWords</>
       in the document will be displayed.
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>FragmentDelimiter</literal>: When more than one fragment is
       displayed, the fragments will be separated by this string.
      </para>
     </listitem>
    </itemizedlist>

    Any unspecified options receive these defaults:

<programlisting>
StartSel=&lt;b&gt;, StopSel=&lt;/b&gt;,
MaxWords=35, MinWords=15, ShortWord=3, HighlightAll=FALSE,
MaxFragments=0, FragmentDelimiter=" ... "
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    如果一个<replaceable>options</replaceable>字符串被指定，它必须由一个逗号分隔的列表组成，列表中是一个或多个<replaceable>option</><literal>=</><replaceable>value</>对。可用的选项是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>StartSel</>、<literal>StopSel</literal>：用来定界文档中出现的查询词的字符串，这用来把它们与其他被引用的词区分开。如果这些字符串包含空格或逗号，你必须把它们加上双引号。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxWords</>、<literal>MinWords</literal>：这些数字决定要输出的最长和最短 headline。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>ShortWord</literal>：长度小于等于这个值的词将被从一个 headline 的开头或结尾处丢掉。默认值三消除普通英语文章。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>HighlightAll</literal>：布尔标志，如果为<literal>true</literal>整个文档将被用作 headline，并忽略前面的三个参数。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>MaxFragments</literal>：要显示的文本引用或片段的最大数量。默认值零选择一种非片段倾向的 headline 生成方法。一个大于零的值选择基于片段的 headline 生成。这种方法找到有尽可能多查询词的文本片段并且展开查询词周围的那些片段。结果是查询词会靠近每个片段的中间并且在其两侧都有词。每一个片段将是最多<literal>MaxWords</>并且长度小于等于<literal>ShortWord</>的词被从每个片段的开头或结尾丢弃。如果不是所有的查询词都在该文档中找到，文档中第一个<literal>MinWords</>的单一片段将被显示。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>FragmentDelimiter</literal>：当多于一个片段被显示时，片段将被这个字符串所分隔。
      </para>
     </listitem>
    </itemizedlist>

    任何未指定的选项将收到这些默认值：

<programlisting>
StartSel=&lt;b&gt;, StopSel=&lt;/b&gt;,
MaxWords=35, MinWords=15, ShortWord=3, HighlightAll=FALSE,
MaxFragments=0, FragmentDelimiter=" ... "
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    For example:

<screen>
SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('query &amp; similarity'));
                        ts_headline                         
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 containing given &lt;b&gt;query&lt;/b&gt; terms
 and return them in order of their &lt;b&gt;similarity&lt;/b&gt; to the
 &lt;b&gt;query&lt;/b&gt;.

SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('query &amp; similarity'),
  'StartSel = &lt;, StopSel = &gt;');
                      ts_headline                      
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 containing given &lt;query&gt; terms
 and return them in order of their &lt;similarity&gt; to the
 &lt;query&gt;.
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    例如：

<screen>
SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('query &amp; similarity'));
                        ts_headline                         
------------------------------------------------------------
 containing given &lt;b&gt;query&lt;/b&gt; terms
 and return them in order of their &lt;b&gt;similarity&lt;/b&gt; to the
 &lt;b&gt;query&lt;/b&gt;.

SELECT ts_headline('english',
  'The most common type of search
is to find all documents containing given query terms
and return them in order of their similarity to the
query.',
  to_tsquery('query &amp; similarity'),
  'StartSel = &lt;, StopSel = &gt;');
                      ts_headline                      
-------------------------------------------------------
 containing given &lt;query&gt; terms
 and return them in order of their &lt;similarity&gt; to the
 &lt;query&gt;.
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    <function>ts_headline</> uses the original document, not a
    <type>tsvector</type> summary, so it can be slow and should be used with
    care.
   </para>
____________________________________________________________________________-->
   <para>
    <function>ts_headline</>使用原始文档，而不是一个<type>tsvector</type>摘要，因此它可能很慢并且应该被小心使用。
   </para>

  </sect2>

 </sect1>

 <sect1 id="textsearch-features">
<!--==========================orignal english content==========================
  <title>Additional Features</title>
____________________________________________________________________________-->
  <title>额外特性</title>

<!--==========================orignal english content==========================
  <para>
   This section describes additional functions and operators that are
   useful in connection with text search.
  </para>
____________________________________________________________________________-->
  <para>
   这一节描述在文本搜索中有用的一些额外的函数和操作符。
  </para>

  <sect2 id="textsearch-manipulate-tsvector">
<!--==========================orignal english content==========================
   <title>Manipulating Documents</title>
____________________________________________________________________________-->
   <title>操纵文档</title>

<!--==========================orignal english content==========================
   <para>
    <xref linkend="textsearch-parsing-documents"> showed how raw textual
    documents can be converted into <type>tsvector</> values.
    <productname>PostgreSQL</productname> also provides functions and
    operators that can be used to manipulate documents that are already
    in <type>tsvector</> form.
   </para>
____________________________________________________________________________-->
   <para>
    <xref linkend="textsearch-parsing-documents">展示了未经处理的文本文档如何被转换成<type>tsvector</>值。<productname>PostgreSQL</productname>也提供了用于操纵已经为<type>tsvector</>形式的文档的函数和操作符。
   </para>

   <variablelist>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>tsvector concatenation</primary>
     </indexterm>

      <literal><type>tsvector</> || <type>tsvector</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>tsvector 连接</primary>
     </indexterm>

      <literal><type>tsvector</> || <type>tsvector</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       The <type>tsvector</> concatenation operator
       returns a vector which combines the lexemes and positional information
       of the two vectors given as arguments.  Positions and weight labels
       are retained during the concatenation.
       Positions appearing in the right-hand vector are offset by the largest
       position mentioned in the left-hand vector, so that the result is
       nearly equivalent to the result of performing <function>to_tsvector</>
       on the concatenation of the two original document strings.  (The
       equivalence is not exact, because any stop-words removed from the
       end of the left-hand argument will not affect the result, whereas
       they would have affected the positions of the lexemes in the
       right-hand argument if textual concatenation were used.)
      </para>
____________________________________________________________________________-->
      <para>
       <type>tsvector</>连接操作符返回一个向量，它结合了作为参数给出的两个向量的词位和位置信息。位置和权重标签在连接期间被保留。出现在右手向量中的位置被使用左手向量中提到的最大位置进行偏移，这样结果几乎等于在两个原始文档字符串的连接上执行<function>to_tsvector</>的结果（这种等价不是完全的，因为从左手参数的尾端移除的任何停用词将会影响结果，而如果文本连接被使用它们就影响了右手参数中的词位位置）。
      </para>

<!--==========================orignal english content==========================
      <para>
       One advantage of using concatenation in the vector form, rather than
       concatenating text before applying <function>to_tsvector</>, is that
       you can use different configurations to parse different sections
       of the document.  Also, because the <function>setweight</> function
       marks all lexemes of the given vector the same way, it is necessary
       to parse the text and do <function>setweight</> before concatenating
       if you want to label different parts of the document with different
       weights.
      </para>
____________________________________________________________________________-->
      <para>
       使用向量形式的连接而不是在应用<function>to_tsvector</>之前连接文本的一个优点是你可以使用不同配置来解析文档的不同小节。此外，因为<function>setweight</>函数按照相同的方式标记给定向量的所有词位，如果你想把文档的不同部分标注不同的权重，你就有必要解析文本并且在连接之前做<function>setweight</>。
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>setweight</primary>
     </indexterm>

      <literal>setweight(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">weight</replaceable> <type>"char"</>) returns <type>tsvector</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>setweight</primary>
     </indexterm>

      <literal>setweight(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>, <replaceable class="PARAMETER">weight</replaceable> <type>"char"</>) returns <type>tsvector</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       <function>setweight</> returns a copy of the input vector in which every
       position has been labeled with the given <replaceable>weight</>, either
       <literal>A</literal>, <literal>B</literal>, <literal>C</literal>, or
       <literal>D</literal>.  (<literal>D</literal> is the default for new
       vectors and as such is not displayed on output.)  These labels are
       retained when vectors are concatenated, allowing words from different
       parts of a document to be weighted differently by ranking functions.
      </para>
____________________________________________________________________________-->
      <para>
       <function>setweight</>返回输入向量的一个拷贝，其中每一个位置都被标注为给定的<replaceable>权重</>：<literal>A</literal>、<literal>B</literal>、<literal>C</literal>或<literal>D</literal>（<literal>D</literal>是新向量的默认值并且并不会被显示在输出上）。向量被连接时会保留这些标签，允许来自文档的不同部分的词被排名函数给予不同的权重。
      </para>

<!--==========================orignal english content==========================
      <para>
       Note that weight labels apply to <emphasis>positions</>, not
       <emphasis>lexemes</>.  If the input vector has been stripped of
       positions then <function>setweight</> does nothing.
      </para>
____________________________________________________________________________-->
      <para>
       注意权重标签是应用到<emphasis>位置</>而不是<emphasis>词位</>。如果输入向量已经被剥离了位置，则<function>setweight</>什么也不会做。
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>
<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>length(tsvector)</primary>
     </indexterm>

      <literal>length(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>) returns <type>integer</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>length(tsvector)</primary>
     </indexterm>

      <literal>length(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>) returns <type>integer</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the number of lexemes stored in the vector.
      </para>
____________________________________________________________________________-->
      <para>
       返回存储在向量中的词位数。
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>strip</primary>
     </indexterm>

      <literal>strip(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>) returns <type>tsvector</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>strip</primary>
     </indexterm>

      <literal>strip(<replaceable class="PARAMETER">vector</replaceable> <type>tsvector</>) returns <type>tsvector</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns a vector that lists the same lexemes as the given vector, but
       lacks any position or weight information.  The result is usually much
       smaller than an unstripped vector, but it is also less useful.
       Relevance ranking does not work as well on stripped vectors as
       unstripped ones.  Also,
       the <literal>&lt;-&gt;</> (FOLLOWED BY) <type>tsquery</> operator
       will never match stripped input, since it cannot determine the
       distance between lexeme occurrences.
      </para>
____________________________________________________________________________-->
      <para>
       返回一个向量，其中列出了和给定向量相同的词位，不过没有任何位置或者权重信息。其结果通常比未被剥离的向量小很多，但是用处也小很多。和未被剥离的向量一样，相关度排名在已剥离的向量上也不起作用。此外，<literal>&lt;-&gt;</>（FOLLOWED BY）<type>tsquery</>操作符不会匹配已剥离的输入，因为它无法确定词位之间的距离。
      </para>
     </listitem>

    </varlistentry>

   </variablelist>
   
<!--==========================orignal english content==========================
   <para>
    A full list of <type>tsvector</>-related functions is available
    in <xref linkend="textsearch-functions-table">.
   </para>
____________________________________________________________________________-->
   <para>
    <xref linkend="textsearch-functions-table">中有<type>tsvector</>相关函数的完整列表。
   </para>

  </sect2>

  <sect2 id="textsearch-manipulate-tsquery">
<!--==========================orignal english content==========================
   <title>Manipulating Queries</title>
____________________________________________________________________________-->
   <title>操纵查询</title>

<!--==========================orignal english content==========================
   <para>
    <xref linkend="textsearch-parsing-queries"> showed how raw textual
    queries can be converted into <type>tsquery</> values.
    <productname>PostgreSQL</productname> also provides functions and
    operators that can be used to manipulate queries that are already
    in <type>tsquery</> form.
   </para>
____________________________________________________________________________-->
   <para>
    <xref linkend="textsearch-parsing-queries">展示了未经处理的文本形式的查询如何被转换成<type>tsquery</>值。<productname>PostgreSQL</productname>也提供了用于操纵已经是<type>tsquery</>形式的查询的函数和操作符。
   </para>

   <variablelist>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
      <literal><type>tsquery</> &amp;&amp; <type>tsquery</></literal>
     </term>
____________________________________________________________________________-->
     <term>
      <literal><type>tsquery</> &amp;&amp; <type>tsquery</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the AND-combination of the two given queries.
      </para>
____________________________________________________________________________-->
      <para>
       返回用 AND 结合的两个给定查询。
      </para>
     </listitem>

    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
      <literal><type>tsquery</> || <type>tsquery</></literal>
     </term>
____________________________________________________________________________-->
     <term>
      <literal><type>tsquery</> || <type>tsquery</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the OR-combination of the two given queries.
      </para>
____________________________________________________________________________-->
      <para>
       返回用 OR 结合的两个给定查询。
      </para>
     </listitem>

    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
      <literal>!! <type>tsquery</></literal>
     </term>
____________________________________________________________________________-->
     <term>
      <literal>!! <type>tsquery</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the negation (NOT) of the given query.
      </para>
____________________________________________________________________________-->
      <para>
       返回一个给定查询的反（NOT）。
      </para>
     </listitem>

    </varlistentry>
    
    <varlistentry>

<!--==========================orignal english content==========================
     <term>
      <literal><type>tsquery</> &lt;-&gt; <type>tsquery</></literal>
     </term>
____________________________________________________________________________-->
     <term>
      <literal><type>tsquery</> &lt;-&gt; <type>tsquery</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns a query that searches for a match to the first given query
       immediately followed by a match to the second given query, using
       the <literal>&lt;-&gt;</> (FOLLOWED BY)
       <type>tsquery</> operator.  For example:

<screen>
SELECT to_tsquery('fat') &lt;-&gt; to_tsquery('cat | rat');
             ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'fat' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
</screen>
      </para>
____________________________________________________________________________-->
      <para>
       返回一个查询，它用<literal>&lt;-&gt;</>（FOLLOWED BY）<type>tsquery</>操作符搜索两个紧跟的匹配，第一个匹配符合第一个给定的查询而第二个匹配符合第二个给定的查询。例如：

<screen>
SELECT to_tsquery('fat') &lt;-&gt; to_tsquery('cat | rat');
             ?column?
-----------------------------------
 'fat' &lt;-&gt; 'cat' | 'fat' &lt;-&gt; 'rat'
</screen>
      </para>
     </listitem>

    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>tsquery_phrase</primary>
     </indexterm>

      <literal>tsquery_phrase(<replaceable class="PARAMETER">query1</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">query2</replaceable> <type>tsquery</> [, <replaceable class="PARAMETER">distance</replaceable> <type>integer</> ]) returns <type>tsquery</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>tsquery_phrase</primary>
     </indexterm>

      <literal>tsquery_phrase(<replaceable class="PARAMETER">query1</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">query2</replaceable> <type>tsquery</> [, <replaceable class="PARAMETER">distance</replaceable> <type>integer</> ]) returns <type>tsquery</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns a query that searches for a match to the first given query
       followed by a match to the second given query at a distance of at
       <replaceable>distance</replaceable> lexemes, using
       the <literal>&lt;<replaceable>N</>&gt;</literal>
       <type>tsquery</> operator.  For example:

<screen>
SELECT tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10);
  tsquery_phrase
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'fat' &lt;10&gt; 'cat'
</screen>
      </para>
____________________________________________________________________________-->
      <para>
       返回一个查询，它使用<literal>&lt;<replaceable>N</>&gt;</literal> <type>tsquery</>操作符搜索两个距离为<replaceable>distance</replaceable>个词位的匹配，第一个匹配符合第一个给定的查询而第二个匹配符合第二个给定的查询。例如：

<screen>
SELECT tsquery_phrase(to_tsquery('fat'), to_tsquery('cat'), 10);
  tsquery_phrase
------------------
 'fat' &lt;10&gt; 'cat'
</screen>
      </para>
     </listitem>

    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>numnode</primary>
     </indexterm>

      <literal>numnode(<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>) returns <type>integer</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>numnode</primary>
     </indexterm>

      <literal>numnode(<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>) returns <type>integer</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the number of nodes (lexemes plus operators) in a
       <type>tsquery</>. This function is useful
       to determine if the <replaceable>query</replaceable> is meaningful
       (returns &gt; 0), or contains only stop words (returns 0).
       Examples:

<screen>
SELECT numnode(plainto_tsquery('the any'));
NOTICE:  query contains only stopword(s) or doesn't contain lexeme(s), ignored
 numnode
-&minus;-&minus;-&minus;-&minus;-
       0

SELECT numnode('foo &amp; bar'::tsquery);
 numnode
-&minus;-&minus;-&minus;-&minus;-
       3
</screen>
      </para>
____________________________________________________________________________-->
      <para>
       返回一个<type>tsquery</>中的结点数（词位外加操作符）。要确定<replaceable>查询</replaceable>是否有意义或者是否只包含停用词时，这个函数有用，在前一种情况它返回 &gt; 0，后一种情况返回 0。例子：

<screen>
SELECT numnode(plainto_tsquery('the any'));
NOTICE:  query contains only stopword(s) or doesn't contain lexeme(s), ignored
 numnode
---------
       0

SELECT numnode('foo &amp; bar'::tsquery);
 numnode
---------
       3
</screen>
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

<!--==========================orignal english content==========================
     <term>
     <indexterm>
      <primary>querytree</primary>
     </indexterm>

      <literal>querytree(<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>) returns <type>text</></literal>
     </term>
____________________________________________________________________________-->
     <term>
     <indexterm>
      <primary>querytree</primary>
     </indexterm>

      <literal>querytree(<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>) returns <type>text</></literal>
     </term>

     <listitem>
<!--==========================orignal english content==========================
      <para>
       Returns the portion of a <type>tsquery</> that can be used for
       searching an index.  This function is useful for detecting
       unindexable queries, for example those containing only stop words
       or only negated terms.  For example:

<screen>
SELECT querytree(to_tsquery('!defined'));
 querytree
-&minus;-&minus;-&minus;-&minus;-&minus;-

</screen>
      </para>
____________________________________________________________________________-->
      <para>
       返回一个<type>tsquery</>中可以被用来搜索一个索引的部分。这个函数可用来检测不可被索引的查询，例如那些只包含停用词或者只有否定术语的查询。例如：

<screen>
SELECT querytree(to_tsquery('!defined'));
 querytree
-----------

</screen>
      </para>
     </listitem>
    </varlistentry>

   </variablelist>

   <sect3 id="textsearch-query-rewriting">
<!--==========================orignal english content==========================
    <title>Query Rewriting</title>
____________________________________________________________________________-->
    <title>查询重写</title>

<!--==========================orignal english content==========================
    <indexterm zone="textsearch-query-rewriting">
     <primary>ts_rewrite</primary>
    </indexterm>
____________________________________________________________________________-->
    <indexterm zone="textsearch-query-rewriting">
     <primary>ts_rewrite</primary>
    </indexterm>

<!--==========================orignal english content==========================
    <para>
     The <function>ts_rewrite</function> family of functions search a
     given <type>tsquery</> for occurrences of a target
     subquery, and replace each occurrence with a
     substitute subquery.  In essence this operation is a
     <type>tsquery</>-specific version of substring replacement.
     A target and substitute combination can be
     thought of as a <firstterm>query rewrite rule</>.  A collection
     of such rewrite rules can be a powerful search aid.
     For example, you can expand the search using synonyms
     (e.g., <literal>new york</>, <literal>big apple</>, <literal>nyc</>,
     <literal>gotham</>) or narrow the search to direct the user to some hot
     topic.  There is some overlap in functionality between this feature
     and thesaurus dictionaries (<xref linkend="textsearch-thesaurus">).
     However, you can modify a set of rewrite rules on-the-fly without
     reindexing, whereas updating a thesaurus requires reindexing to be
     effective.
    </para>
____________________________________________________________________________-->
    <para>
     <function>ts_rewrite</function>函数族在一个给定的<type>tsquery</>中搜索一个目标子查询的出现，并且将每一次出现替换成一个替补子查询。本质上这个操作就是一个<type>tsquery</>版本的子串替换。一个目标和替补的组合可以被看成是一个<firstterm>查询重写规则</>。一个这类重写规则的集合可以是一个强大的搜索助手。例如，你可以使用同义词扩展搜索（如，<literal>new york</>、<literal>big apple</>、<literal>nyc</>、<literal>gotham</>），或者收缩搜索来将用户导向某些特点主题。在这个特性和分类词典（<xref linkend="textsearch-thesaurus">）有些功能重叠。但是，你可以随时修改一组重写规则而无需重索引，而更新一个分类词典则要求进行重索引才能生效。
    </para>

    <variablelist>

     <varlistentry>

<!--==========================orignal english content==========================
      <term>
       <literal>ts_rewrite (<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">target</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">substitute</replaceable> <type>tsquery</>) returns <type>tsquery</></literal>
      </term>
____________________________________________________________________________-->
      <term>
       <literal>ts_rewrite (<replaceable class="PARAMETER">query</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">target</replaceable> <type>tsquery</>, <replaceable class="PARAMETER">substitute</replaceable> <type>tsquery</>) returns <type>tsquery</></literal>
      </term>

      <listitem>
<!--==========================orignal english content==========================
       <para>
        This form of <function>ts_rewrite</> simply applies a single
        rewrite rule: <replaceable class="PARAMETER">target</replaceable>
        is replaced by <replaceable class="PARAMETER">substitute</replaceable>
        wherever it appears in <replaceable
        class="PARAMETER">query</replaceable>.  For example:

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery, 'a'::tsquery, 'c'::tsquery);
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
       </para>
____________________________________________________________________________-->
       <para>
        这种形式的<function>ts_rewrite</>简单地应用一个单一重写规则：不管<replaceable class="PARAMETER">target</replaceable>出现在<replaceable class="PARAMETER">query</replaceable>中的那个地方，它都被<replaceable class="PARAMETER">substitute</replaceable>替代。例如：

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery, 'a'::tsquery, 'c'::tsquery);
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
       </para>
      </listitem>
     </varlistentry>

     <varlistentry>

<!--==========================orignal english content==========================
      <term>
       <literal>ts_rewrite (<replaceable class="PARAMETER">query</> <type>tsquery</>, <replaceable class="PARAMETER">select</> <type>text</>) returns <type>tsquery</></literal>
      </term>
____________________________________________________________________________-->
      <term>
       <literal>ts_rewrite (<replaceable class="PARAMETER">query</> <type>tsquery</>, <replaceable class="PARAMETER">select</> <type>text</>) returns <type>tsquery</></literal>
      </term>

      <listitem>
<!--==========================orignal english content==========================
       <para>
        This form of <function>ts_rewrite</> accepts a starting
        <replaceable>query</> and a SQL <replaceable>select</> command, which
        is given as a text string.  The <replaceable>select</> must yield two
        columns of <type>tsquery</> type.  For each row of the
        <replaceable>select</> result, occurrences of the first column value
        (the target) are replaced by the second column value (the substitute)
        within the current <replaceable>query</> value.  For example:

<screen>
CREATE TABLE aliases (t tsquery PRIMARY KEY, s tsquery);
INSERT INTO aliases VALUES('a', 'c');

SELECT ts_rewrite('a &amp; b'::tsquery, 'SELECT t,s FROM aliases');
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
       </para>
____________________________________________________________________________-->
       <para>
        这种形式的<function>ts_rewrite</>接受一个开始<replaceable>query</>和一个 SQL <replaceable>select</>命令，它们以一个文本字符串的形式给出。<replaceable>select</>必须得到<type>tsquery</>类型的两列。对于<replaceable>select</>结果的每一行，在当前<replaceable>query</>值中出现的第一列值（目标）被第二列值（替补）所替换。例如：

<screen>
CREATE TABLE aliases (t tsquery PRIMARY KEY, s tsquery);
INSERT INTO aliases VALUES('a', 'c');

SELECT ts_rewrite('a &amp; b'::tsquery, 'SELECT t,s FROM aliases');
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
       </para>

<!--==========================orignal english content==========================
       <para>
        Note that when multiple rewrite rules are applied in this way,
        the order of application can be important; so in practice you will
        want the source query to <literal>ORDER BY</> some ordering key.
       </para>
____________________________________________________________________________-->
       <para>
        注意当多个重写规则被以这种方式应用时，应用的顺序很重要；因此在实际中你会要求源查询按某些排序键<literal>ORDER BY</>。
       </para>
      </listitem>
     </varlistentry>

    </variablelist>

<!--==========================orignal english content==========================
    <para>
     Let's consider a real-life astronomical example. We'll expand query
     <literal>supernovae</literal> using table-driven rewriting rules:

<screen>
CREATE TABLE aliases (t tsquery primary key, s tsquery);
INSERT INTO aliases VALUES(to_tsquery('supernovae'), to_tsquery('supernovae|sn'));

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
           ts_rewrite            
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'crab' &amp; ( 'supernova' | 'sn' )
</screen>

     We can change the rewriting rules just by updating the table:

<screen>
UPDATE aliases
SET s = to_tsquery('supernovae|sn &amp; !nebulae')
WHERE t = to_tsquery('supernovae');

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
                 ts_rewrite                  
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'crab' &amp; ( 'supernova' | 'sn' &amp; !'nebula' )
</screen>
    </para>
____________________________________________________________________________-->
    <para>
     让我们考虑一个现实的天文学例子。我们将使用表驱动的重写规则扩展查询<literal>supernovae</literal>：

<screen>
CREATE TABLE aliases (t tsquery primary key, s tsquery);
INSERT INTO aliases VALUES(to_tsquery('supernovae'), to_tsquery('supernovae|sn'));

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
           ts_rewrite            
---------------------------------
 'crab' &amp; ( 'supernova' | 'sn' )
</screen>

     我们可以通过只更新表来改变重写规则：

<screen>
UPDATE aliases
SET s = to_tsquery('supernovae|sn &amp; !nebulae')
WHERE t = to_tsquery('supernovae');

SELECT ts_rewrite(to_tsquery('supernovae &amp; crab'), 'SELECT * FROM aliases');
                 ts_rewrite                  
---------------------------------------------
 'crab' &amp; ( 'supernova' | 'sn' &amp; !'nebula' )
</screen>
    </para>

<!--==========================orignal english content==========================
    <para>
     Rewriting can be slow when there are many rewriting rules, since it
     checks every rule for a possible match. To filter out obvious non-candidate
     rules we can use the containment operators for the <type>tsquery</type>
     type. In the example below, we select only those rules which might match
     the original query:

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery,
                  'SELECT t,s FROM aliases WHERE ''a &amp; b''::tsquery @&gt; t');
 ts_rewrite
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'b' &amp; 'c'
</screen>
    </para>
____________________________________________________________________________-->
    <para>
     当有很多重写规则时，重写可能会很慢，因为它要为为每一个可能的匹配检查每一条规则。要过滤掉明显不符合的规则，我们可以为<type>tsquery</type>类型使用包含操作符。在下面的例子中，我们只选择那些可能匹配原始查询的规则：

<screen>
SELECT ts_rewrite('a &amp; b'::tsquery,
                  'SELECT t,s FROM aliases WHERE ''a &amp; b''::tsquery @&gt; t');
 ts_rewrite
------------
 'b' &amp; 'c'
</screen>
    </para>

   </sect3>

  </sect2>

  <sect2 id="textsearch-update-triggers">
<!--==========================orignal english content==========================
   <title>Triggers for Automatic Updates</title>
____________________________________________________________________________-->
   <title>用于自动更新的触发器</title>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>trigger</primary>
    <secondary>for updating a derived tsvector column</secondary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>触发器</primary>
    <secondary>用于更新一个派生的 tsvector 列</secondary>
   </indexterm>

<!--==========================orignal english content==========================
   <para>
    When using a separate column to store the <type>tsvector</> representation
    of your documents, it is necessary to create a trigger to update the
    <type>tsvector</> column when the document content columns change.
    Two built-in trigger functions are available for this, or you can write
    your own.
   </para>
____________________________________________________________________________-->
   <para>
    当使用一个单独的列来存储你的文档的<type>tsvector</>表示时，有必要创建一个触发器在文档内容列改变时更新<type>tsvector</>列。两个内建触发器函数可以用于这个目的，或者你可以编写你自己的触发器函数。
   </para>

<!--==========================orignal english content==========================
<synopsis>
tsvector_update_trigger(<replaceable class="PARAMETER">tsvector_column_name</replaceable>, <replaceable class="PARAMETER">config_name</replaceable>, <replaceable class="PARAMETER">text_column_name</replaceable> <optional>, ... </optional>)
tsvector_update_trigger_column(<replaceable class="PARAMETER">tsvector_column_name</replaceable>, <replaceable class="PARAMETER">config_column_name</replaceable>, <replaceable class="PARAMETER">text_column_name</replaceable> <optional>, ... </optional>)
</synopsis>
____________________________________________________________________________-->
<synopsis>
tsvector_update_trigger(<replaceable class="PARAMETER">tsvector_column_name</replaceable>, <replaceable class="PARAMETER">config_name</replaceable>, <replaceable class="PARAMETER">text_column_name</replaceable> <optional>, ... </optional>)
tsvector_update_trigger_column(<replaceable class="PARAMETER">tsvector_column_name</replaceable>, <replaceable class="PARAMETER">config_column_name</replaceable>, <replaceable class="PARAMETER">text_column_name</replaceable> <optional>, ... </optional>)
</synopsis>

<!--==========================orignal english content==========================
   <para>
    These trigger functions automatically compute a <type>tsvector</>
    column from one or more textual columns, under the control of
    parameters specified in the <command>CREATE TRIGGER</> command.
    An example of their use is:

<screen>
CREATE TABLE messages (
    title       text,
    body        text,
    tsv         tsvector
);

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE PROCEDURE
tsvector_update_trigger(tsv, 'pg_catalog.english', title, body);

INSERT INTO messages VALUES('title here', 'the body text is here');

SELECT * FROM messages;
   title    |         body          |            tsv             
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 title here | the body text is here | 'bodi':4 'text':5 'titl':1

SELECT title, body FROM messages WHERE tsv @@ to_tsquery('title &amp; body');
   title    |         body          
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 title here | the body text is here
</screen>

    Having created this trigger, any change in <structfield>title</> or
    <structfield>body</> will automatically be reflected into
    <structfield>tsv</>, without the application having to worry about it.
   </para>
____________________________________________________________________________-->
   <para>
    这些触发器函数在<command>CREATE TRIGGER</>命令中指定的参数控制下，自动从一个或多个文本列计算一个<type>tsvector</>列。它们使用的一个例子是：

<screen>
CREATE TABLE messages (
    title       text,
    body        text,
    tsv         tsvector
);

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
ON messages FOR EACH ROW EXECUTE PROCEDURE
tsvector_update_trigger(tsv, 'pg_catalog.english', title, body);

INSERT INTO messages VALUES('title here', 'the body text is here');

SELECT * FROM messages;
   title    |         body          |            tsv             
------------+-----------------------+----------------------------
 title here | the body text is here | 'bodi':4 'text':5 'titl':1

SELECT title, body FROM messages WHERE tsv @@ to_tsquery('title &amp; body');
   title    |         body          
------------+-----------------------
 title here | the body text is here
</screen>

    在创建了这个触发器后，在<structfield>title</>或<structfield>body</>中的任何修改将自动地被反映到<structfield>tsv</>中，不需要应用来操心同步的问题。
   </para>

<!--==========================orignal english content==========================
   <para>
    The first trigger argument must be the name of the <type>tsvector</>
    column to be updated.  The second argument specifies the text search
    configuration to be used to perform the conversion.  For
    <function>tsvector_update_trigger</>, the configuration name is simply
    given as the second trigger argument.  It must be schema-qualified as
    shown above, so that the trigger behavior will not change with changes
    in <varname>search_path</>.  For
    <function>tsvector_update_trigger_column</>, the second trigger argument
    is the name of another table column, which must be of type
    <type>regconfig</>.  This allows a per-row selection of configuration
    to be made.  The remaining argument(s) are the names of textual columns
    (of type <type>text</>, <type>varchar</>, or <type>char</>).  These
    will be included in the document in the order given.  NULL values will
    be skipped (but the other columns will still be indexed).
   </para>
____________________________________________________________________________-->
   <para>
    第一个触发器参数必须是要被更新的<type>tsvector</>列的名字。第二个参数指定要被用来执行转换的文本搜索配置。对于<function>tsvector_update_trigger</>，配置名被简单地用第二个触发器参数给出。如上所示，它必须是模式限定的，因此该触发器行为不会因为<varname>search_path</>中的改变而改变。对于<function>tsvector_update_trigger_column</>，第二个触发器参数是另一个表列的名称，它必须是类型<type>regconfig</>。这允许做一种逐行的配置选择。剩下的参数是文本列的名称（类型为<type>text</>、<type>varchar</>或<type>char</>）。它们将按给定的顺序被包括在文档中。NULL 值将被跳过（但是其他列仍将被索引）。
   </para>

<!--==========================orignal english content==========================
   <para>
    A limitation of these built-in triggers is that they treat all the
    input columns alike.  To process columns differently &mdash; for
    example, to weight title differently from body &mdash; it is necessary
    to write a custom trigger.  Here is an example using
    <application>PL/pgSQL</application> as the trigger language:

<programlisting>
CREATE FUNCTION messages_trigger() RETURNS trigger AS $$
begin
  new.tsv :=
     setweight(to_tsvector('pg_catalog.english', coalesce(new.title,'')), 'A') ||
     setweight(to_tsvector('pg_catalog.english', coalesce(new.body,'')), 'D');
  return new;
end
$$ LANGUAGE plpgsql;

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
    ON messages FOR EACH ROW EXECUTE PROCEDURE messages_trigger();
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    这些内建触发器的一个限制是它们将所有输入列同样对待。要对列进行不同的处理 &mdash; 例如，使标题的权重和正文的不同 &mdash; 就需要编写一个自定义触发器。下面是用<application>PL/pgSQL</application>作为触发器语言的一个例子：

<programlisting>
CREATE FUNCTION messages_trigger() RETURNS trigger AS $$
begin
  new.tsv :=
     setweight(to_tsvector('pg_catalog.english', coalesce(new.title,'')), 'A') ||
     setweight(to_tsvector('pg_catalog.english', coalesce(new.body,'')), 'D');
  return new;
end
$$ LANGUAGE plpgsql;

CREATE TRIGGER tsvectorupdate BEFORE INSERT OR UPDATE
    ON messages FOR EACH ROW EXECUTE PROCEDURE messages_trigger();
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    Keep in mind that it is important to specify the configuration name
    explicitly when creating <type>tsvector</> values inside triggers,
    so that the column's contents will not be affected by changes to
    <varname>default_text_search_config</>.  Failure to do this is likely to
    lead to problems such as search results changing after a dump and reload.
   </para>
____________________________________________________________________________-->
   <para>
    记住当在触发器内创建<type>tsvector</>值时，显式地指定配置名非常重要，这样列的内容才不会被<varname>default_text_search_config</>的改变所影响。如果不这样做很可能导致问题，例如在转储并重新载入之后搜索结果改变。
   </para>

  </sect2>

  <sect2 id="textsearch-statistics">
<!--==========================orignal english content==========================
   <title>Gathering Document Statistics</title>
____________________________________________________________________________-->
   <title>收集文档统计数据</title>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>ts_stat</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>ts_stat</primary>
   </indexterm>

<!--==========================orignal english content==========================
   <para>
    The function <function>ts_stat</> is useful for checking your
    configuration and for finding stop-word candidates.
   </para>
____________________________________________________________________________-->
   <para>
    <function>ts_stat</>被用于检查你的配置以及寻找候选的停用词。
   </para>

<!--==========================orignal english content==========================
<synopsis>
ts_stat(<replaceable class="PARAMETER">sqlquery</replaceable> <type>text</>, <optional> <replaceable class="PARAMETER">weights</replaceable> <type>text</>, </optional>
        OUT <replaceable class="PARAMETER">word</replaceable> <type>text</>, OUT <replaceable class="PARAMETER">ndoc</replaceable> <type>integer</>,
        OUT <replaceable class="PARAMETER">nentry</replaceable> <type>integer</>) returns <type>setof record</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_stat(<replaceable class="PARAMETER">sqlquery</replaceable> <type>text</>, <optional> <replaceable class="PARAMETER">weights</replaceable> <type>text</>, </optional>
        OUT <replaceable class="PARAMETER">word</replaceable> <type>text</>, OUT <replaceable class="PARAMETER">ndoc</replaceable> <type>integer</>,
        OUT <replaceable class="PARAMETER">nentry</replaceable> <type>integer</>) returns <type>setof record</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <replaceable>sqlquery</replaceable> is a text value containing an SQL
    query which must return a single <type>tsvector</type> column.
    <function>ts_stat</> executes the query and returns statistics about
    each distinct lexeme (word) contained in the <type>tsvector</type>
    data.  The columns returned are

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>word</> <type>text</> &mdash; the value of a lexeme
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>ndoc</> <type>integer</> &mdash; number of documents
       (<type>tsvector</>s) the word occurred in
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>nentry</> <type>integer</> &mdash; total number of
       occurrences of the word
      </para>
     </listitem>
    </itemizedlist>

    If <replaceable>weights</replaceable> is supplied, only occurrences
    having one of those weights are counted.
   </para>
____________________________________________________________________________-->
   <para>
    <replaceable>sqlquery</replaceable>是一个文本值，它包含一个必须返回单一<type>tsvector</type>列的 SQL 查询。<function>ts_stat</>执行该查询并返回有关包含在该<type>tsvector</type>数据中的每一个可区分词位（词）的统计数据。返回的列是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>word</> <type>text</> &mdash; 一个词位的值
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>ndoc</> <type>integer</> &mdash; 词出现过的文档（<type>tsvector</>）的数量
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>nentry</> <type>integer</> &mdash; 词出现的总次数
      </para>
     </listitem>
    </itemizedlist>

    如果提供了<replaceable>权重</replaceable>，只有具有其中之一权重的出现才被计算在内。
   </para>

<!--==========================orignal english content==========================
   <para>
    For example, to find the ten most frequent words in a document collection:

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>

    The same, but counting only word occurrences with weight <literal>A</>
    or <literal>B</>:

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod', 'ab')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    例如，要在一个文档集合中查找十个最频繁的词：

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>

    同样的要求，但是只计算以权重<literal>A</>或<literal>B</>出现的次数：

<programlisting>
SELECT * FROM ts_stat('SELECT vector FROM apod', 'ab')
ORDER BY nentry DESC, ndoc DESC, word
LIMIT 10;
</programlisting>
   </para>

  </sect2>

 </sect1>

 <sect1 id="textsearch-parsers">
<!--==========================orignal english content==========================
  <title>Parsers</title>
____________________________________________________________________________-->
  <title>解析器</title>

<!--==========================orignal english content==========================
  <para>
   Text search parsers are responsible for splitting raw document text
   into <firstterm>tokens</> and identifying each token's type, where
   the set of possible types is defined by the parser itself.
   Note that a parser does not modify the text at all &mdash; it simply
   identifies plausible word boundaries.  Because of this limited scope,
   there is less need for application-specific custom parsers than there is
   for custom dictionaries.  At present <productname>PostgreSQL</productname>
   provides just one built-in parser, which has been found to be useful for a
   wide range of applications.
  </para>
____________________________________________________________________________-->
  <para>
   文本搜索解析器负责把未处理的文档文本划分成<firstterm>记号</>并且标识每一个记号的类型，而可能的类型集合由解析器本身定义。注意一个解析器完全不会修改文本 &mdash; 它简单地标识看似有理的词边界。因为这种有限的视野，对于应用相关的自定义解析器的需求就没有自定义字典那么强烈。目前<productname>PostgreSQL</productname>只提供了一种内建解析器，它已经被证实对很多种应用都适用。
  </para>

<!--==========================orignal english content==========================
  <para>
   The built-in parser is named <literal>pg_catalog.default</>.
   It recognizes 23 token types, shown in <xref linkend="textsearch-default-parser">.
  </para>
____________________________________________________________________________-->
  <para>
   内建解析器被称为<literal>pg_catalog.default</>。它识别 23 种记号类型，如<xref linkend="textsearch-default-parser">所示。
  </para>

  <table id="textsearch-default-parser">
<!--==========================orignal english content==========================
   <title>Default Parser's Token Types</title>
____________________________________________________________________________-->
   <title>默认解析器的记号类型</title>
   <tgroup cols="3">
    <thead>
<!--==========================orignal english content==========================
     <row>
      <entry>Alias</entry>
      <entry>Description</entry>
      <entry>Example</entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry>别名</entry>
      <entry>描述</entry>
      <entry>例子</entry>
     </row>
    </thead>
    <tbody>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>asciiword</></entry>
      <entry>Word, all ASCII letters</entry>
      <entry><literal>elephant</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>asciiword</></entry>
      <entry>单词，所有 ASCII 字母</entry>
      <entry><literal>elephant</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>word</></entry>
      <entry>Word, all letters</entry>
      <entry><literal>ma&ntilde;ana</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>word</></entry>
      <entry>单词，所有字母</entry>
      <entry><literal>ma&ntilde;ana</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>numword</></entry>
      <entry>Word, letters and digits</entry>
      <entry><literal>beta1</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>numword</></entry>
      <entry>单词，字母和数字</entry>
      <entry><literal>beta1</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>asciihword</></entry>
      <entry>Hyphenated word, all ASCII</entry>
      <entry><literal>up-to-date</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>asciihword</></entry>
      <entry>带连字符的单词，所有 ASCII</entry>
      <entry><literal>up-to-date</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>hword</></entry>
      <entry>Hyphenated word, all letters</entry>
      <entry><literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>hword</></entry>
      <entry>带连字符的单词，所有字母</entry>
      <entry><literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>numhword</></entry>
      <entry>Hyphenated word, letters and digits</entry>
      <entry><literal>postgresql-beta1</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>numhword</></entry>
      <entry>带连字符的单词，字母和数字</entry>
      <entry><literal>postgresql-beta1</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>hword_asciipart</></entry>
      <entry>Hyphenated word part, all ASCII</entry>
      <entry><literal>postgresql</literal> in the context <literal>postgresql-beta1</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>hword_asciipart</></entry>
      <entry>带连字符的单词部分，所有 ASCII</entry>
      <entry><literal>postgresql</literal> in the context <literal>postgresql-beta1</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>hword_part</></entry>
      <entry>Hyphenated word part, all letters</entry>
      <entry><literal>l&oacute;gico</literal> or <literal>matem&aacute;tica</literal>
       in the context <literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>hword_part</></entry>
      <entry>带连字符的单词部分，所有字母</entry>
      <entry><literal>l&oacute;gico</literal> or <literal>matem&aacute;tica</literal>
       in the context <literal>l&oacute;gico-matem&aacute;tica</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>hword_numpart</></entry>
      <entry>Hyphenated word part, letters and digits</entry>
      <entry><literal>beta1</literal> in the context
       <literal>postgresql-beta1</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>hword_numpart</></entry>
      <entry>带连字符的单词部分，字母和数字</entry>
      <entry><literal>beta1</literal> in the context
       <literal>postgresql-beta1</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>email</></entry>
      <entry>Email address</entry>
      <entry><literal>foo@example.com</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>email</></entry>
      <entry>Email 地址</entry>
      <entry><literal>foo@example.com</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>protocol</></entry>
      <entry>Protocol head</entry>
      <entry><literal>http://</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>protocol</></entry>
      <entry>协议头部</entry>
      <entry><literal>http://</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>url</></entry>
      <entry>URL</entry>
      <entry><literal>example.com/stuff/index.html</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>url</></entry>
      <entry>URL</entry>
      <entry><literal>example.com/stuff/index.html</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>host</></entry>
      <entry>Host</entry>
      <entry><literal>example.com</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>host</></entry>
      <entry>主机</entry>
      <entry><literal>example.com</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>url_path</></entry>
      <entry>URL path</entry>
      <entry><literal>/stuff/index.html</literal>, in the context of a URL</entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>url_path</></entry>
      <entry>URL 路径</entry>
      <entry><literal>/stuff/index.html</literal>, in the context of a URL</entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>file</></entry>
      <entry>File or path name</entry>
      <entry><literal>/usr/local/foo.txt</literal>, if not within a URL</entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>file</></entry>
      <entry>文件或路径名</entry>
      <entry><literal>/usr/local/foo.txt</literal>, if not within a URL</entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>sfloat</></entry>
      <entry>Scientific notation</entry>
      <entry><literal>-1.234e56</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>sfloat</></entry>
      <entry>科学记数法</entry>
      <entry><literal>-1.234e56</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>float</></entry>
      <entry>Decimal notation</entry>
      <entry><literal>-1.234</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>float</></entry>
      <entry>十进制记数法</entry>
      <entry><literal>-1.234</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>int</></entry>
      <entry>Signed integer</entry>
      <entry><literal>-1234</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>int</></entry>
      <entry>有符号整数</entry>
      <entry><literal>-1234</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>uint</></entry>
      <entry>Unsigned integer</entry>
      <entry><literal>1234</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>uint</></entry>
      <entry>无符号整数</entry>
      <entry><literal>1234</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>version</></entry>
      <entry>Version number</entry>
      <entry><literal>8.3.0</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>version</></entry>
      <entry>版本号</entry>
      <entry><literal>8.3.0</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>tag</></entry>
      <entry>XML tag</entry>
      <entry><literal>&lt;a href="dictionaries.html"&gt;</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>tag</></entry>
      <entry>XML 标签</entry>
      <entry><literal>&lt;a href="dictionaries.html"&gt;</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>entity</></entry>
      <entry>XML entity</entry>
      <entry><literal>&amp;amp;</literal></entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>entity</></entry>
      <entry>XML 实体</entry>
      <entry><literal>&amp;amp;</literal></entry>
     </row>
<!--==========================orignal english content==========================
     <row>
      <entry><literal>blank</></entry>
      <entry>Space symbols</entry>
      <entry>(any whitespace or punctuation not otherwise recognized)</entry>
     </row>
____________________________________________________________________________-->
     <row>
      <entry><literal>blank</></entry>
      <entry>空格符号</entry>
      <entry>（其他不识别的任意空白或标点符号）</entry>
     </row>
    </tbody>
   </tgroup>
  </table>

  <note>
<!--==========================orignal english content==========================
   <para>
    The parser's notion of a <quote>letter</> is determined by the database's
    locale setting, specifically <varname>lc_ctype</>.  Words containing
    only the basic ASCII letters are reported as a separate token type,
    since it is sometimes useful to distinguish them.  In most European
    languages, token types <literal>word</> and <literal>asciiword</>
    should be treated alike.
   </para>
____________________________________________________________________________-->
   <para>
    解析器的一个<quote>字母</>的概念由数据库的区域设置决定，具体是<varname>lc_ctype</>。只包含基本 ASCII 字母的词被报告为一个单独的记号类型，因为有时可以用来区别它们。在大部分欧洲语言中，记号类型<literal>word</>和<literal>asciiword</>应该被同样对待。
   </para>

<!--==========================orignal english content==========================
   <para>
    <literal>email</> does not support all valid email characters as
    defined by RFC 5322.  Specifically, the only non-alphanumeric
    characters supported for email user names are period, dash, and
    underscore.
   </para>
____________________________________________________________________________-->
   <para>
    <literal>email</>不支持 RFC 5322 定义的所有合法 email 字符。具体来说，对 email 用户名被支持的非字母数字字符只有句点、破折号和下划线。
   </para>
  </note>

<!--==========================orignal english content==========================
  <para>
   It is possible for the parser to produce overlapping tokens from the same
   piece of text.  As an example, a hyphenated word will be reported both
   as the entire word and as each component:

<screen>
SELECT alias, description, token FROM ts_debug('foo-bar-beta1');
      alias      |               description                |     token     
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 numhword        | Hyphenated word, letters and digits      | foo-bar-beta1
 hword_asciipart | Hyphenated word part, all ASCII          | foo
 blank           | Space symbols                            | -
 hword_asciipart | Hyphenated word part, all ASCII          | bar
 blank           | Space symbols                            | -
 hword_numpart   | Hyphenated word part, letters and digits | beta1
</screen>

   This behavior is desirable since it allows searches to work for both
   the whole compound word and for components.  Here is another
   instructive example:

<screen>
SELECT alias, description, token FROM ts_debug('http://example.com/stuff/index.html');
  alias   |  description  |            token             
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 protocol | Protocol head | http://
 url      | URL           | example.com/stuff/index.html
 host     | Host          | example.com
 url_path | URL path      | /stuff/index.html
</screen>
  </para>
____________________________________________________________________________-->
  <para>
   解析器有可能从同一份文本得出相互覆盖的记号。例如，一个带连字符的词可能会被报告为一整个词或者多个部分：

<screen>
SELECT alias, description, token FROM ts_debug('foo-bar-beta1');
      alias      |               description                |     token     
-----------------+------------------------------------------+---------------
 numhword        | Hyphenated word, letters and digits      | foo-bar-beta1
 hword_asciipart | Hyphenated word part, all ASCII          | foo
 blank           | Space symbols                            | -
 hword_asciipart | Hyphenated word part, all ASCII          | bar
 blank           | Space symbols                            | -
 hword_numpart   | Hyphenated word part, letters and digits | beta1
</screen>

   这种行为是值得要的，因为它允许对整个复合词和每个部分进行搜索。这里是另一个例子：

<screen>
SELECT alias, description, token FROM ts_debug('http://example.com/stuff/index.html');
  alias   |  description  |            token             
----------+---------------+------------------------------
 protocol | Protocol head | http://
 url      | URL           | example.com/stuff/index.html
 host     | Host          | example.com
 url_path | URL path      | /stuff/index.html
</screen>
  </para>

 </sect1>

 <sect1 id="textsearch-dictionaries">
<!--==========================orignal english content==========================
  <title>Dictionaries</title>
____________________________________________________________________________-->
  <title>词典</title>

<!--==========================orignal english content==========================
  <para>
   Dictionaries are used to eliminate words that should not be considered in a
   search (<firstterm>stop words</>), and to <firstterm>normalize</> words so
   that different derived forms of the same word will match.  A successfully
   normalized word is called a <firstterm>lexeme</>.  Aside from
   improving search quality, normalization and removal of stop words reduce the
   size of the <type>tsvector</type> representation of a document, thereby
   improving performance.  Normalization does not always have linguistic meaning
   and usually depends on application semantics.
  </para>
____________________________________________________________________________-->
  <para>
   词典被用来消除不被搜索考虑的词（<firstterm>stop words</>）、并被用来<firstterm>正规化</>词这样同一个词的不同派生形式将会匹配。一个被成功地正规化的词被称为一个<firstterm>词位</>。除了提高搜索质量，正规化和移除停用词减小了文档的<type>tsvector</type>表示的尺寸，因而提高了性能。正规化不会总是有语言上的意义并且通常依赖于应用的语义。
  </para>

<!--==========================orignal english content==========================
  <para>
   Some examples of normalization:

   <itemizedlist  spacing="compact" mark="bullet">

    <listitem>
     <para>
      Linguistic - Ispell dictionaries try to reduce input words to a
      normalized form; stemmer dictionaries remove word endings
     </para>
    </listitem>
    <listitem>
     <para>
      <acronym>URL</acronym> locations can be canonicalized to make
      equivalent URLs match:

      <itemizedlist  spacing="compact" mark="bullet">
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/index.html
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/../db/mw/index.html
        </para>
       </listitem>
      </itemizedlist>
     </para>
    </listitem>
    <listitem>
     <para>
      Color names can be replaced by their hexadecimal values, e.g.,
      <literal>red, green, blue, magenta -> FF0000, 00FF00, 0000FF, FF00FF</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      If indexing numbers, we can
      remove some fractional digits to reduce the range of possible
      numbers, so for example <emphasis>3.14</emphasis>159265359,
      <emphasis>3.14</emphasis>15926, <emphasis>3.14</emphasis> will be the same
      after normalization if only two digits are kept after the decimal point.
     </para>
    </listitem>
   </itemizedlist>

  </para>
____________________________________________________________________________-->
  <para>
   一些正规化的例子：

   <itemizedlist  spacing="compact" mark="bullet">

    <listitem>
     <para>
      语言学的 - Ispell 词典尝试将输入词缩减为一种正规化的形式；词干分析器词典移除词的结尾
     </para>
    </listitem>
    <listitem>
     <para>
      <acronym>URL</acronym>位置可以被规范化来得到等效的 URL 匹配：

      <itemizedlist  spacing="compact" mark="bullet">
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/index.html
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/mw/
        </para>
       </listitem>
       <listitem>
        <para>
         http://www.pgsql.ru/db/../db/mw/index.html
        </para>
       </listitem>
      </itemizedlist>
     </para>
    </listitem>
    <listitem>
     <para>
      颜色名可以被它们的十六进制值替换，例如<literal>red, green, blue, magenta -> FF0000, 00FF00, 0000FF, FF00FF</literal>
     </para>
    </listitem>
    <listitem>
     <para>
      如果索引数字，我们可以移除某些小数位来缩减可能的数字的范围，因此如果只保留小数点后两位，例如<emphasis>3.14</emphasis>159265359、<emphasis>3.14</emphasis>15926、<emphasis>3.14</emphasis>在正规化后会变得相同。
     </para>
    </listitem>
   </itemizedlist>

  </para>

<!--==========================orignal english content==========================
  <para>
   A dictionary is a program that accepts a token as
   input and returns:
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>
      an array of lexemes if the input token is known to the dictionary
      (notice that one token can produce more than one lexeme)
     </para>
    </listitem>
    <listitem>
     <para>
      a single lexeme with the <literal>TSL_FILTER</> flag set, to replace
      the original token with a new token to be passed to subsequent
      dictionaries (a dictionary that does this is called a
      <firstterm>filtering dictionary</>)
     </para>
    </listitem>
    <listitem>
     <para>
      an empty array if the dictionary knows the token, but it is a stop word
     </para>
    </listitem>
    <listitem>
     <para>
      <literal>NULL</literal> if the dictionary does not recognize the input token
     </para>
    </listitem>
   </itemizedlist>
  </para>
____________________________________________________________________________-->
  <para>
   一个词典是一个程序，它接受一个记号作为输入，并返回：
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>
      如果输入的记号对词典是已知的，则返回一个词位数组（注意一个记号可能产生多于一个词位）
     </para>
    </listitem>
    <listitem>
     <para>
      一个<literal>TSL_FILTER</>标志被设置的单一词位，用一个新记号来替换要被传递给后续字典的原始记号（做这件事的一个字典被称为一个<firstterm>过滤字典</>）
     </para>
    </listitem>
    <listitem>
     <para>
      如果字典知道该记号但它是一个停用词，则返回一个空数组
     </para>
    </listitem>
    <listitem>
     <para>
      如果字典不识别该输入记号，则返回<literal>NULL</literal>
     </para>
    </listitem>
   </itemizedlist>
  </para>

<!--==========================orignal english content==========================
  <para>
   <productname>PostgreSQL</productname> provides predefined dictionaries for
   many languages.  There are also several predefined templates that can be
   used to create new dictionaries with custom parameters.  Each predefined
   dictionary template is described below.  If no existing
   template is suitable, it is possible to create new ones; see the
   <filename>contrib/</> area of the <productname>PostgreSQL</> distribution
   for examples.
  </para>
____________________________________________________________________________-->
  <para>
   <productname>PostgreSQL</productname>为许多语言提供了预定义的字典。也有多种预定义模板可以被用于创建带自定义参数的新词典。每一种预定义词典模板在下面描述。如果没有合适的现有模板，可以创建新的；例子见<productname>PostgreSQL</>发布的<filename>contrib/</>区域。
  </para>

<!--==========================orignal english content==========================
  <para>
   A text search configuration binds a parser together with a set of
   dictionaries to process the parser's output tokens.  For each token
   type that the parser can return, a separate list of dictionaries is
   specified by the configuration.  When a token of that type is found
   by the parser, each dictionary in the list is consulted in turn,
   until some dictionary recognizes it as a known word.  If it is identified
   as a stop word, or if no dictionary recognizes the token, it will be
   discarded and not indexed or searched for.
   Normally, the first dictionary that returns a non-<literal>NULL</>
   output determines the result, and any remaining dictionaries are not
   consulted; but a filtering dictionary can replace the given word
   with a modified word, which is then passed to subsequent dictionaries.
  </para>
____________________________________________________________________________-->
  <para>
   一个文本搜索配置把一个解析器和一组处理解析器输出记号的词典绑定在一起。对于每一中解析器能返回的记号类型，配置都指定了一个单独的词典列表。当该类型的一个记号被解析器找到时，每一个词典都被按照顺序查询，知道某个词典将其识别为一个已知词。如果它被标识为一个停用词或者没有一个词典识别它，它将被丢弃并且不会被索引和用于搜索。通常，第一个返回非<literal>NULL</>输出的词典决定结果，并且任何剩下的词典都不会被查找；但是一个过滤词典可以将给定词替换为一个被修改的词，它再被传递给后续的词典。
  </para>

<!--==========================orignal english content==========================
  <para>
   The general rule for configuring a list of dictionaries
   is to place first the most narrow, most specific dictionary, then the more
   general dictionaries, finishing with a very general dictionary, like
   a <application>Snowball</> stemmer or <literal>simple</>, which
   recognizes everything.  For example, for an astronomy-specific search
   (<literal>astro_en</literal> configuration) one could bind token type
   <type>asciiword</type> (ASCII word) to a synonym dictionary of astronomical
   terms, a general English dictionary and a <application>Snowball</> English
   stemmer:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION astro_en
    ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
</programlisting>
  </para>
____________________________________________________________________________-->
  <para>
   配置一个词典列表的通用规则是将最狭窄、最特定的词典放在第一位，然后是更加通用的词典，以一个非常通用的词典结尾，像一个<application>Snowball</>词干分析器或什么都识别的<literal>simple</>。例如，对于一个天文学相关的搜索（<literal>astro_en</literal> 配置）我们可以把记号类型<type>asciiword</type>（ASCII 词）绑定到一个天文学术语的分类词典、一个通用英语词典和一个<application>Snowball</>英语词干分析器：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION astro_en
    ADD MAPPING FOR asciiword WITH astrosyn, english_ispell, english_stem;
</programlisting>
  </para>

<!--==========================orignal english content==========================
  <para>
   A filtering dictionary can be placed anywhere in the list, except at the
   end where it'd be useless.  Filtering dictionaries are useful to partially
   normalize words to simplify the task of later dictionaries.  For example,
   a filtering dictionary could be used to remove accents from accented
   letters, as is done by the <xref linkend="unaccent"> module.
  </para>
____________________________________________________________________________-->
  <para>
   一个过滤词典可以被放置在列表中的任意位置，除了在最后，因为过滤词典放在最后就等于无用。过滤词典可用于部分正规化词来简化后续词典的工作。例如，一个过滤词典可以被用来从音标字母中移除重音符号，就像<xref linkend="unaccent">模块所做的。
  </para>

  <sect2 id="textsearch-stopwords">
<!--==========================orignal english content==========================
   <title>Stop Words</title>
____________________________________________________________________________-->
   <title>停用词</title>

<!--==========================orignal english content==========================
   <para>
    Stop words are words that are very common, appear in almost every
    document, and have no discrimination value. Therefore, they can be ignored
    in the context of full text searching. For example, every English text
    contains words like <literal>a</literal> and <literal>the</>, so it is
    useless to store them in an index.  However, stop words do affect the
    positions in <type>tsvector</type>, which in turn affect ranking:

<screen>
SELECT to_tsvector('english','in the list of stop words');
        to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'list':3 'stop':5 'word':6
</screen>

    The missing positions 1,2,4 are because of stop words.  Ranks
    calculated for documents with and without stop words are quite different:

<screen>
SELECT ts_rank_cd (to_tsvector('english','in the list of stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
       0.05

SELECT ts_rank_cd (to_tsvector('english','list stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
        0.1
</screen>

   </para>
____________________________________________________________________________-->
   <para>
    停用词是非常常用、在几乎每一个文档中出现并且没有任何区分度的词。因此，在全文搜索的环境中它们可以被忽略。例如，每一段英语文本都包含<literal>a</literal>和<literal>the</>等次，因此把它们存储在一个索引中是没有用处的。但是，停用词确实会影响在<type>tsvector</type>中的位置，这进而会影响排名：

<screen>
SELECT to_tsvector('english','in the list of stop words');
        to_tsvector
----------------------------
 'list':3 'stop':5 'word':6
</screen>

    缺失的位置 1、2、4 是因为停用词。文档的排名计算在使用和不使用停用词的情况下是很不同的：

<screen>
SELECT ts_rank_cd (to_tsvector('english','in the list of stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
       0.05

SELECT ts_rank_cd (to_tsvector('english','list stop words'), to_tsquery('list &amp; stop'));
 ts_rank_cd
------------
        0.1
</screen>

   </para>

<!--==========================orignal english content==========================
   <para>
    It is up to the specific dictionary how it treats stop words. For example,
    <literal>ispell</literal> dictionaries first normalize words and then
    look at the list of stop words, while <literal>Snowball</literal> stemmers
    first check the list of stop words. The reason for the different
    behavior is an attempt to decrease noise.
   </para>
____________________________________________________________________________-->
   <para>
    如何对待停用词是由指定词典决定的。例如，<literal>ispell</literal>词典首先正规化词并且查看停用词列表，而<literal>Snowball</literal>词干分析器首先检查停用词的列表。这种不同行为的原因是一冲降低噪声的尝试。
   </para>

  </sect2>

  <sect2 id="textsearch-simple-dictionary">
<!--==========================orignal english content==========================
   <title>Simple Dictionary</title>
____________________________________________________________________________-->
   <title>简单词典</title>

<!--==========================orignal english content==========================
   <para>
    The <literal>simple</> dictionary template operates by converting the
    input token to lower case and checking it against a file of stop words.
    If it is found in the file then an empty array is returned, causing
    the token to be discarded.  If not, the lower-cased form of the word
    is returned as the normalized lexeme.  Alternatively, the dictionary
    can be configured to report non-stop-words as unrecognized, allowing
    them to be passed on to the next dictionary in the list.
   </para>
____________________________________________________________________________-->
   <para>
    <literal>simple</>词典模板的操作是将输入记号转换为小写形式并且根据一个停用词文件检查它。如果该记号在该文件中被找到，则返回一个空数组，导致该记号被丢弃。否则，该词的小写形式被返回作为正规化的词位。作为一种选择，该词典可以被配置为将非停用词报告为未识别，允许它们被传递给列表中的下一个词典。
   </para>

<!--==========================orignal english content==========================
   <para>
    Here is an example of a dictionary definition using the <literal>simple</>
    template:

<programlisting>
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
    TEMPLATE = pg_catalog.simple,
    STOPWORDS = english
);
</programlisting>

    Here, <literal>english</literal> is the base name of a file of stop words.
    The file's full name will be
    <filename>$SHAREDIR/tsearch_data/english.stop</>,
    where <literal>$SHAREDIR</> means the
    <productname>PostgreSQL</productname> installation's shared-data directory,
    often <filename>/usr/local/share/postgresql</> (use <command>pg_config
    -&minus;sharedir</> to determine it if you're not sure).
    The file format is simply a list
    of words, one per line.  Blank lines and trailing spaces are ignored,
    and upper case is folded to lower case, but no other processing is done
    on the file contents.
   </para>
____________________________________________________________________________-->
   <para>
    下面是一个使用<literal>simple</>模板的词典定义的例子：

<programlisting>
CREATE TEXT SEARCH DICTIONARY public.simple_dict (
    TEMPLATE = pg_catalog.simple,
    STOPWORDS = english
);
</programlisting>

    这里，<literal>english</literal>是一个停用词文件的基本名称。该文件的全名将是<filename>$SHAREDIR/tsearch_data/english.stop</>，其中<literal>$SHAREDIR</>表示<productname>PostgreSQL</productname>安装的共享数据目录，通常是<filename>/usr/local/share/postgresql</>（如果不确定，使用<command>pg_config --sharedir</>）。该文件格式是一个词的列表，每行一个。空行和尾部的空格都被忽略，并且大写也被折叠成小写，但是没有其他对该文件内容的处理。
   </para>

<!--==========================orignal english content==========================
   <para>
    Now we can test our dictionary:

<screen>
SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {yes}

SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    现在我们能够测试我们的词典：

<screen>
SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-----------
 {yes}

SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-----------
 {}
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    We can also choose to return <literal>NULL</>, instead of the lower-cased
    word, if it is not found in the stop words file.  This behavior is
    selected by setting the dictionary's <literal>Accept</> parameter to
    <literal>false</>.  Continuing the example:

<screen>
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );

SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-


SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    如果没有在停用词文件中找到，我们也可以选择返回<literal>NULL</>而不是小写形式的词。这种行为可以通过设置词典的<literal>Accept</>参数为<literal>false</>来选择。继续该例子：

<screen>
ALTER TEXT SEARCH DICTIONARY public.simple_dict ( Accept = false );

SELECT ts_lexize('public.simple_dict','YeS');
 ts_lexize
-----------


SELECT ts_lexize('public.simple_dict','The');
 ts_lexize
-----------
 {}
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    With the default setting of <literal>Accept</> = <literal>true</>,
    it is only useful to place a <literal>simple</> dictionary at the end
    of a list of dictionaries, since it will never pass on any token to
    a following dictionary.  Conversely, <literal>Accept</> = <literal>false</>
    is only useful when there is at least one following dictionary.
   </para>
____________________________________________________________________________-->
   <para>
    在使用默认值<literal>Accept</> = <literal>true</>，只有把一个<literal>simple</>词典放在词典列表的尾部才有用，因为它将不会传递任何记号给后续的词典。相反，<literal>Accept</> = <literal>false</>只有当至少有一个后续词典的情况下才有用。
   </para>

   <caution>
<!--==========================orignal english content==========================
    <para>
     Most types of dictionaries rely on configuration files, such as files of
     stop words.  These files <emphasis>must</> be stored in UTF-8 encoding.
     They will be translated to the actual database encoding, if that is
     different, when they are read into the server.
    </para>
____________________________________________________________________________-->
    <para>
     大部分类型的词典依赖于配置文件，例如停用词文件。这些文件<emphasis>必须</>被存储为 UTF-8 编码。当它们被读入服务器时，如果存在不同，它们将被翻译成真实的数据库编码。
    </para>
   </caution>

   <caution>
<!--==========================orignal english content==========================
    <para>
     Normally, a database session will read a dictionary configuration file
     only once, when it is first used within the session.  If you modify a
     configuration file and want to force existing sessions to pick up the
     new contents, issue an <command>ALTER TEXT SEARCH DICTIONARY</> command
     on the dictionary.  This can be a <quote>dummy</> update that doesn't
     actually change any parameter values.
    </para>
____________________________________________________________________________-->
    <para>
     通常，当一个词典配置文件第一次在数据库会话中使用时，数据库会话将只读取它一次。如果你修改了一个配置文件并且想强迫现有的会话取得新内容，可以在该词典上发出一个<command>ALTER TEXT SEARCH DICTIONARY</>命令。这可以是一次<quote>假</>更新，它并不实际修改任何参数值。
    </para>
   </caution>

  </sect2>

  <sect2 id="textsearch-synonym-dictionary">
<!--==========================orignal english content==========================
   <title>Synonym Dictionary</title>
____________________________________________________________________________-->
   <title>同义词词典</title>

<!--==========================orignal english content==========================
   <para>
    This dictionary template is used to create dictionaries that replace a
    word with a synonym. Phrases are not supported (use the thesaurus
    template (<xref linkend="textsearch-thesaurus">) for that).  A synonym
    dictionary can be used to overcome linguistic problems, for example, to
    prevent an English stemmer dictionary from reducing the word <quote>Paris</quote> to
    <quote>pari</quote>.  It is enough to have a <literal>Paris paris</literal> line in the
    synonym dictionary and put it before the <literal>english_stem</>
    dictionary.  For example:

<screen>
SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | Paris | {english_stem} | english_stem | {pari}

CREATE TEXT SEARCH DICTIONARY my_synonym (
    TEMPLATE = synonym,
    SYNONYMS = my_synonyms
);

ALTER TEXT SEARCH CONFIGURATION english
    ALTER MAPPING FOR asciiword
    WITH my_synonym, english_stem;

SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |       dictionaries        | dictionary | lexemes 
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | Paris | {my_synonym,english_stem} | my_synonym | {paris}
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    这个词典模板被用来创建用于同义词替换的词典。不支持短语（使用分类词典模板（<xref linkend="textsearch-thesaurus">）可以支持）。一个同义词词典可以被用来解决语言学问题，例如，阻止一个英语词干分析器词典把词<quote>Paris</quote>缩减成<quote>pari</quote>。在同义词词典中有一行<literal>Paris paris</literal>并把它放在<literal>english_stem</>词典之前就足够了。例如：

<screen>
SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | Paris | {english_stem} | english_stem | {pari}

CREATE TEXT SEARCH DICTIONARY my_synonym (
    TEMPLATE = synonym,
    SYNONYMS = my_synonyms
);

ALTER TEXT SEARCH CONFIGURATION english
    ALTER MAPPING FOR asciiword
    WITH my_synonym, english_stem;

SELECT * FROM ts_debug('english', 'Paris');
   alias   |   description   | token |       dictionaries        | dictionary | lexemes 
-----------+-----------------+-------+---------------------------+------------+---------
 asciiword | Word, all ASCII | Paris | {my_synonym,english_stem} | my_synonym | {paris}
</screen>
   </para>

<!--==========================orignal english content==========================
   <para>
    The only parameter required by the <literal>synonym</> template is
    <literal>SYNONYMS</>, which is the base name of its configuration file
    &mdash; <literal>my_synonyms</> in the above example.
    The file's full name will be
    <filename>$SHAREDIR/tsearch_data/my_synonyms.syn</>
    (where <literal>$SHAREDIR</> means the
    <productname>PostgreSQL</> installation's shared-data directory).
    The file format is just one line
    per word to be substituted, with the word followed by its synonym,
    separated by white space.  Blank lines and trailing spaces are ignored.
   </para>
____________________________________________________________________________-->
   <para>
    <literal>synonym</>模板要求的唯一参数是<literal>SYNONYMS</>，它是其配置文件的基本名 &mdash; 上例中的<literal>my_synonyms</>。该文件的完整名称将是<filename>$SHAREDIR/tsearch_data/my_synonyms.syn</>（其中<literal>$SHAREDIR</>表示<productname>PostgreSQL</>安装的共享数据目录）。该文件格式是每行一个要被替换的词，后面跟着它的同义词，用空白分隔。空行和结尾的空格会被忽略。
   </para>

<!--==========================orignal english content==========================
   <para>
    The <literal>synonym</> template also has an optional parameter
    <literal>CaseSensitive</>, which defaults to <literal>false</>.  When
    <literal>CaseSensitive</> is <literal>false</>, words in the synonym file
    are folded to lower case, as are input tokens.  When it is
    <literal>true</>, words and tokens are not folded to lower case,
    but are compared as-is.
   </para>
____________________________________________________________________________-->
   <para>
    <literal>synonym</>模板还有一个可选的参数<literal>CaseSensitive</>，其默认值为<literal>false</>。当<literal>CaseSensitive</>为<literal>false</>时，同义词文件中的词被折叠成小写，这和输入记号一样。当它为<literal>true</>时，词和记号将不会被折叠成小写，但是比较时就好像被折叠过一样。
   </para>

<!--==========================orignal english content==========================
   <para>
    An asterisk (<literal>*</literal>) can be placed at the end of a synonym
    in the configuration file.  This indicates that the synonym is a prefix.
    The asterisk is ignored when the entry is used in
    <function>to_tsvector()</function>, but when it is used in
    <function>to_tsquery()</function>, the result will be a query item with
    the prefix match marker (see
    <xref linkend="textsearch-parsing-queries">).
    For example, suppose we have these entries in
    <filename>$SHAREDIR/tsearch_data/synonym_sample.syn</>:
<programlisting>
postgres        pgsql
postgresql      pgsql
postgre pgsql
gogle   googl
indices index*
</programlisting>
    Then we will get these results:
<screen>
mydb=# CREATE TEXT SEARCH DICTIONARY syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn','indices');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {index}
(1 row)

mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword WITH syn;
mydb=# SELECT to_tsvector('tst','indices');
 to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'index':1
(1 row)

mydb=# SELECT to_tsquery('tst','indices');
 to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'index':*
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector;
            tsvector             
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'are' 'indexes' 'useful' 'very'
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector @@ to_tsquery('tst','indices');
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
(1 row)
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    一个星号（<literal>*</literal>）可以被放置在配置文件中一个同义词的末尾。这表示该同义词是一个前缀。当项被用在<function>to_tsvector()</function>中时，星号会被忽略；当它被用在<function>to_tsquery()</function>中时，结果将是一个带有前缀匹配标记器（见<xref linkend="textsearch-parsing-queries">）的查询项。例如，假设我们在<filename>$SHAREDIR/tsearch_data/synonym_sample.syn</>中有这些项：
<programlisting>
postgres        pgsql
postgresql      pgsql
postgre pgsql
gogle   googl
indices index*
</programlisting>
    那么我们将得到这些结果：
<screen>
mydb=# CREATE TEXT SEARCH DICTIONARY syn (template=synonym, synonyms='synonym_sample');
mydb=# SELECT ts_lexize('syn','indices');
 ts_lexize
-----------
 {index}
(1 row)

mydb=# CREATE TEXT SEARCH CONFIGURATION tst (copy=simple);
mydb=# ALTER TEXT SEARCH CONFIGURATION tst ALTER MAPPING FOR asciiword WITH syn;
mydb=# SELECT to_tsvector('tst','indices');
 to_tsvector
-------------
 'index':1
(1 row)

mydb=# SELECT to_tsquery('tst','indices');
 to_tsquery
------------
 'index':*
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector;
            tsvector             
---------------------------------
 'are' 'indexes' 'useful' 'very'
(1 row)

mydb=# SELECT 'indexes are very useful'::tsvector @@ to_tsquery('tst','indices');
 ?column?
----------
 t
(1 row)
</screen>
   </para>
  </sect2>

  <sect2 id="textsearch-thesaurus">
<!--==========================orignal english content==========================
   <title>Thesaurus Dictionary</title>
____________________________________________________________________________-->
   <title>分类词典</title>

<!--==========================orignal english content==========================
   <para>
    A thesaurus dictionary (sometimes abbreviated as <acronym>TZ</acronym>) is
    a collection of words that includes information about the relationships
    of words and phrases, i.e., broader terms (<acronym>BT</acronym>), narrower
    terms (<acronym>NT</acronym>), preferred terms, non-preferred terms, related
    terms, etc.
   </para>
____________________________________________________________________________-->
   <para>
    一个分类词典（有时被简写成<acronym>TZ</acronym>）是一个词的集合，其中包括了词与短语之间的联系，即广义词（<acronym>BT</acronym>）、狭义词（<acronym>NT</acronym>）、首选词、非首选词、相关词等。
   </para>

<!--==========================orignal english content==========================
   <para>
    Basically a thesaurus dictionary replaces all non-preferred terms by one
    preferred term and, optionally, preserves the original terms for indexing
    as well.  <productname>PostgreSQL</>'s current implementation of the
    thesaurus dictionary is an extension of the synonym dictionary with added
    <firstterm>phrase</firstterm> support.  A thesaurus dictionary requires
    a configuration file of the following format:

<programlisting>
# this is a comment
sample word(s) : indexed word(s)
more sample word(s) : more indexed word(s)
...
</programlisting>

    where  the colon (<symbol>:</symbol>) symbol acts as a delimiter between a
    phrase and its replacement.
   </para>
____________________________________________________________________________-->
   <para>
    基本上一个分类词典会用一个首选词替换所有非首选词，并且也可选择地保留原始术语用于索引。<productname>PostgreSQL</>的分类词典的当前实现是同义词词典的一个扩展，并增加了<firstterm>短语</firstterm>支持。一个分类词典要求一个下列格式的配置文件：

<programlisting>
# this is a comment
sample word(s) : indexed word(s)
more sample word(s) : more indexed word(s)
...
</programlisting>

    其中冒号（<symbol>:</symbol>）符号扮演了一个短语及其替换之间的定界符。
   </para>

<!--==========================orignal english content==========================
   <para>
    A thesaurus dictionary uses a <firstterm>subdictionary</firstterm> (which
    is specified in the dictionary's configuration) to normalize the input
    text before checking for phrase matches. It is only possible to select one
    subdictionary.  An error is reported if the subdictionary fails to
    recognize a word. In that case, you should remove the use of the word or
    teach the subdictionary about it.  You can place an asterisk
    (<symbol>*</symbol>) at the beginning of an indexed word to skip applying
    the subdictionary to it, but all sample words <emphasis>must</> be known
    to the subdictionary.
   </para>
____________________________________________________________________________-->
   <para>
    一个分类词典使用一个<firstterm>子词典</firstterm>（在词典的配置中指定）在检查短语匹配之前正规化输入文本。只能选择一个子词典。如果子词典无法识别一个词，将报告一个错误。在这种情况下，你应该移除该词的使用或者让子词典学会这个词。你可以在一个被索引词的开头放上一个星号（<symbol>*</symbol>）来跳过在其上应用子词典，但是所有采样词<emphasis>必须</>被子词典知道。
   </para>

<!--==========================orignal english content==========================
   <para>
    The thesaurus dictionary chooses the longest match if there are multiple
    phrases matching the input, and ties are broken by using the last
    definition.
   </para>
____________________________________________________________________________-->
   <para>
    如果有多个短语匹配输入，则分类词典选择最长的那一个，并且使用最后的定义打破连结。
   </para>

<!--==========================orignal english content==========================
   <para>
    Specific stop words recognized by the subdictionary cannot be
    specified;  instead use <literal>?</> to mark the location where any
    stop word can appear.  For example, assuming that <literal>a</> and
    <literal>the</> are stop words according to the subdictionary:

<programlisting>
? one ? two : swsw
</programlisting>

    matches <literal>a one the two</> and <literal>the one a two</>;
    both would be replaced by <literal>swsw</>.
   </para>
____________________________________________________________________________-->
   <para>
    由子词典识别的特定停用词不能够被指定；改用<literal>?</>标记任何可以出现停用词的地方。例如，假定根据子词典<literal>a</>和<literal>the</>是停用词：

<programlisting>
? one ? two : swsw
</programlisting>

    匹配<literal>a one the two</>和<literal>the one a two</>；两者都将被<literal>swsw</>替换。
   </para>

<!--==========================orignal english content==========================
   <para>
    Since a thesaurus dictionary has the capability to recognize phrases it
    must remember its state and interact with the parser. A thesaurus dictionary
    uses these assignments to check if it should handle the next word or stop
    accumulation.  The thesaurus dictionary must be configured
    carefully. For example, if the thesaurus dictionary is assigned to handle
    only the <literal>asciiword</literal> token, then a thesaurus dictionary
    definition like <literal>one 7</> will not work since token type
    <literal>uint</literal> is not assigned to the thesaurus dictionary.
   </para>
____________________________________________________________________________-->
   <para>
    由于一个分类词典具有识别短语的能力，它必须记住它的状态并与解析器交互。一个分类词典使用这些任务来检查它是否应当处理下一个词或者停止累积。分类词典必须被小心地配置。例如，如果分类词典被分配只处理<literal>asciiword</literal>记号，则一个形如<literal>one 7</>的分类词典定义将不会工作，因为记号类型<literal>uint</literal>没有被分配给该分类词典。
   </para>

   <caution>
<!--==========================orignal english content==========================
    <para>
     Thesauruses are used during indexing so any change in the thesaurus
     dictionary's parameters <emphasis>requires</emphasis> reindexing.
     For most other dictionary types, small changes such as adding or
     removing stopwords does not force reindexing.
    </para>
____________________________________________________________________________-->
    <para>
     在索引期间要用到分类词典，因此分类词典参数中的任何变化都<emphasis>要求</emphasis>重索引。对于大多数其他索引类型，例如增加或移除停用词等小改动都不会强制重索引。
    </para>
   </caution>

  <sect3 id="textsearch-thesaurus-config">
<!--==========================orignal english content==========================
   <title>Thesaurus Configuration</title>
____________________________________________________________________________-->
   <title>分类词典配置</title>

<!--==========================orignal english content==========================
   <para>
    To define a new thesaurus dictionary, use the <literal>thesaurus</>
    template.  For example:

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
    TEMPLATE = thesaurus,
    DictFile = mythesaurus,
    Dictionary = pg_catalog.english_stem
);
</programlisting>

    Here:
    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>thesaurus_simple</literal> is the new dictionary's name
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>mythesaurus</literal> is the base name of the thesaurus
       configuration file.
       (Its full name will be <filename>$SHAREDIR/tsearch_data/mythesaurus.ths</>,
       where <literal>$SHAREDIR</> means the installation shared-data
       directory.)
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>pg_catalog.english_stem</literal> is the subdictionary (here,
       a Snowball English stemmer) to use for thesaurus normalization.
       Notice that the subdictionary will have its own
       configuration (for example, stop words), which is not shown here.
      </para>
     </listitem>
    </itemizedlist>

    Now it is possible to bind the thesaurus dictionary <literal>thesaurus_simple</literal>
    to the desired token types in a configuration, for example:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_simple;
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    要定义一个新的分类词典，可使用<literal>thesaurus</>模板。例如：

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_simple (
    TEMPLATE = thesaurus,
    DictFile = mythesaurus,
    Dictionary = pg_catalog.english_stem
);
</programlisting>

    这里：
    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <literal>thesaurus_simple</literal>是新词典的名称
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>mythesaurus</literal>是分类词典配置文件的基础名称（它的全名将是<filename>$SHAREDIR/tsearch_data/mythesaurus.ths</>，其中<literal>$SHAREDIR</>表示安装的共享数据目录）。
      </para>
     </listitem>
     <listitem>
      <para>
       <literal>pg_catalog.english_stem</literal>是要用于分类词典正规化的子词典（这里是一个 Snowball 英语词干分析器）。注意子词典将拥有它自己的配置（例如停用词），但这里没有展示。
      </para>
     </listitem>
    </itemizedlist>

    现在可以在配置中把分类词典<literal>thesaurus_simple</literal>绑定到想要的记号类型上，例如：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_simple;
</programlisting>
   </para>

  </sect3>

  <sect3 id="textsearch-thesaurus-examples">
<!--==========================orignal english content==========================
   <title>Thesaurus Example</title>
____________________________________________________________________________-->
   <title>分类词典例子</title>

<!--==========================orignal english content==========================
   <para>
    Consider a simple astronomical thesaurus <literal>thesaurus_astro</literal>,
    which contains some astronomical word combinations:

<programlisting>
supernovae stars : sn
crab nebulae : crab
</programlisting>

    Below we create a dictionary and bind some token types to
    an astronomical thesaurus and English stemmer:

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
    TEMPLATE = thesaurus,
    DictFile = thesaurus_astro,
    Dictionary = english_stem
);

ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_astro, english_stem;
</programlisting>

    Now we can see how it works.
    <function>ts_lexize</function> is not very useful for testing a thesaurus,
    because it treats its input as a single token.  Instead we can use
    <function>plainto_tsquery</function> and <function>to_tsvector</function>
    which will break their input strings into multiple tokens:

<screen>
SELECT plainto_tsquery('supernova star');
 plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn'

SELECT to_tsvector('supernova star');
 to_tsvector
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn':1
</screen>

    In principle, one can use <function>to_tsquery</function> if you quote
    the argument:

<screen>
SELECT to_tsquery('''supernova star''');
 to_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 'sn'
</screen>

    Notice that <literal>supernova star</literal> matches <literal>supernovae
    stars</literal> in <literal>thesaurus_astro</literal> because we specified
    the <literal>english_stem</literal> stemmer in the thesaurus definition.
    The stemmer removed the <literal>e</> and <literal>s</>.
   </para>
____________________________________________________________________________-->
   <para>
    考虑一个简单的天文学分类词典<literal>thesaurus_astro</literal>，它包含一些天文学词组合：

<programlisting>
supernovae stars : sn
crab nebulae : crab
</programlisting>

    下面我们创建一个词典并绑定一些记号类型到一个天文学分类词典以及英语词干分析器：

<programlisting>
CREATE TEXT SEARCH DICTIONARY thesaurus_astro (
    TEMPLATE = thesaurus,
    DictFile = thesaurus_astro,
    Dictionary = english_stem
);

ALTER TEXT SEARCH CONFIGURATION russian
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart
    WITH thesaurus_astro, english_stem;
</programlisting>

    现在我们可以看看它如何工作。<function>ts_lexize</function>对于测试一个分类词典用处不大，因为它把它的输入看成是一个单一记号。我们可以用<function>plainto_tsquery</function>和<function>to_tsvector</function>，它们将把其输入字符串打断成多个记号：

<screen>
SELECT plainto_tsquery('supernova star');
 plainto_tsquery
-----------------
 'sn'

SELECT to_tsvector('supernova star');
 to_tsvector
-------------
 'sn':1
</screen>

    原则上，如果你对参数加了引号，你可以使用<function>to_tsquery</function>：

<screen>
SELECT to_tsquery('''supernova star''');
 to_tsquery
------------
 'sn'
</screen>

    注意在<literal>thesaurus_astro</literal>中<literal>supernova star</literal>匹配<literal>supernovae stars</literal>，因为我们在分类词典定义中指定了<literal>english_stem</literal>词干分析器。该词干分析器移除了<literal>e</>和<literal>s</>。
   </para>

<!--==========================orignal english content==========================
   <para>
    To index the original phrase as well as the substitute, just include it
    in the right-hand part of the definition:

<screen>
supernovae stars : sn supernovae stars

SELECT plainto_tsquery('supernova star');
       plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn' &amp; 'supernova' &amp; 'star'
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    要和替补一样也索引原始短语，只要将它包含在定义的右手部分中：

<screen>
supernovae stars : sn supernovae stars

SELECT plainto_tsquery('supernova star');
       plainto_tsquery
-----------------------------
 'sn' &amp; 'supernova' &amp; 'star'
</screen>
   </para>

  </sect3>

  </sect2>

  <sect2 id="textsearch-ispell-dictionary">
<!--==========================orignal english content==========================
   <title><application>Ispell</> Dictionary</title>
____________________________________________________________________________-->
   <title><application>Ispell</> 词典</title>

<!--==========================orignal english content==========================
   <para>
    The <application>Ispell</> dictionary template supports
    <firstterm>morphological dictionaries</>, which can normalize many
    different linguistic forms of a word into the same lexeme.  For example,
    an English <application>Ispell</> dictionary can match all declensions and
    conjugations of the search term <literal>bank</literal>, e.g.,
    <literal>banking</>, <literal>banked</>, <literal>banks</>,
    <literal>banks'</>, and <literal>bank's</>.
   </para>
____________________________________________________________________________-->
   <para>
    <application>Ispell</>词典模板支持<firstterm>词法词典</>，它可以把一个词的很多不同语言学的形式正规化成相同的词位。例如，一个英语<application>Ispell</>词典可以匹配搜索词<literal>bank</literal>的词尾变化和词形变化，例如<literal>banking</>、<literal>banked</>、<literal>banks</>、<literal>banks'</>和<literal>bank's</>。
   </para>

<!--==========================orignal english content==========================
   <para>
    The standard <productname>PostgreSQL</productname> distribution does
    not include any <application>Ispell</> configuration files.
    Dictionaries for a large number of languages are available from <ulink
    url="http://ficus-www.cs.ucla.edu/geoff/ispell.html">Ispell</ulink>.
    Also, some more modern dictionary file formats are supported &mdash; <ulink
    url="http://en.wikipedia.org/wiki/MySpell">MySpell</ulink> (OO &lt; 2.0.1)
    and <ulink url="http://sourceforge.net/projects/hunspell/">Hunspell</ulink>
    (OO &gt;= 2.0.2).  A large list of dictionaries is available on the <ulink
    url="http://wiki.services.openoffice.org/wiki/Dictionaries">OpenOffice
    Wiki</ulink>.
   </para>
____________________________________________________________________________-->
   <para>
    标准的<productname>PostgreSQL</productname>发布不包括任何<application>Ispell</>配置文件。用于很多种语言的词典可以从<ulink url="http://ficus-www.cs.ucla.edu/geoff/ispell.html">Ispell</ulink>得到。此外，也支持一些更现代的词典文件格式 &mdash; <ulink url="http://en.wikipedia.org/wiki/MySpell">MySpell</ulink>（OO &lt; 2.0.1）和<ulink url="http://sourceforge.net/projects/hunspell/">Hunspell</ulink>（OO &gt;= 2.0.2）。一个很大的词典列表在<ulink url="http://wiki.services.openoffice.org/wiki/Dictionaries">OpenOffice Wiki</ulink>上可以得到。
   </para>

<!--==========================orignal english content==========================
   <para>
    To create an <application>Ispell</> dictionary perform these steps:
   </para>
____________________________________________________________________________-->
   <para>
    要创建一个<application>Ispell</>词典，执行这三步：
   </para>
   <itemizedlist spacing="compact" mark="bullet">
    <listitem>
<!--==========================orignal english content==========================
     <para>
      download dictionary configuration files. <productname>OpenOffice</>
      extension files have the <filename>.oxt</> extension. It is necessary
      to extract <filename>.aff</> and <filename>.dic</> files, change
      extensions to <filename>.affix</> and <filename>.dict</>. For some
      dictionary files it is also needed to convert characters to the UTF-8
      encoding with commands (for example, for a Norwegian language dictionary):
<programlisting>
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
</programlisting>
     </para>
____________________________________________________________________________-->
     <para>
      下载词典配置文件。<productname>OpenOffice</>扩展文件的扩展名是<filename>.oxt</>。有必要抽取<filename>.aff</>和<filename>.dic</>文件，把扩展改为<filename>.affix</>和<filename>.dict</>。对于某些词典文件，还需要使用下面的命令把字符转换成 UTF-8 编码（例如挪威语词典）：
<programlisting>
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.affix nn_NO.aff
iconv -f ISO_8859-1 -t UTF-8 -o nn_no.dict nn_NO.dic
</programlisting>
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      copy files to the <filename>$SHAREDIR/tsearch_data</> directory
     </para>
____________________________________________________________________________-->
     <para>
      拷贝文件到<filename>$SHAREDIR/tsearch_data</>目录
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      load files into PostgreSQL with the following command:
<programlisting>
CREATE TEXT SEARCH DICTIONARY english_hunspell (
    TEMPLATE = ispell,
    DictFile = en_us,
    AffFile = en_us,
    Stopwords = english);
</programlisting>
     </para>
____________________________________________________________________________-->
     <para>
      用下面的命令把文件载入到 PostgreSQL：
<programlisting>
CREATE TEXT SEARCH DICTIONARY english_hunspell (
    TEMPLATE = ispell,
    DictFile = en_us,
    AffFile = en_us,
    Stopwords = english);
</programlisting>
     </para>
    </listitem>
   </itemizedlist>

<!--==========================orignal english content==========================
   <para>
    Here, <literal>DictFile</>, <literal>AffFile</>, and <literal>StopWords</>
    specify the base names of the dictionary, affixes, and stop-words files.
    The stop-words file has the same format explained above for the
    <literal>simple</> dictionary type.  The format of the other files is
    not specified here but is available from the above-mentioned web sites.
   </para>
____________________________________________________________________________-->
   <para>
    这里，<literal>DictFile</>、<literal>AffFile</>和<literal>StopWords</>指定词典、词缀和停用词文件的基础名称。停用词文件的格式和前面解释的<literal>simple</>词典类型相同。其他文件的格式在这里没有指定，但是也可以从上面提到的网站获得。
   </para>

<!--==========================orignal english content==========================
   <para>
    Ispell dictionaries usually recognize a limited set of words, so they
    should be followed by another broader dictionary; for
    example, a Snowball dictionary, which recognizes everything.
   </para>
____________________________________________________________________________-->
   <para>
    Ispell 词典通常识别一个有限集合的词，这样它们后面应该跟着另一个更广义的词典；例如，一个 Snowball 词典，它可以识别所有东西。
   </para>
   
<!--==========================orignal english content==========================
   <para>
    The <filename>.affix</> file of <application>Ispell</> has the following
    structure:
<programlisting>
prefixes
flag *A:
    .           >   RE      # As in enter > reenter
suffixes
flag T:
    E           >   ST      # As in late > latest
    [^AEIOU]Y   >   -Y,IEST # As in dirty > dirtiest
    [AEIOU]Y    >   EST     # As in gray > grayest
    [^EY]       >   EST     # As in small > smallest
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <application>Ispell</>的<filename>.affix</>文件具有下面的结构：
<programlisting>
prefixes
flag *A:
    .           >   RE      # As in enter > reenter
suffixes
flag T:
    E           >   ST      # As in late > latest
    [^AEIOU]Y   >   -Y,IEST # As in dirty > dirtiest
    [AEIOU]Y    >   EST     # As in gray > grayest
    [^EY]       >   EST     # As in small > smallest
</programlisting>
   </para>
<!--==========================orignal english content==========================
   <para>
    And the <filename>.dict</> file has the following structure:
<programlisting>
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <filename>.dict</>文件具有下面的结构：
<programlisting>
lapse/ADGRS
lard/DGRS
large/PRTY
lark/MRS
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    Format of the <filename>.dict</> file is:
<programlisting>
basic_form/affix_class_name
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <filename>.dict</>文件的格式是：
<programlisting>
basic_form/affix_class_name
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    In the <filename>.affix</> file every affix flag is described in the
    following format:
<programlisting>
condition > [-stripping_letters,] adding_affix
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    在<filename>.affix</>文件中，每一个词缀标志以下面的格式描述：
<programlisting>
condition > [-stripping_letters,] adding_affix
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    Here, condition has a format similar to the format of regular expressions.
    It can use groupings <literal>[...]</> and <literal>[^...]</>.
    For example, <literal>[AEIOU]Y</> means that the last letter of the word
    is <literal>"y"</> and the penultimate letter is <literal>"a"</>,
    <literal>"e"</>, <literal>"i"</>, <literal>"o"</> or <literal>"u"</>.
    <literal>[^EY]</> means that the last letter is neither <literal>"e"</>
    nor <literal>"y"</>.
   </para>
____________________________________________________________________________-->
   <para>
    这里的条件具有和正则表达式相似的格式。它可以使用分组<literal>[...]</>和<literal>[^...]</>。例如，<literal>[AEIOU]Y</>表示词的最后一个字母是<literal>"y"</>并且倒数第二个字母是<literal>"a"</>、<literal>"e"</>、<literal>"i"</>、<literal>"o"</>或者<literal>"u"</>。<literal>[^EY]</>表示最后一个字母既不是<literal>"e"</>也不是<literal>"y"</>。
   </para>

<!--==========================orignal english content==========================
   <para>
    Ispell dictionaries support splitting compound words;
    a useful feature.
    Notice that the affix file should specify a special flag using the
    <literal>compoundwords controlled</literal> statement that marks dictionary
    words that can participate in compound formation:

<programlisting>
compoundwords  controlled z
</programlisting>

    Here are some examples for the Norwegian language:

<programlisting>
SELECT ts_lexize('norwegian_ispell', 'overbuljongterningpakkmesterassistent');
   {over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
   {sjokoladefabrikk,sjokolade,fabrikk}
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    Ispell 词典支持划分复合词，这是一个有用的特性。注意词缀文件应该用<literal>compoundwords controlled</literal>语句指定一个特殊标志，它标记可以参与到复合格式中的词典词：

<programlisting>
compoundwords  controlled z
</programlisting>

    下面是挪威语的一些例子：

<programlisting>
SELECT ts_lexize('norwegian_ispell', 'overbuljongterningpakkmesterassistent');
   {over,buljong,terning,pakk,mester,assistent}
SELECT ts_lexize('norwegian_ispell', 'sjokoladefabrikk');
   {sjokoladefabrikk,sjokolade,fabrikk}
</programlisting>
   </para>
   
<!--==========================orignal english content==========================
   <para>
    <application>MySpell</> format is a subset of <application>Hunspell</>.
    The <filename>.affix</> file of <application>Hunspell</> has the following
    structure:
<programlisting>
PFX A Y 1
PFX A   0     re         .
SFX T N 4
SFX T   0     st         e
SFX T   y     iest       [^aeiou]y
SFX T   0     est        [aeiou]y
SFX T   0     est        [^ey]
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <application>MySpell</>格式是<application>Hunspell</>格式的一个子集。<application>Hunspell</>的<filename>.affix</>文件具有下面的结构：
<programlisting>
PFX A Y 1
PFX A   0     re         .
SFX T N 4
SFX T   0     st         e
SFX T   y     iest       [^aeiou]y
SFX T   0     est        [aeiou]y
SFX T   0     est        [^ey]
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    The first line of an affix class is the header. Fields of an affix rules are
    listed after the header:
   </para>
____________________________________________________________________________-->
   <para>
    一个词缀类的第一行是头部。头部后面列出了词缀规则的域：
   </para>
   <itemizedlist spacing="compact" mark="bullet">
    <listitem>
<!--==========================orignal english content==========================
     <para>
      parameter name (PFX or SFX)
     </para>
____________________________________________________________________________-->
     <para>
      参数名（PFX 或者 SFX）
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      flag (name of the affix class)
     </para>
____________________________________________________________________________-->
     <para>
      标志（词缀类的名称）
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      stripping characters from beginning (at prefix) or end (at suffix) of the
      word
     </para>
____________________________________________________________________________-->
     <para>
      从该词的开始（前缀）或者结尾（后缀）剥离字符
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      adding affix
     </para>
____________________________________________________________________________-->
     <para>
      增加词缀
     </para>
    </listitem>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      condition that has a format similar to the format of regular expressions.
     </para>
____________________________________________________________________________-->
     <para>
      和正则表达式格式类似的条件。
     </para>
    </listitem>
   </itemizedlist>

<!--==========================orignal english content==========================
   <para>
    The <filename>.dict</> file looks like the <filename>.dict</> file of
    <application>Ispell</>:
<programlisting>
larder/M
lardy/RT
large/RSPMYT
largehearted
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    <filename>.dict</>文件看起来和<application>Ispell</>的<filename>.dict</>文件相似：
<programlisting>
larder/M
lardy/RT
large/RSPMYT
largehearted
</programlisting>
   </para>

   <note>
<!--==========================orignal english content==========================
    <para>
     <application>MySpell</> does not support compound words.
     <application>Hunspell</> has sophisticated support for compound words. At
     present, <productname>PostgreSQL</productname> implements only the basic
     compound word operations of Hunspell.
    </para>
____________________________________________________________________________-->
    <para>
     <application>MySpell</> 不支持复合词。<application>Hunspell</>则对复合词有更好的支持。当前，<productname>PostgreSQL</productname>只实现了 Hunspell 中基本的复合词操作。
    </para>
   </note>

  </sect2>

  <sect2 id="textsearch-snowball-dictionary">
<!--==========================orignal english content==========================
   <title><application>Snowball</> Dictionary</title>
____________________________________________________________________________-->
   <title><application>Snowball</> 词典</title>

<!--==========================orignal english content==========================
   <para>
    The <application>Snowball</> dictionary template is based on a project
    by Martin Porter, inventor of the popular Porter's stemming algorithm
    for the English language.  Snowball now provides stemming algorithms for
    many languages (see the <ulink url="http://snowballstem.org/">Snowball
    site</ulink> for more information).  Each algorithm understands how to
    reduce common variant forms of words to a base, or stem, spelling within
    its language.  A Snowball dictionary requires a <literal>language</>
    parameter to identify which stemmer to use, and optionally can specify a
    <literal>stopword</> file name that gives a list of words to eliminate.
    (<productname>PostgreSQL</productname>'s standard stopword lists are also
    provided by the Snowball project.)
    For example, there is a built-in definition equivalent to

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_stem (
    TEMPLATE = snowball,
    Language = english,
    StopWords = english
);
</programlisting>

    The stopword file format is the same as already explained.
   </para>
____________________________________________________________________________-->
   <para>
    <application>Snowball</>词典模板基于 Martin Porter 的一个项目，他是流行的英语 Porter 词干分析算法的发明者。Snowball 现在对许多语言提供词干分析算法（详见<ulink url="http://snowballstem.org/">Snowball 站点</ulink>）。每一个算法懂得按照其语言中的拼写，如何缩减词的常见变体形式为一个基础或词干。一个 Snowball 词典要求一个<literal>language</>参数来标识要用哪种词干分析器，并且可以选择地指定一个<literal>stopword</>文件名来给出一个要被消除的词列表（<productname>PostgreSQL</productname>的标准停用词列表也是由 Snowball 项目提供的）。例如，有一个内建的定义等效于

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_stem (
    TEMPLATE = snowball,
    Language = english,
    StopWords = english
);
</programlisting>

    停用词文件格式和已经解释的一样。
   </para>

<!--==========================orignal english content==========================
   <para>
    A <application>Snowball</> dictionary recognizes everything, whether
    or not it is able to simplify the word, so it should be placed
    at the end of the dictionary list. It is useless to have it
    before any other dictionary because a token will never pass through it to
    the next dictionary.
   </para>
____________________________________________________________________________-->
   <para>
    一个<application>Snowball</>词典识别所有的东西，不管它能不能简化该词，因此它应当被放置在词典列表的最后。把它放在任何其他词典前面是没有用处的，因为一个记号永远不会穿过它而进入到下一个词典。
   </para>

  </sect2>

 </sect1>

 <sect1 id="textsearch-configuration">
<!--==========================orignal english content==========================
  <title>Configuration Example</title>
____________________________________________________________________________-->
  <title>配置例子</title>

<!--==========================orignal english content==========================
   <para>
    A text search configuration specifies all options necessary to transform a
    document into a <type>tsvector</type>: the parser to use to break text
    into tokens, and the dictionaries to use to transform each token into a
    lexeme.  Every call of
    <function>to_tsvector</function> or <function>to_tsquery</function>
    needs a text search configuration to perform its processing.
    The configuration parameter
    <xref linkend="guc-default-text-search-config">
    specifies the name of the default configuration, which is the
    one used by text search functions if an explicit configuration
    parameter is omitted.
    It can be set in <filename>postgresql.conf</filename>, or set for an
    individual session using the <command>SET</> command.
   </para>
____________________________________________________________________________-->
   <para>
    一个文本搜索配置指定了将一个文档转换成一个<type>tsvector</type>所需的所有选项：用于把文本分解成记号的解析器，以及用于将每一个记号转换成词位的词典。每一次<function>to_tsvector</function>或<function>to_tsquery</function>的调用都需要一个文本搜索配置来执行其处理。配置参数<xref linkend="guc-default-text-search-config">指定了默认配置的名称，如果忽略了显式的配置参数，文本搜索函数将会使用它。它可以在<filename>postgresql.conf</filename>中设置，或者使用<command>SET</>命令为一个单独的会话设置。
   </para>

<!--==========================orignal english content==========================
   <para>
    Several predefined text search configurations are available, and
    you can create custom configurations easily.  To facilitate management
    of text search objects, a set of <acronym>SQL</acronym> commands
    is available, and there are several <application>psql</application> commands that display information
    about text search objects (<xref linkend="textsearch-psql">).
   </para>
____________________________________________________________________________-->
   <para>
    有一些预定义的文本搜索配置可用，并且你可以容易地创建自定义的配置。为了便于管理文本搜索对象，可以使用一组<acronym>SQL</acronym>命令，并且有多个<application>psql</application>命令可以显示有关文本搜索对象（<xref linkend="textsearch-psql">）的信息。
   </para>

<!--==========================orignal english content==========================
   <para>
    As an example we will create a configuration
    <literal>pg</literal>, starting by duplicating the built-in
    <literal>english</> configuration:

<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.pg ( COPY = pg_catalog.english );
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    作为一个例子，我们将创建一个配置<literal>pg</literal>，从复制内建的<literal>english</>配置开始：

<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.pg ( COPY = pg_catalog.english );
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    We will use a PostgreSQL-specific synonym list
    and store it in <filename>$SHAREDIR/tsearch_data/pg_dict.syn</filename>.
    The file contents look like:

<programlisting>
postgres    pg
pgsql       pg
postgresql  pg
</programlisting>

    We define the synonym dictionary like this:

<programlisting>
CREATE TEXT SEARCH DICTIONARY pg_dict (
    TEMPLATE = synonym,
    SYNONYMS = pg_dict
);
</programlisting>

    Next we register the <productname>Ispell</> dictionary
    <literal>english_ispell</literal>, which has its own configuration files:

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);
</programlisting>

    Now we can set up the mappings for words in configuration
    <literal>pg</>:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart,
                      word, hword, hword_part
    WITH pg_dict, english_ispell, english_stem;
</programlisting>

    We choose not to index or search some token types that the built-in
    configuration does handle:

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    DROP MAPPING FOR email, url, url_path, sfloat, float;
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    我们将使用一个 PostgreSQL 相关的同义词列表，并将它存储在<filename>$SHAREDIR/tsearch_data/pg_dict.syn</filename>中。文件内容看起来像：

<programlisting>
postgres    pg
pgsql       pg
postgresql  pg
</programlisting>

    我们定义同义词词典如下：

<programlisting>
CREATE TEXT SEARCH DICTIONARY pg_dict (
    TEMPLATE = synonym,
    SYNONYMS = pg_dict
);
</programlisting>

    接下来我们注册<productname>Ispell</>词典<literal>english_ispell</literal>，它有其自己的配置文件：

<programlisting>
CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);
</programlisting>

    现在我们可以在配置<literal>pg</>中建立词的映射：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    ALTER MAPPING FOR asciiword, asciihword, hword_asciipart,
                      word, hword, hword_part
    WITH pg_dict, english_ispell, english_stem;
</programlisting>

    我们选择不索引或搜索某些内建配置确实处理的记号类型：

<programlisting>
ALTER TEXT SEARCH CONFIGURATION pg
    DROP MAPPING FOR email, url, url_path, sfloat, float;
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    Now we can test our configuration:

<programlisting>
SELECT * FROM ts_debug('public.pg', '
PostgreSQL, the highly scalable, SQL compliant, open source object-relational
database management system, is now undergoing beta testing of the next
version of our software.
');
</programlisting>
   </para>
____________________________________________________________________________-->
   <para>
    现在我们可以测试我们的配置：

<programlisting>
SELECT * FROM ts_debug('public.pg', '
PostgreSQL, the highly scalable, SQL compliant, open source object-relational
database management system, is now undergoing beta testing of the next
version of our software.
');
</programlisting>
   </para>

<!--==========================orignal english content==========================
   <para>
    The next step is to set the session to use the new configuration, which was
    created in the <literal>public</> schema:

<screen>
=&gt; \dF
   List of text search configurations
 Schema  | Name | Description
-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 public  | pg   |

SET default_text_search_config = 'public.pg';
SET

SHOW default_text_search_config;
 default_text_search_config
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 public.pg
</screen>
  </para>
____________________________________________________________________________-->
   <para>
    下一个步骤是设置会话让它使用新配置，它被创建在<literal>public</>模式中：

<screen>
=&gt; \dF
   List of text search configurations
 Schema  | Name | Description
---------+------+-------------
 public  | pg   |

SET default_text_search_config = 'public.pg';
SET

SHOW default_text_search_config;
 default_text_search_config
----------------------------
 public.pg
</screen>
  </para>

 </sect1>

 <sect1 id="textsearch-debugging">
<!--==========================orignal english content==========================
  <title>Testing and Debugging Text Search</title>
____________________________________________________________________________-->
  <title>测试和调试文本搜索</title>

<!--==========================orignal english content==========================
  <para>
   The behavior of a custom text search configuration can easily become
   confusing.  The functions described
   in this section are useful for testing text search objects.  You can
   test a complete configuration, or test parsers and dictionaries separately.
  </para>
____________________________________________________________________________-->
  <para>
   一个自定义文本搜索配置的行为很容易变得混乱。本节中描述的函数对于测试文本搜索对象有用。你可以测试一个完整的配置，或者独立测试解析器和词典。
  </para>

  <sect2 id="textsearch-configuration-testing">
<!--==========================orignal english content==========================
   <title>Configuration Testing</title>
____________________________________________________________________________-->
   <title>配置测试</title>

<!--==========================orignal english content==========================
  <para>
   The function <function>ts_debug</function> allows easy testing of a
   text search configuration.
  </para>
____________________________________________________________________________-->
  <para>
   函数<function>ts_debug</function>允许简单地测试一个文本搜索配置。
  </para>

<!--==========================orignal english content==========================
  <indexterm>
   <primary>ts_debug</primary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm>
   <primary>ts_debug</primary>
  </indexterm>

<!--==========================orignal english content==========================
<synopsis>
ts_debug(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">alias</> <type>text</>,
         OUT <replaceable class="PARAMETER">description</> <type>text</>,
         OUT <replaceable class="PARAMETER">token</> <type>text</>,
         OUT <replaceable class="PARAMETER">dictionaries</> <type>regdictionary[]</>,
         OUT <replaceable class="PARAMETER">dictionary</> <type>regdictionary</>,
         OUT <replaceable class="PARAMETER">lexemes</> <type>text[]</>)
         returns setof record
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_debug(<optional> <replaceable class="PARAMETER">config</replaceable> <type>regconfig</>, </optional> <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">alias</> <type>text</>,
         OUT <replaceable class="PARAMETER">description</> <type>text</>,
         OUT <replaceable class="PARAMETER">token</> <type>text</>,
         OUT <replaceable class="PARAMETER">dictionaries</> <type>regdictionary[]</>,
         OUT <replaceable class="PARAMETER">dictionary</> <type>regdictionary</>,
         OUT <replaceable class="PARAMETER">lexemes</> <type>text[]</>)
         returns setof record
</synopsis>

<!--==========================orignal english content==========================
  <para>
   <function>ts_debug</> displays information about every token of
   <replaceable class="PARAMETER">document</replaceable> as produced by the
   parser and processed by the configured dictionaries.  It uses the
   configuration specified by <replaceable
   class="PARAMETER">config</replaceable>,
   or <varname>default_text_search_config</varname> if that argument is
   omitted.
  </para>
____________________________________________________________________________-->
  <para>
   <function>ts_debug</>显示<replaceable class="PARAMETER">document</replaceable>的每一个记号的信息，记号由解析器产生并由配置的词典处理过。该函数使用由<replaceable class="PARAMETER">config</replaceable>指定的配置，如果该参数被忽略则使用<varname>default_text_search_config</varname>指定的配置。
  </para>

<!--==========================orignal english content==========================
  <para>
   <function>ts_debug</> returns one row for each token identified in the text
   by the parser.  The columns returned are

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>alias</> <type>text</> &mdash; short name of the token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>description</> <type>text</> &mdash; description of the
       token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>token</> <type>text</> &mdash; text of the token
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionaries</> <type>regdictionary[]</> &mdash; the
       dictionaries selected by the configuration for this token type
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionary</> <type>regdictionary</> &mdash; the dictionary
       that recognized the token, or <literal>NULL</> if none did
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>lexemes</> <type>text[]</> &mdash; the lexeme(s) produced
       by the dictionary that recognized the token, or <literal>NULL</> if
       none did; an empty array (<literal>{}</>) means it was recognized as a
       stop word
      </para>
     </listitem>
    </itemizedlist>
  </para>
____________________________________________________________________________-->
  <para>
   <function>ts_debug</>为解析器在文本中标识的每一个记号返回一行。被返回的列是：

    <itemizedlist  spacing="compact" mark="bullet">
     <listitem>
      <para>
       <replaceable>alias</> <type>text</> &mdash; 记号类型的短名称
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>description</> <type>text</> &mdash; 记号类型的描述
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>token</> <type>text</> &mdash; 记号的文本
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionaries</> <type>regdictionary[]</> &mdash; 配置为这种记号类型选择的词典
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>dictionary</> <type>regdictionary</> &mdash; 识别该记号的词典，如果没有词典能识别则为<literal>NULL</>
      </para>
     </listitem>
     <listitem>
      <para>
       <replaceable>lexemes</> <type>text[]</> &mdash; 识别该记号的词典产生的词位，如果没有词典能识别则为<literal>NULL</>；一个空数组（<literal>{}</>）表示该记号被识别为一个停用词
      </para>
     </listitem>
    </itemizedlist>
  </para>

<!--==========================orignal english content==========================
  <para>
   Here is a simple example:

<screen>
SELECT * FROM ts_debug('english','a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              | 
 blank     | Space symbols   | -     | {}             |              | 
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}
</screen>
  </para>
____________________________________________________________________________-->
  <para>
   这里是一个简单的例子：

<screen>
SELECT * FROM ts_debug('english','a fat  cat sat on a mat - it ate a fat rats');
   alias   |   description   | token |  dictionaries  |  dictionary  | lexemes 
-----------+-----------------+-------+----------------+--------------+---------
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | cat   | {english_stem} | english_stem | {cat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | sat   | {english_stem} | english_stem | {sat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | on    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | mat   | {english_stem} | english_stem | {mat}
 blank     | Space symbols   |       | {}             |              | 
 blank     | Space symbols   | -     | {}             |              | 
 asciiword | Word, all ASCII | it    | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | ate   | {english_stem} | english_stem | {ate}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | a     | {english_stem} | english_stem | {}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | fat   | {english_stem} | english_stem | {fat}
 blank     | Space symbols   |       | {}             |              | 
 asciiword | Word, all ASCII | rats  | {english_stem} | english_stem | {rat}
</screen>
  </para>

<!--==========================orignal english content==========================
  <para>
   For a more extensive demonstration, we
   first create a <literal>public.english</literal> configuration and
   Ispell dictionary for the English language:
  </para>
____________________________________________________________________________-->
  <para>
   为了一个更广泛的示范，我们先为英语语言创建一个<literal>public.english</literal>配置和 Ispell 词典：
  </para>

<!--==========================orignal english content==========================
<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
</programlisting>
____________________________________________________________________________-->
<programlisting>
CREATE TEXT SEARCH CONFIGURATION public.english ( COPY = pg_catalog.english );

CREATE TEXT SEARCH DICTIONARY english_ispell (
    TEMPLATE = ispell,
    DictFile = english,
    AffFile = english,
    StopWords = english
);

ALTER TEXT SEARCH CONFIGURATION public.english
   ALTER MAPPING FOR asciiword WITH english_ispell, english_stem;
</programlisting>

<!--==========================orignal english content==========================
<screen>
SELECT * FROM ts_debug('public.english','The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes   
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}
</screen>
____________________________________________________________________________-->
<screen>
SELECT * FROM ts_debug('public.english','The Brightest supernovaes');
   alias   |   description   |    token    |         dictionaries          |   dictionary   |   lexemes   
-----------+-----------------+-------------+-------------------------------+----------------+-------------
 asciiword | Word, all ASCII | The         | {english_ispell,english_stem} | english_ispell | {}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | Brightest   | {english_ispell,english_stem} | english_ispell | {bright}
 blank     | Space symbols   |             | {}                            |                | 
 asciiword | Word, all ASCII | supernovaes | {english_ispell,english_stem} | english_stem   | {supernova}
</screen>

<!--==========================orignal english content==========================
  <para>
   In this example, the word <literal>Brightest</> was recognized by the
   parser as an <literal>ASCII word</literal> (alias <literal>asciiword</literal>).
   For this token type the dictionary list is
   <literal>english_ispell</> and
   <literal>english_stem</literal>. The word was recognized by
   <literal>english_ispell</literal>, which reduced it to the noun
   <literal>bright</literal>. The word <literal>supernovaes</literal> is
   unknown to the <literal>english_ispell</literal> dictionary so it
   was passed to the next dictionary, and, fortunately, was recognized (in
   fact, <literal>english_stem</literal> is a Snowball dictionary which
   recognizes everything; that is why it was placed at the end of the
   dictionary list).
  </para>
____________________________________________________________________________-->
  <para>
   在这个例子中，词<literal>Brightest</>被解析器识别为一个<literal>ASCII 词</literal>（别名<literal>asciiword</literal>）。对于这种记号类型，词典列表是<literal>english_ispell</>和<literal>english_stem</literal>。该词被<literal>english_ispell</literal>识别，这个词典将它缩减为名词<literal>bright</literal>。词<literal>supernovaes</literal>对于<literal>english_ispell</literal>词典是未知的，因此它被传递给下一个词典，并且幸运地是，它被识别了（实际上，<literal>english_stem</literal>是一个 Snowball 词典，它识别所有的东西；这也是为什么它被放置在词典列表的尾部）。
  </para>

<!--==========================orignal english content==========================
  <para>
   The word <literal>The</literal> was recognized by the
   <literal>english_ispell</literal> dictionary as a stop word (<xref
   linkend="textsearch-stopwords">) and will not be indexed.
   The spaces are discarded too, since the configuration provides no
   dictionaries at all for them.
  </para>
____________________________________________________________________________-->
  <para>
   词<literal>The</literal>被<literal>english_ispell</literal>词典识别为一个停用词（<xref linkend="textsearch-stopwords">）并且将不会被索引。空格也被丢弃，因为该配置没有为它们提供词典。
  </para>

<!--==========================orignal english content==========================
  <para>
   You can reduce the width of the output by explicitly specifying which columns
   you want to see:

<screen>
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english','The Brightest supernovaes');
   alias   |    token    |   dictionary   |   lexemes   
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 asciiword | The         | english_ispell | {}
 blank     |             |                | 
 asciiword | Brightest   | english_ispell | {bright}
 blank     |             |                | 
 asciiword | supernovaes | english_stem   | {supernova}
</screen>
  </para>
____________________________________________________________________________-->
  <para>
   你可以通过显式地指定你想看哪些列来缩减输出的宽度：

<screen>
SELECT alias, token, dictionary, lexemes
FROM ts_debug('public.english','The Brightest supernovaes');
   alias   |    token    |   dictionary   |   lexemes   
-----------+-------------+----------------+-------------
 asciiword | The         | english_ispell | {}
 blank     |             |                | 
 asciiword | Brightest   | english_ispell | {bright}
 blank     |             |                | 
 asciiword | supernovaes | english_stem   | {supernova}
</screen>
  </para>

  </sect2>

  <sect2 id="textsearch-parser-testing">
<!--==========================orignal english content==========================
   <title>Parser Testing</title>
____________________________________________________________________________-->
   <title>解析器测试</title>

<!--==========================orignal english content==========================
  <para>
   The following functions allow direct testing of a text search parser.
  </para>
____________________________________________________________________________-->
  <para>
   下列函数允许直接测试一个文本搜索解析器。
  </para>

<!--==========================orignal english content==========================
  <indexterm>
   <primary>ts_parse</primary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm>
   <primary>ts_parse</primary>
  </indexterm>

<!--==========================orignal english content==========================
<synopsis>
ts_parse(<replaceable class="PARAMETER">parser_name</replaceable> <type>text</>, <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">tokid</> <type>integer</>, OUT <replaceable class="PARAMETER">token</> <type>text</>) returns <type>setof record</>
ts_parse(<replaceable class="PARAMETER">parser_oid</replaceable> <type>oid</>, <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">tokid</> <type>integer</>, OUT <replaceable class="PARAMETER">token</> <type>text</>) returns <type>setof record</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_parse(<replaceable class="PARAMETER">parser_name</replaceable> <type>text</>, <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">tokid</> <type>integer</>, OUT <replaceable class="PARAMETER">token</> <type>text</>) returns <type>setof record</>
ts_parse(<replaceable class="PARAMETER">parser_oid</replaceable> <type>oid</>, <replaceable class="PARAMETER">document</replaceable> <type>text</>,
         OUT <replaceable class="PARAMETER">tokid</> <type>integer</>, OUT <replaceable class="PARAMETER">token</> <type>text</>) returns <type>setof record</>
</synopsis>

<!--==========================orignal english content==========================
  <para>
   <function>ts_parse</> parses the given <replaceable>document</replaceable>
   and returns a series of records, one for each token produced by
   parsing. Each record includes a <varname>tokid</varname> showing the
   assigned token type and a <varname>token</varname> which is the text of the
   token.  For example:

<screen>
SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number
</screen>
  </para>
____________________________________________________________________________-->
  <para>
   <function>ts_parse</>解析给定的<replaceable>document</replaceable>并返回一系列记录，每一个记录对应一个由解析产生的记号。每一个记录包括一个<varname>tokid</varname>展示分配给记号的类型以及一个<varname>token</varname>展示记号的文本。例如：

<screen>
SELECT * FROM ts_parse('default', '123 - a number');
 tokid | token
-------+--------
    22 | 123
    12 |
    12 | -
     1 | a
    12 |
     1 | number
</screen>
  </para>

<!--==========================orignal english content==========================
  <indexterm>
   <primary>ts_token_type</primary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm>
   <primary>ts_token_type</primary>
  </indexterm>

<!--==========================orignal english content==========================
<synopsis>
ts_token_type(<replaceable class="PARAMETER">parser_name</> <type>text</>, OUT <replaceable class="PARAMETER">tokid</> <type>integer</>,
              OUT <replaceable class="PARAMETER">alias</> <type>text</>, OUT <replaceable class="PARAMETER">description</> <type>text</>) returns <type>setof record</>
ts_token_type(<replaceable class="PARAMETER">parser_oid</> <type>oid</>, OUT <replaceable class="PARAMETER">tokid</> <type>integer</>,
              OUT <replaceable class="PARAMETER">alias</> <type>text</>, OUT <replaceable class="PARAMETER">description</> <type>text</>) returns <type>setof record</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_token_type(<replaceable class="PARAMETER">parser_name</> <type>text</>, OUT <replaceable class="PARAMETER">tokid</> <type>integer</>,
              OUT <replaceable class="PARAMETER">alias</> <type>text</>, OUT <replaceable class="PARAMETER">description</> <type>text</>) returns <type>setof record</>
ts_token_type(<replaceable class="PARAMETER">parser_oid</> <type>oid</>, OUT <replaceable class="PARAMETER">tokid</> <type>integer</>,
              OUT <replaceable class="PARAMETER">alias</> <type>text</>, OUT <replaceable class="PARAMETER">description</> <type>text</>) returns <type>setof record</>
</synopsis>

<!--==========================orignal english content==========================
  <para>
   <function>ts_token_type</> returns a table which describes each type of
   token the specified parser can recognize.  For each token type, the table
   gives the integer <varname>tokid</varname> that the parser uses to label a
   token of that type, the <varname>alias</varname> that names the token type
   in configuration commands, and a short <varname>description</varname>.  For
   example:

<screen>
SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description                
-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity
</screen>
   </para>
____________________________________________________________________________-->
  <para>
   <function>ts_token_type</>返回一个表，该表描述指定解析器能够识别的每一种记号类型。对于每一种记号类型，该表给出了解析器用来标注该类型记号的整数<varname>tokid</varname>，还给出了在配置命令中命名该记号类型的<varname>alias</varname>，以及一个简短的<varname>description</varname>。例如：

<screen>
SELECT * FROM ts_token_type('default');
 tokid |      alias      |               description                
-------+-----------------+------------------------------------------
     1 | asciiword       | Word, all ASCII
     2 | word            | Word, all letters
     3 | numword         | Word, letters and digits
     4 | email           | Email address
     5 | url             | URL
     6 | host            | Host
     7 | sfloat          | Scientific notation
     8 | version         | Version number
     9 | hword_numpart   | Hyphenated word part, letters and digits
    10 | hword_part      | Hyphenated word part, all letters
    11 | hword_asciipart | Hyphenated word part, all ASCII
    12 | blank           | Space symbols
    13 | tag             | XML tag
    14 | protocol        | Protocol head
    15 | numhword        | Hyphenated word, letters and digits
    16 | asciihword      | Hyphenated word, all ASCII
    17 | hword           | Hyphenated word, all letters
    18 | url_path        | URL path
    19 | file            | File or path name
    20 | float           | Decimal notation
    21 | int             | Signed integer
    22 | uint            | Unsigned integer
    23 | entity          | XML entity
</screen>
   </para>

  </sect2>

  <sect2 id="textsearch-dictionary-testing">
<!--==========================orignal english content==========================
   <title>Dictionary Testing</title>
____________________________________________________________________________-->
   <title>词典测试</title>

<!--==========================orignal english content==========================
   <para>
    The <function>ts_lexize</> function facilitates dictionary testing.
   </para>
____________________________________________________________________________-->
   <para>
    <function>ts_lexize</>函数帮助词典测试。
   </para>

<!--==========================orignal english content==========================
   <indexterm>
    <primary>ts_lexize</primary>
   </indexterm>
____________________________________________________________________________-->
   <indexterm>
    <primary>ts_lexize</primary>
   </indexterm>

<!--==========================orignal english content==========================
<synopsis>
ts_lexize(<replaceable class="PARAMETER">dict</replaceable> <type>regdictionary</>, <replaceable class="PARAMETER">token</replaceable> <type>text</>) returns <type>text[]</>
</synopsis>
____________________________________________________________________________-->
<synopsis>
ts_lexize(<replaceable class="PARAMETER">dict</replaceable> <type>regdictionary</>, <replaceable class="PARAMETER">token</replaceable> <type>text</>) returns <type>text[]</>
</synopsis>

<!--==========================orignal english content==========================
   <para>
    <function>ts_lexize</> returns an array of lexemes if the input
    <replaceable>token</replaceable> is known to the dictionary,
    or an empty array if the token
    is known to the dictionary but it is a stop word, or
    <literal>NULL</literal> if it is an unknown word.
   </para>
____________________________________________________________________________-->
   <para>
    如果输入的<replaceable>token</replaceable>是该词典已知的，则<function>ts_lexize</>返回一个词位数组；如果记号是词典已知的但是它是一个停用词，则返回一个空数组；或者如果它对词典是未知词，则返回<literal>NULL</literal>。
   </para>

<!--==========================orignal english content==========================
   <para>
    Examples:

<screen>
SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-&minus;-&minus;-&minus;-&minus;-&minus;-
 {}
</screen>
   </para>
____________________________________________________________________________-->
   <para>
    例子：

<screen>
SELECT ts_lexize('english_stem', 'stars');
 ts_lexize
-----------
 {star}

SELECT ts_lexize('english_stem', 'a');
 ts_lexize
-----------
 {}
</screen>
   </para>

   <note>
<!--==========================orignal english content==========================
    <para>
     The <function>ts_lexize</function> function expects a single
     <emphasis>token</emphasis>, not text. Here is a case
     where this can be confusing:

<screen>
SELECT ts_lexize('thesaurus_astro','supernovae stars') is null;
 ?column?
-&minus;-&minus;-&minus;-&minus;-&minus;
 t
</screen>

     The thesaurus dictionary <literal>thesaurus_astro</literal> does know the
     phrase <literal>supernovae stars</literal>, but <function>ts_lexize</>
     fails since it does not parse the input text but treats it as a single
     token. Use <function>plainto_tsquery</> or <function>to_tsvector</> to
     test thesaurus dictionaries, for example:

<screen>
SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 'sn'
</screen>
    </para>
____________________________________________________________________________-->
    <para>
     <function>ts_lexize</function>函数期望一个单一<emphasis>记号</emphasis>而不是文本。下面的情况会让它搞混：

<screen>
SELECT ts_lexize('thesaurus_astro','supernovae stars') is null;
 ?column?
----------
 t
</screen>

     分类词典<literal>thesaurus_astro</literal>确实知道短语<literal>supernovae stars</literal>，但是<function>ts_lexize</>会失败，因为它无法解析输入文本而把它当做一个单一记号。可以使用<function>plainto_tsquery</>或<function>to_tsvector</>来测试分类词典，例如：

<screen>
SELECT plainto_tsquery('supernovae stars');
 plainto_tsquery
-----------------
 'sn'
</screen>
    </para>
   </note>

  </sect2>

 </sect1>

 <sect1 id="textsearch-indexes">
<!--==========================orignal english content==========================
  <title>GIN and GiST Index Types</title>
____________________________________________________________________________-->
  <title>GIN 和 GiST 索引类型</title>

<!--==========================orignal english content==========================
  <indexterm zone="textsearch-indexes">
   <primary>text search</primary>
   <secondary>indexes</secondary>
  </indexterm>
____________________________________________________________________________-->
  <indexterm zone="textsearch-indexes">
   <primary>文本搜索</primary>
   <secondary>索引</secondary>
  </indexterm>

<!--==========================orignal english content==========================
  <para>
   There are two kinds of indexes that can be used to speed up full text
   searches.
   Note that indexes are not mandatory for full text searching, but in
   cases where a column is searched on a regular basis, an index is
   usually desirable.

   <variablelist>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>index</primary>
      <secondary>GIN</secondary>
      <tertiary>text search</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIN (<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       Creates a GIN (Generalized Inverted Index)-based index.
       The <replaceable>column</replaceable> must be of <type>tsvector</> type.
      </para>
     </listitem>
    </varlistentry>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>index</primary>
      <secondary>GiST</secondary>
      <tertiary>text search</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIST (<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       Creates a GiST (Generalized Search Tree)-based index.
       The <replaceable>column</replaceable> can be of <type>tsvector</> or
       <type>tsquery</> type.
      </para>
     </listitem>
    </varlistentry>

   </variablelist>
  </para>
____________________________________________________________________________-->
  <para>
   有两种索引可以被用来加速全文搜索。注意全文搜索并非一定需要索引，但是在一个定期会被搜索的列上，通常需要有一个索引。

   <variablelist>

    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>索引</primary>
      <secondary>GIN</secondary>
      <tertiary>文本搜索</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIN(<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       创建一个基于 GIN（通用倒排索引）的索引。<replaceable>column</replaceable>必须是<type>tsvector</>类型。
      </para>
     </listitem>
    </varlistentry>
    
    <varlistentry>

     <term>
     <indexterm zone="textsearch-indexes">
      <primary>索引</primary>
      <secondary>GiST</secondary>
      <tertiary>文本搜索</tertiary>
     </indexterm>

      <literal>CREATE INDEX <replaceable>name</replaceable> ON <replaceable>table</replaceable> USING GIST(<replaceable>column</replaceable>);</literal>
     </term>

     <listitem>
      <para>
       创建一个基于 GiST（通用搜索树）的索引。<replaceable>column</replaceable>可以是<type>tsvector</>或<type>tsquery</>类型。
      </para>
     </listitem>
    </varlistentry>

   </variablelist>
  </para>

<!--==========================orignal english content==========================
  <para>
   GIN indexes are the preferred text search index type.  As inverted
   indexes, they contain an index entry for each word (lexeme), with a
   compressed list of matching locations.  Multi-word searches can find
   the first match, then use the index to remove rows that are lacking
   additional words.  GIN indexes store only the words (lexemes) of
   <type>tsvector</> values, and not their weight labels.  Thus a table
   row recheck is needed when using a query that involves weights.
  </para>
____________________________________________________________________________-->
  <para>
   GIN 索引是更好的文本搜索索引类型。作为倒排索引，每个词（词位）在
   其中都有一个索引项，其中有压缩过的匹配位置的列表。多词搜索可以找到
   第一个匹配，然后使用该索引移除缺少额外词的行。GIN 索引只存储
   <type>tsvector</>值的词（词位），并且不存储它们的权重标签。因此，
   在使用涉及权重的查询时需要一次在表行上的重新检查。
  </para>

<!--==========================orignal english content==========================
  <para>
   A GiST index is <firstterm>lossy</firstterm>, meaning that the index
   might produce false matches, and it is necessary
   to check the actual table row to eliminate such false matches.
   (<productname>PostgreSQL</productname> does this automatically when needed.)
   GiST indexes are lossy because each document is represented in the
   index by a fixed-length signature. The signature is generated by hashing
   each word into a single bit in an n-bit string, with all these bits OR-ed
   together to produce an n-bit document signature.  When two words hash to
   the same bit position there will be a false match.  If all words in
   the query have matches (real or false) then the table row must be
   retrieved to see if the match is correct.
  </para>
____________________________________________________________________________-->
  <para>
   一个 GiST 索引是<firstterm>有损的</firstterm>，这表示索引可能产生假匹配，并且有必要检查真实的表行来消除这种假匹配（<productname>PostgreSQL</productname>在需要时会自动做这一步）。GiST 索引之所以是有损的，是因为每一个文档在索引中被表示为一个定长的签名。该签名通过哈希每一个词到一个 n 位串中的一个单一位来产生，通过将所有这些位 OR 在一起产生一个 n 位的文档签名。当两个词哈希到同一个位位置时就会产生假匹配。如果查询中所有词都有匹配（真或假），则必须检索表行查看匹配是否正确。
  </para>

<!--==========================orignal english content==========================
  <para>
   Lossiness causes performance degradation due to unnecessary fetches of table
   records that turn out to be false matches.  Since random access to table
   records is slow, this limits the usefulness of GiST indexes.  The
   likelihood of false matches depends on several factors, in particular the
   number of unique words, so using dictionaries to reduce this number is
   recommended.
  </para>
____________________________________________________________________________-->
  <para>
   有损性导致的性能下降归因于不必要的表记录（即被证实为假匹配的记录）获取。因为表记录的随机访问是较慢的，这限制了 GiST 索引的可用性。假匹配的可能性取决于几个因素，特别是唯一词的数量，因此推荐使用词典来缩减这个数量。
  </para>

<!--==========================orignal english content==========================
  <para>
   Note that <acronym>GIN</acronym> index build time can often be improved
   by increasing <xref linkend="guc-maintenance-work-mem">, while
   <acronym>GiST</acronym> index build time is not sensitive to that
   parameter.
  </para>
____________________________________________________________________________-->
  <para>
   注意<acronym>GIN</acronym>索引的构件时间常常可以通过增加<xref linkend="guc-maintenance-work-mem">来改进，而<acronym>GiST</acronym>索引的构建时间则与该参数无关。
  </para>

<!--==========================orignal english content==========================
  <para>
   Partitioning of big collections and the proper use of GIN and GiST indexes
   allows the implementation of very fast searches with online update.
   Partitioning can be done at the database level using table inheritance,
   or by distributing documents over
   servers and collecting search results using the <xref linkend="dblink">
   module. The latter is possible because ranking functions use
   only local information.
  </para>
____________________________________________________________________________-->
  <para>
   对大集合分区并正确使用 GIN 和 GiST 索引允许实现带在线更新的快速搜索。分区可以在数据库层面上使用表继承来完成，或者是通过将文档分布在服务器上并使用<xref linkend="dblink">收集结果。后者是可能的，因为排名函数只使用本地信息。
  </para>

 </sect1>

 <sect1 id="textsearch-psql">
<!--==========================orignal english content==========================
  <title><application>psql</> Support</title>
____________________________________________________________________________-->
  <title><application>psql</>支持</title>

<!--==========================orignal english content==========================
  <para>
   Information about text search configuration objects can be obtained
   in <application>psql</application> using a set of commands:
<synopsis>
\dF{d,p,t}<optional>+</optional> <optional>PATTERN</optional>
</synopsis>
   An optional <literal>+</literal> produces more details.
  </para>
____________________________________________________________________________-->
  <para>
   关于文本搜索配置对象的信息可以在<application>psql</application>中使用一组命令获得：
<synopsis>
\dF{d,p,t}<optional>+</optional> <optional>PATTERN</optional>
</synopsis>
   可选的<literal>+</literal>能产生更多细节。
  </para>

<!--==========================orignal english content==========================
  <para>
   The optional parameter <replaceable>PATTERN</replaceable> can be the name of
   a text search object, optionally schema-qualified.  If
   <replaceable>PATTERN</replaceable> is omitted then information about all
   visible objects will be displayed.  <replaceable>PATTERN</replaceable> can be a
   regular expression and can provide <emphasis>separate</emphasis> patterns
   for the schema and object names.  The following examples illustrate this:

<screen>
=&gt; \dF *fulltext*
       List of text search configurations
 Schema |  Name        | Description
-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 public | fulltext_cfg |
</screen>

<screen>
=&gt; \dF *.fulltext*
       List of text search configurations
 Schema   |  Name        | Description
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 fulltext | fulltext_cfg |
 public   | fulltext_cfg |
</screen>

   The available commands are:
  </para>
____________________________________________________________________________-->
  <para>
   可选参数<replaceable>PATTERN</replaceable>可以是一个文本搜索对象的名称，可以是模式限定的。如果<replaceable>PATTERN</replaceable>被忽略，则所有可见对象的信息都将被显示。<replaceable>PATTERN</replaceable>可以是一个正则表达式并且可以为模式和对象名称提供<emphasis>独立的</emphasis>模式。下面的例子展示了这些特性：

<screen>
=&gt; \dF *fulltext*
       List of text search configurations
 Schema |  Name        | Description
--------+--------------+-------------
 public | fulltext_cfg |
</screen>

<screen>
=&gt; \dF *.fulltext*
       List of text search configurations
 Schema   |  Name        | Description
----------+----------------------------
 fulltext | fulltext_cfg |
 public   | fulltext_cfg |
</screen>

   可用的命令是：
  </para>

  <variablelist>
   <varlistentry>
<!--==========================orignal english content==========================
    <term><literal>\dF<optional>+</optional> <optional>PATTERN</optional></literal></term>
____________________________________________________________________________-->
    <term><literal>\dF<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      List text search configurations (add <literal>+</> for more detail).
<screen>
=&gt; \dF russian
            List of text search configurations
   Schema   |  Name   |            Description             
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 pg_catalog | russian | configuration for russian language

=&gt; \dF+ russian
Text search configuration "pg_catalog.russian"
Parser: "pg_catalog.default"
      Token      | Dictionaries 
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 asciihword      | english_stem
 asciiword       | english_stem
 email           | simple
 file            | simple
 float           | simple
 host            | simple
 hword           | russian_stem
 hword_asciipart | english_stem
 hword_numpart   | simple
 hword_part      | russian_stem
 int             | simple
 numhword        | simple
 numword         | simple
 sfloat          | simple
 uint            | simple
 url             | simple
 url_path        | simple
 version         | simple
 word            | russian_stem
</screen>
     </para>
____________________________________________________________________________-->
     <para>
      列出文本搜索配置（加上<literal>+</>得到更多细节）。
<screen>
=&gt; \dF russian
            List of text search configurations
   Schema   |  Name   |            Description             
------------+---------+------------------------------------
 pg_catalog | russian | configuration for russian language

=&gt; \dF+ russian
Text search configuration "pg_catalog.russian"
Parser: "pg_catalog.default"
      Token      | Dictionaries 
-----------------+--------------
 asciihword      | english_stem
 asciiword       | english_stem
 email           | simple
 file            | simple
 float           | simple
 host            | simple
 hword           | russian_stem
 hword_asciipart | english_stem
 hword_numpart   | simple
 hword_part      | russian_stem
 int             | simple
 numhword        | simple
 numword         | simple
 sfloat          | simple
 uint            | simple
 url             | simple
 url_path        | simple
 version         | simple
 word            | russian_stem
</screen>
     </para>
    </listitem>
   </varlistentry>

   <varlistentry>
<!--==========================orignal english content==========================
    <term><literal>\dFd<optional>+</optional> <optional>PATTERN</optional></literal></term>
____________________________________________________________________________-->
    <term><literal>\dFd<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      List text search dictionaries (add <literal>+</> for more detail).
<screen>
=&gt; \dFd
                            List of text search dictionaries
   Schema   |      Name       |                        Description                        
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | danish_stem     | snowball stemmer for danish language
 pg_catalog | dutch_stem      | snowball stemmer for dutch language
 pg_catalog | english_stem    | snowball stemmer for english language
 pg_catalog | finnish_stem    | snowball stemmer for finnish language
 pg_catalog | french_stem     | snowball stemmer for french language
 pg_catalog | german_stem     | snowball stemmer for german language
 pg_catalog | hungarian_stem  | snowball stemmer for hungarian language
 pg_catalog | italian_stem    | snowball stemmer for italian language
 pg_catalog | norwegian_stem  | snowball stemmer for norwegian language
 pg_catalog | portuguese_stem | snowball stemmer for portuguese language
 pg_catalog | romanian_stem   | snowball stemmer for romanian language
 pg_catalog | russian_stem    | snowball stemmer for russian language
 pg_catalog | simple          | simple dictionary: just lower case and check for stopword
 pg_catalog | spanish_stem    | snowball stemmer for spanish language
 pg_catalog | swedish_stem    | snowball stemmer for swedish language
 pg_catalog | turkish_stem    | snowball stemmer for turkish language
</screen>
     </para>
____________________________________________________________________________-->
     <para>
      列出文本搜索词典（加上<literal>+</>得到更多细节）。
<screen>
=&gt; \dFd
                            List of text search dictionaries
   Schema   |      Name       |                        Description                        
------------+-----------------+-----------------------------------------------------------
 pg_catalog | danish_stem     | snowball stemmer for danish language
 pg_catalog | dutch_stem      | snowball stemmer for dutch language
 pg_catalog | english_stem    | snowball stemmer for english language
 pg_catalog | finnish_stem    | snowball stemmer for finnish language
 pg_catalog | french_stem     | snowball stemmer for french language
 pg_catalog | german_stem     | snowball stemmer for german language
 pg_catalog | hungarian_stem  | snowball stemmer for hungarian language
 pg_catalog | italian_stem    | snowball stemmer for italian language
 pg_catalog | norwegian_stem  | snowball stemmer for norwegian language
 pg_catalog | portuguese_stem | snowball stemmer for portuguese language
 pg_catalog | romanian_stem   | snowball stemmer for romanian language
 pg_catalog | russian_stem    | snowball stemmer for russian language
 pg_catalog | simple          | simple dictionary: just lower case and check for stopword
 pg_catalog | spanish_stem    | snowball stemmer for spanish language
 pg_catalog | swedish_stem    | snowball stemmer for swedish language
 pg_catalog | turkish_stem    | snowball stemmer for turkish language
</screen>
     </para>
    </listitem>
   </varlistentry>

   <varlistentry>
<!--==========================orignal english content==========================
   <term><literal>\dFp<optional>+</optional> <optional>PATTERN</optional></literal></term>
____________________________________________________________________________-->
   <term><literal>\dFp<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      List text search parsers (add <literal>+</> for more detail).
<screen>
=&gt; \dFp
        List of text search parsers
   Schema   |  Name   |     Description     
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | default | default word parser
=&gt; \dFp+
    Text search parser "pg_catalog.default"
     Method      |    Function    | Description 
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Start parse     | prsd_start     | 
 Get next token  | prsd_nexttoken | 
 End parse       | prsd_end       | 
 Get headline    | prsd_headline  | 
 Get token types | prsd_lextype   | 

        Token types for parser "pg_catalog.default"
   Token name    |               Description                
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 asciihword      | Hyphenated word, all ASCII
 asciiword       | Word, all ASCII
 blank           | Space symbols
 email           | Email address
 entity          | XML entity
 file            | File or path name
 float           | Decimal notation
 host            | Host
 hword           | Hyphenated word, all letters
 hword_asciipart | Hyphenated word part, all ASCII
 hword_numpart   | Hyphenated word part, letters and digits
 hword_part      | Hyphenated word part, all letters
 int             | Signed integer
 numhword        | Hyphenated word, letters and digits
 numword         | Word, letters and digits
 protocol        | Protocol head
 sfloat          | Scientific notation
 tag             | XML tag
 uint            | Unsigned integer
 url             | URL
 url_path        | URL path
 version         | Version number
 word            | Word, all letters
(23 rows)
</screen>
     </para>
____________________________________________________________________________-->
     <para>
      列出文本搜索解析器（加上<literal>+</>得到更多细节）。
<screen>
=&gt; \dFp
        List of text search parsers
   Schema   |  Name   |     Description     
------------+---------+---------------------
 pg_catalog | default | default word parser
=&gt; \dFp+
    Text search parser "pg_catalog.default"
     Method      |    Function    | Description 
-----------------+----------------+-------------
 Start parse     | prsd_start     | 
 Get next token  | prsd_nexttoken | 
 End parse       | prsd_end       | 
 Get headline    | prsd_headline  | 
 Get token types | prsd_lextype   | 

        Token types for parser "pg_catalog.default"
   Token name    |               Description                
-----------------+------------------------------------------
 asciihword      | Hyphenated word, all ASCII
 asciiword       | Word, all ASCII
 blank           | Space symbols
 email           | Email address
 entity          | XML entity
 file            | File or path name
 float           | Decimal notation
 host            | Host
 hword           | Hyphenated word, all letters
 hword_asciipart | Hyphenated word part, all ASCII
 hword_numpart   | Hyphenated word part, letters and digits
 hword_part      | Hyphenated word part, all letters
 int             | Signed integer
 numhword        | Hyphenated word, letters and digits
 numword         | Word, letters and digits
 protocol        | Protocol head
 sfloat          | Scientific notation
 tag             | XML tag
 uint            | Unsigned integer
 url             | URL
 url_path        | URL path
 version         | Version number
 word            | Word, all letters
(23 rows)
</screen>
     </para>
    </listitem>
   </varlistentry>

   <varlistentry>
<!--==========================orignal english content==========================
   <term><literal>\dFt<optional>+</optional> <optional>PATTERN</optional></literal></term>
____________________________________________________________________________-->
   <term><literal>\dFt<optional>+</optional> <optional>PATTERN</optional></literal></term>
    <listitem>
<!--==========================orignal english content==========================
     <para>
      List text search templates (add <literal>+</> for more detail).
<screen>
=&gt; \dFt
                           List of text search templates
   Schema   |   Name    |                        Description                        
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 pg_catalog | ispell    | ispell dictionary
 pg_catalog | simple    | simple dictionary: just lower case and check for stopword
 pg_catalog | snowball  | snowball stemmer
 pg_catalog | synonym   | synonym dictionary: replace word by its synonym
 pg_catalog | thesaurus | thesaurus dictionary: phrase by phrase substitution
</screen>
     </para>
____________________________________________________________________________-->
     <para>
      列出文本搜索模板（加上<literal>+</>得到更多细节）。
<screen>
=&gt; \dFt
                           List of text search templates
   Schema   |   Name    |                        Description                        
------------+-----------+-----------------------------------------------------------
 pg_catalog | ispell    | ispell dictionary
 pg_catalog | simple    | simple dictionary: just lower case and check for stopword
 pg_catalog | snowball  | snowball stemmer
 pg_catalog | synonym   | synonym dictionary: replace word by its synonym
 pg_catalog | thesaurus | thesaurus dictionary: phrase by phrase substitution
</screen>
     </para>
    </listitem>
   </varlistentry>
  </variablelist>

 </sect1>

 <sect1 id="textsearch-limitations">
<!--==========================orignal english content==========================
  <title>Limitations</title>
____________________________________________________________________________-->
  <title>限制</title>

<!--==========================orignal english content==========================
  <para>
   The current limitations of <productname>PostgreSQL</productname>'s
   text search features are:
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>The length of each lexeme must be less than 2K bytes</para>
    </listitem>
    <listitem>
     <para>The length of a <type>tsvector</type> (lexemes + positions) must be
     less than 1 megabyte</para>
    </listitem>
    <listitem>
     <!-&minus; TODO: number of lexemes in what?  This is unclear -&minus;>
     <para>The number of lexemes must be less than
     2<superscript>64</superscript></para>
    </listitem>
    <listitem>
     <para>Position values in <type>tsvector</> must be greater than 0 and
     no more than 16,383</para>
    </listitem>
    <listitem>
     <para>The match distance in a <literal>&lt;<replaceable>N</>&gt;</literal>
     (FOLLOWED BY) <type>tsquery</> operator cannot be more than
     16,384</para>
    </listitem>
    <listitem>
     <para>No more than 256 positions per lexeme</para>
    </listitem>
    <listitem>
     <para>The number of nodes (lexemes + operators) in a <type>tsquery</type>
     must be less than 32,768</para>
    </listitem>
   </itemizedlist>
  </para>
____________________________________________________________________________-->
  <para>
   <productname>PostgreSQL</productname>的文本搜索特性的当前限制是：
   <itemizedlist  spacing="compact" mark="bullet">
    <listitem>
     <para>每一个词位的长度必须小于 2K 字节</para>
    </listitem>
    <listitem>
     <para>一个<type>tsvector</type>（词位 + 位置）的长度必须小于 1 兆字节</para>
    </listitem>
    <listitem>
     <!-- TODO: number of lexemes in what?  This is unclear -->
     <para>词位的数量必须小于
     2<superscript>64</superscript></para>
    </listitem>
    <listitem>
     <para><type>tsvector</>中的位置值必须大于 0 并且小于 16,383</para>
    </listitem>
    <listitem>
     <para><literal>&lt;<replaceable>N</>&gt;</literal>（FOLLOWED BY）<type>tsquery</>操作符中的匹配距离不能超过 16,384</para>
    </listitem>
    <listitem>
     <para>每个词位不超过 256 个位置</para>
    </listitem>
    <listitem>
     <para> 一个<type>tsquery</type>中结点（词位 + 操作符）的个数必须小于 32,768</para>
    </listitem>
   </itemizedlist>
  </para>

<!--==========================orignal english content==========================
  <para>
   For comparison, the <productname>PostgreSQL</productname> 8.1 documentation
   contained 10,441 unique words, a total of 335,420 words, and the most
   frequent word <quote>postgresql</> was mentioned 6,127 times in 655
   documents.
  </para>
____________________________________________________________________________-->
  <para>
   为了对比，<productname>PostgreSQL</productname> 8.1 的文档包含 10,441 个唯一词，总数 335,420 个词，并且最频繁的词<quote>postgresql</>在 655 个文档中被提到 6,127 次。
  </para>

   <!-- TODO we need to put a date on these numbers? -->
<!--==========================orignal english content==========================
  <para>
   Another example &mdash; the <productname>PostgreSQL</productname> mailing
   list archives contained 910,989 unique words with 57,491,343 lexemes in
   461,020 messages.
  </para>
____________________________________________________________________________-->
  <para>
   另一个例子 &mdash; <productname>PostgreSQL</productname>的邮件列表归档在 461,020 条消息的 57,491,343 个词位中包含 910,989 个唯一词。
  </para>

 </sect1>
</chapter>
