<!-- doc/src/sgml/planstats.sgml -->

<chapter id="planner-stats-details">
<!-- pgdoc-cn_start sig_en=b137c9176b482da349faa754599f7ae7 sig_cn_org=None source=14.1 
 <title>How the Planner Uses Statistics</title>
________________________________________________________-->
 <title>规划器如何使用统计信息</title>
<!-- pgdoc-cn_end sig_en=b137c9176b482da349faa754599f7ae7 -->

<!-- pgdoc-cn_start sig_en=0a812d994f3b5151f6c60627fc686fa9 sig_cn_org=None source=14.1 
  <para>
   This chapter builds on the material covered in <xref
   linkend="using-explain"/> and <xref linkend="planner-stats"/> to show some
   additional details about how the planner uses the
   system statistics to estimate the number of rows each part of a query might
   return. This is a significant part of the planning process,
   providing much of the raw material for cost calculation.
  </para>
________________________________________________________-->
  <para>
   本章建立在<xref linkend="using-explain"/>和<xref linkend="planner-stats"/>中讨论的材料之上，展示了关于规划器如何使用系统统计信息来估计一个查询的各个部分可能返回的行数。这是规划处理中的一个重要的部分，它提供了代价计算中的很多原始材料。
  </para>
<!-- pgdoc-cn_end sig_en=0a812d994f3b5151f6c60627fc686fa9 -->

<!-- pgdoc-cn_start sig_en=b42e024df9bbfd9482ae205c748d5ea2 sig_cn_org=None source=14.1 
  <para>
   The intent of this chapter is not to document the code in detail,
   but to present an overview of how it works.
   This will perhaps ease the learning curve for someone who subsequently
   wishes to read the code.
  </para>
________________________________________________________-->
  <para>
   本章的目的不是详细地解释代码，而是给出一个规划器如何使用统计信息的概述。这样可能可以降低那些想以后阅读这部份代码的人的学习曲线。
  </para>
<!-- pgdoc-cn_end sig_en=b42e024df9bbfd9482ae205c748d5ea2 -->

 <sect1 id="row-estimation-examples">
<!-- pgdoc-cn_start sig_en=454e53c35391c4966a30d7daf2410ce2 sig_cn_org=None source=14.1 
  <title>Row Estimation Examples</title>
________________________________________________________-->
  <title>行估计例子</title>
<!-- pgdoc-cn_end sig_en=454e53c35391c4966a30d7daf2410ce2 -->

<!-- pgdoc-cn_start sig_en=d889eaec719c7b29c4bc977c79512ee7 sig_cn_org=None source=14.1 
  <indexterm zone="row-estimation-examples">
   <primary>row estimation</primary>
   <secondary>planner</secondary>
  </indexterm>
________________________________________________________-->
  <indexterm zone="row-estimation-examples">
   <primary>行估计</primary>
   <secondary>规划器</secondary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=d889eaec719c7b29c4bc977c79512ee7 -->

<!-- pgdoc-cn_start sig_en=44db63ba1085b20f98dd922e498c845e sig_cn_org=None source=14.1 
  <para>
   The examples shown below use tables in the <productname>PostgreSQL</productname>
   regression test database.
   The outputs shown are taken from version 8.3.
   The behavior of earlier (or later) versions might vary.
   Note also that since <command>ANALYZE</command> uses random sampling
   while producing statistics, the results will change slightly after
   any new <command>ANALYZE</command>.
  </para>
________________________________________________________-->
  <para>
   下面展示的例子使用<productname>PostgreSQL</productname>回归测试数据库中的表。输出结果是从版本 8.3 获得。之前（或之后）版本的动作可能会有所变化。同时还要注意的是，由于<command>ANALYZE</command>使用随机采样来产生统计信息，在任何新的<command>ANALYZE</command>之后结果将有轻微改变。
  </para>
<!-- pgdoc-cn_end sig_en=44db63ba1085b20f98dd922e498c845e -->

<!-- pgdoc-cn_start sig_en=2177c1131f1baeed5ede7b89c7a9d32f sig_cn_org=None source=14.1 
  <para>
   Let's start with a very simple query:

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>

   How the planner determines the cardinality of <structname>tenk1</structname>
   is covered in <xref linkend="planner-stats"/>, but is repeated here for
   completeness. The number of pages and rows is looked up in
   <structname>pg_class</structname>:

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';

 relpages | reltuples
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-
      358 |     10000
</programlisting>

    These numbers are current as of the last <command>VACUUM</command> or
    <command>ANALYZE</command> on the table.  The planner then fetches the
    actual current number of pages in the table (this is a cheap operation,
    not requiring a table scan).  If that is different from
    <structfield>relpages</structfield> then
    <structfield>reltuples</structfield> is scaled accordingly to
    arrive at a current number-of-rows estimate.  In the example above, the value of
    <structfield>relpages</structfield> is up-to-date so the rows estimate is
    the same as <structfield>reltuples</structfield>.
  </para>
________________________________________________________-->
  <para>
   让我们从一个很简单的查询开始：

<programlisting>
EXPLAIN SELECT * FROM tenk1;

                         QUERY PLAN
-------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
</programlisting>

   规划器如何判断<structname>tenk1</structname>的势在<xref linkend="planner-stats"/>中介绍，但为了完整还会在这里重复介绍。行数或页数是从<structname>pg_class</structname>中查出来的：

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 'tenk1';

 relpages | reltuples
----------+-----------
      358 |     10000
</programlisting>

    这些数字是在表上的最后一次<command>VACUUM</command>或<command>ANALYZE</command>以来的当前值。
    之后，规划器取出该表中实际的当前页数（这个操作的开销很小，不需要扫描全表）。
    如果与<structfield>relpages</structfield>不同，则对<structfield>reltuples</structfield>
    进行相应的缩放以得到一个当前的行数估计。在上面的例子中，
    <structfield>relpages</structfield>的值是最新的，
    因此行估计与<structfield>reltuples</structfield>相同。
  </para>
<!-- pgdoc-cn_end sig_en=2177c1131f1baeed5ede7b89c7a9d32f -->

<!-- pgdoc-cn_start sig_en=8eb1ece6a5edc66ecd6a8336898a8d58 sig_cn_org=None source=14.1 
  <para>
   Let's move on to an example with a range condition in its
   <literal>WHERE</literal> clause:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 1000;

                                   QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Bitmap Heap Scan on tenk1  (cost=24.06..394.64 rows=1007 width=244)
   Recheck Cond: (unique1 &lt; 1000)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..23.80 rows=1007 width=0)
         Index Cond: (unique1 &lt; 1000)
</programlisting>

   The planner examines the <literal>WHERE</literal> clause condition
   and looks up the selectivity function for the operator
   <literal>&lt;</literal> in <structname>pg_operator</structname>.
   This is held in the column <structfield>oprrest</structfield>,
   and the entry in this case is <function>scalarltsel</function>.
   The <function>scalarltsel</function> function retrieves the histogram for
   <structfield>unique1</structfield> from
   <structname>pg_statistic</structname>.  For manual queries it is more
   convenient to look in the simpler <structname>pg_stats</structname>
   view:

<programlisting>
SELECT histogram_bounds FROM pg_stats
WHERE tablename='tenk1' AND attname='unique1';

                   histogram_bounds
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 {0,993,1997,3050,4040,5036,5957,7057,8029,9016,9995}
</programlisting>

   Next the fraction of the histogram occupied by <quote>&lt; 1000</quote>
   is worked out. This is the selectivity. The histogram divides the range
   into equal frequency buckets, so all we have to do is locate the bucket
   that our value is in and count <emphasis>part</emphasis> of it and
   <emphasis>all</emphasis> of the ones before. The value 1000 is clearly in
   the second bucket (993&ndash;1997).  Assuming a linear distribution of
   values inside each bucket, we can calculate the selectivity as:

<programlisting>
selectivity = (1 + (1000 - bucket[2].min)/(bucket[2].max - bucket[2].min))/num_buckets
            = (1 + (1000 - 993)/(1997 - 993))/10
            = 0.100697
</programlisting>

   that is, one whole bucket plus a linear fraction of the second, divided by
   the number of buckets. The estimated number of rows can now be calculated as
   the product of the selectivity and the cardinality of
   <structname>tenk1</structname>:

<programlisting>
rows = rel_cardinality * selectivity
     = 10000 * 0.100697
     = 1007  (rounding off)
</programlisting>
  </para>
________________________________________________________-->
  <para>
   换一个在<literal>WHERE</literal>子句中带有范围条件的例子：

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 1000;

                                   QUERY PLAN
-------------------------------------------------------------------&zwsp;-------------
 Bitmap Heap Scan on tenk1  (cost=24.06..394.64 rows=1007 width=244)
   Recheck Cond: (unique1 &lt; 1000)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..23.80 rows=1007 width=0)
         Index Cond: (unique1 &lt; 1000)
</programlisting>

   规划器检查<literal>WHERE</literal>子句条件，并在<structname>pg_operator</structname>中查找<literal>&lt;</literal>操作符的选择度函数。这被保持在<structfield>oprrest</structfield>列中， 并且在这个例子中的项是<function>scalarltsel</function>。 <function>scalarltsel</function>函数从<structname>pg_statistic</structname>为<structfield>unique1</structfield>检索直方图。 对于手工查询来说，查看更简单的<structname>pg_stats</structname>视图会更方便：

<programlisting>
SELECT histogram_bounds FROM pg_stats
WHERE tablename='tenk1' AND attname='unique1';

                   histogram_bounds
------------------------------------------------------
 {0,993,1997,3050,4040,5036,5957,7057,8029,9016,9995}
</programlisting>

   然后，把直方图里面被<quote>&lt; 1000</quote>占据的部分找出来。这就是选择度。直方图把范围分隔成等频的桶， 所以我们要做的只是把我们的值所在的桶找出来，然后计数其中的<emphasis>部分</emphasis>以及<emphasis>所有</emphasis>该值之前的部分。值 1000 很明显在第二个桶（993&ndash;1943）中。假设每个桶中的值是线性分布，那么就可以计算出选择度：

<programlisting>
selectivity = (1 + (1000 - bucket[2].min)/(bucket[2].max - bucket[2].min))/num_buckets
            = (1 + (1000 - 993)/(1997 - 993))/10
            = 0.100697
</programlisting>

   也就是一整个桶加上第二个桶的线性部分，除以桶数。那么估计的行数现在可以用选择度乘以<structname>tenk1</structname>的势来计算：

<programlisting>
rows = rel_cardinality * selectivity
     = 10000 * 0.100697
     = 1007  (rounding off)
</programlisting>
  </para>
<!-- pgdoc-cn_end sig_en=8eb1ece6a5edc66ecd6a8336898a8d58 -->

<!-- pgdoc-cn_start sig_en=75ba6081c55b1666c6c0ca44f8bd6270 sig_cn_org=None source=14.1 
  <para>
   Next let's consider an example with an equality condition in its
   <literal>WHERE</literal> clause:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 = 'CRAAAA';

                        QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on tenk1  (cost=0.00..483.00 rows=30 width=244)
   Filter: (stringu1 = 'CRAAAA'::name)
</programlisting>

   Again the planner examines the <literal>WHERE</literal> clause condition
   and looks up the selectivity function for <literal>=</literal>, which is
   <function>eqsel</function>.  For equality estimation the histogram is
   not useful; instead the list of <firstterm>most
   common values</firstterm> (<acronym>MCV</acronym>s) is used to determine the
   selectivity. Let's have a look at the MCVs, with some additional columns
   that will be useful later:

<programlisting>
SELECT null_frac, n_distinct, most_common_vals, most_common_freqs FROM pg_stats
WHERE tablename='tenk1' AND attname='stringu1';

null_frac         | 0
n_distinct        | 676
most_common_vals  | {EJAAAA,BBAAAA,CRAAAA,FCAAAA,FEAAAA,GSAAAA,&zwsp;JOAAAA,MCAAAA,NAAAAA,WGAAAA}
most_common_freqs | {0.00333333,0.003,0.003,0.003,0.003,0.003,&zwsp;0.003,0.003,0.003,0.003}

</programlisting>

   Since <literal>CRAAAA</literal> appears in the list of MCVs, the selectivity is
   merely the corresponding entry in the list of most common frequencies
   (<acronym>MCF</acronym>s):

<programlisting>
selectivity = mcf[3]
            = 0.003
</programlisting>

   As before, the estimated number of rows is just the product of this with the
   cardinality of <structname>tenk1</structname>:

<programlisting>
rows = 10000 * 0.003
     = 30
</programlisting>
  </para>
________________________________________________________-->
  <para>
   然后让我们考虑一个在<literal>WHERE</literal>子句有等于条件的例子：

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 = 'CRAAAA';

                        QUERY PLAN
----------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=30 width=244)
   Filter: (stringu1 = 'CRAAAA'::name)
</programlisting>

   规划器还是检查<literal>WHERE</literal>子句条件，并为<literal>=</literal>查找选择度函数（这次是<function>eqsel</function>）。对于等值估计而言，直方图是没用的；相反，<firstterm>最常见值</firstterm>（<acronym>MCV</acronym>）列表可以用来决定选择度。让我们来看一下 MCV，以及一些额外的后面用得上的列：

<programlisting>
SELECT null_frac, n_distinct, most_common_vals, most_common_freqs FROM pg_stats
WHERE tablename='tenk1' AND attname='stringu1';

null_frac         | 0
n_distinct        | 676
most_common_vals  | {EJAAAA,BBAAAA,CRAAAA,FCAAAA,FEAAAA,GSAAAA,&zwsp;JOAAAA,MCAAAA,NAAAAA,WGAAAA}
most_common_freqs | {0.00333333,0.003,0.003,0.003,0.003,0.003,&zwsp;0.003,0.003,0.003,0.003}

</programlisting>

   因为<literal>CRAAAA</literal>出现在 MCV 列表中，那么选择度只是最常见频度（<acronym>MCF</acronym>）列表中的一个对应项：

<programlisting>
selectivity = mcf[3]
            = 0.003
</programlisting>

   像之前一样，行数的估计只是和前面一样用<structname>tenk1</structname>的势乘以选择度：

<programlisting>
rows = 10000 * 0.003
     = 30
</programlisting>
  </para>
<!-- pgdoc-cn_end sig_en=75ba6081c55b1666c6c0ca44f8bd6270 -->

<!-- pgdoc-cn_start sig_en=e17d0b4c5576b3b81ddd8b2ecc14789a sig_cn_org=None source=14.1 
  <para>
   Now consider the same query, but with a constant that is not in the
   <acronym>MCV</acronym> list:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 = 'xxx';

                        QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on tenk1  (cost=0.00..483.00 rows=15 width=244)
   Filter: (stringu1 = 'xxx'::name)
</programlisting>

   This is quite a different problem: how to estimate the selectivity when the
   value is <emphasis>not</emphasis> in the <acronym>MCV</acronym> list.
   The approach is to use the fact that the value is not in the list,
   combined with the knowledge of the frequencies for all of the
   <acronym>MCV</acronym>s:

<programlisting>
selectivity = (1 - sum(mvf))/(num_distinct - num_mcv)
            = (1 - (0.00333333 + 0.003 + 0.003 + 0.003 + 0.003 + 0.003 +
                    0.003 + 0.003 + 0.003 + 0.003))/(676 - 10)
            = 0.0014559
</programlisting>

   That is, add up all the frequencies for the <acronym>MCV</acronym>s and
   subtract them from one, then
   divide by the number of <emphasis>other</emphasis> distinct values.
   This amounts to assuming that the fraction of the column that is not any
   of the MCVs is evenly distributed among all the other distinct values.
   Notice that there are no null values so we don't have to worry about those
   (otherwise we'd subtract the null fraction from the numerator as well).
   The estimated number of rows is then calculated as usual:

<programlisting>
rows = 10000 * 0.0014559
     = 15  (rounding off)
</programlisting>
  </para>
________________________________________________________-->
  <para>
   现在看看同样的查询，但是常量不在<acronym>MCV</acronym>列表中：

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 = 'xxx';

                        QUERY PLAN
----------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=15 width=244)
   Filter: (stringu1 = 'xxx'::name)
</programlisting>

   这是完全不同的一个问题：当值<emphasis>不</emphasis>在<acronym>MCV</acronym>列表中时， 如何估计选择度。解决方法是利用该值不在列表中的事实，结合所有<acronym>MCV</acronym>出现的频率的知识：

<programlisting>
selectivity = (1 - sum(mvf))/(num_distinct - num_mcv)
            = (1 - (0.00333333 + 0.003 + 0.003 + 0.003 + 0.003 + 0.003 +
                    0.003 + 0.003 + 0.003 + 0.003))/(676 - 10)
            = 0.0014559
</programlisting>

   也就是，把所有<acronym>MCV</acronym>的频度加起来并从 1 减去，然后除以<emphasis>其他</emphasis>可区分值的个数。这相当于假设不是 MCV 中的列的部分均匀分布在所有其他可区分值上。 需要注意的是，这里没有空值，因此我们不需要担心这些（否则需要从分子中减去空值的部分）。估计的行数然后按照常规计算：

<programlisting>
rows = 10000 * 0.0014559
     = 15  (rounding off)
</programlisting>
  </para>
<!-- pgdoc-cn_end sig_en=e17d0b4c5576b3b81ddd8b2ecc14789a -->

<!-- pgdoc-cn_start sig_en=e931bb02e2933a3d7c22b220bcc5b9b8 sig_cn_org=None source=14.1 
  <para>
   The previous example with <literal>unique1 &lt; 1000</literal> was an
   oversimplification of what <function>scalarltsel</function> really does;
   now that we have seen an example of the use of MCVs, we can fill in some
   more detail.  The example was correct as far as it went, because since
   <structfield>unique1</structfield> is a unique column it has no MCVs (obviously, no
   value is any more common than any other value).  For a non-unique
   column, there will normally be both a histogram and an MCV list, and
   <emphasis>the histogram does not include the portion of the column
   population represented by the MCVs</emphasis>.  We do things this way because
   it allows more precise estimation.  In this situation
   <function>scalarltsel</function> directly applies the condition (e.g.,
   <quote>&lt; 1000</quote>) to each value of the MCV list, and adds up the
   frequencies of the MCVs for which the condition is true.  This gives
   an exact estimate of the selectivity within the portion of the table
   that is MCVs.  The histogram is then used in the same way as above
   to estimate the selectivity in the portion of the table that is not
   MCVs, and then the two numbers are combined to estimate the overall
   selectivity.  For example, consider

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 &lt; 'IAAAAA';

                         QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on tenk1  (cost=0.00..483.00 rows=3077 width=244)
   Filter: (stringu1 &lt; 'IAAAAA'::name)
</programlisting>

   We already saw the MCV information for <structfield>stringu1</structfield>,
   and here is its histogram:

<programlisting>
SELECT histogram_bounds FROM pg_stats
WHERE tablename='tenk1' AND attname='stringu1';

                                histogram_bounds
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 {AAAAAA,CQAAAA,FRAAAA,IBAAAA,KRAAAA,NFAAAA,PSAAAA,SGAAAA,VAAAAA,&zwsp;XLAAAA,ZZAAAA}
</programlisting>

   Checking the MCV list, we find that the condition <literal>stringu1 &lt;
   'IAAAAA'</literal> is satisfied by the first six entries and not the last four,
   so the selectivity within the MCV part of the population is

<programlisting>
selectivity = sum(relevant mvfs)
            = 0.00333333 + 0.003 + 0.003 + 0.003 + 0.003 + 0.003
            = 0.01833333
</programlisting>

   Summing all the MCFs also tells us that the total fraction of the
   population represented by MCVs is 0.03033333, and therefore the
   fraction represented by the histogram is 0.96966667 (again, there
   are no nulls, else we'd have to exclude them here).  We can see
   that the value <literal>IAAAAA</literal> falls nearly at the end of the
   third histogram bucket.  Using some rather cheesy assumptions
   about the frequency of different characters, the planner arrives
   at the estimate 0.298387 for the portion of the histogram population
   that is less than <literal>IAAAAA</literal>.  We then combine the estimates
   for the MCV and non-MCV populations:

<programlisting>
selectivity = mcv_selectivity + histogram_selectivity * histogram_fraction
            = 0.01833333 + 0.298387 * 0.96966667
            = 0.307669

rows        = 10000 * 0.307669
            = 3077  (rounding off)
</programlisting>

   In this particular example, the correction from the MCV list is fairly
   small, because the column distribution is actually quite flat (the
   statistics showing these particular values as being more common than
   others are mostly due to sampling error).  In a more typical case where
   some values are significantly more common than others, this complicated
   process gives a useful improvement in accuracy because the selectivity
   for the most common values is found exactly.
  </para>
________________________________________________________-->
  <para>
   之前带有<literal>unique1 &lt; 1000</literal>的例子是<function>scalarltsel</function>实际工作的过度简化。 现在我们已经看过了使用 MCV 的例子，可以增加一些具体细节了。 这个例子到目前为止是正确的，因为<structfield>unique1</structfield>是一个唯一列，它没有 MCV（显然， 没有一个值能比其他值更通用）。对一个非唯一列而言，通常会有直方图和 MCV 列表， 并且<emphasis>直方图不包括由 MCV 表示的那部分列</emphasis>。之所以这样做是因为可以得到更精确的估计。在这种情况下，<function>scalarltsel</function>直接应用条件（如<quote>&lt; 1000</quote>）到 MCV 列表中的每个值，并且把那些条件判断为真的 MCV 的频度加起来。这对表中是 MCV 的那一部分给出了准确的选择度估计。然后以上述同样的方式使用直方图估计表中不是 MCV 的那部分的选择度，并且组合这两个数字来估计总的选择读。例如，考虑：

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE stringu1 &lt; 'IAAAAA';

                         QUERY PLAN
------------------------------------------------------------
 Seq Scan on tenk1  (cost=0.00..483.00 rows=3077 width=244)
   Filter: (stringu1 &lt; 'IAAAAA'::name)
</programlisting>

   我们已看到<structfield>stringu1</structfield>的 MCV 信息，这里是它的直方图：

<programlisting>
SELECT histogram_bounds FROM pg_stats
WHERE tablename='tenk1' AND attname='stringu1';

                                histogram_bounds
-------------------------------------------------------------------&zwsp;-------------
 {AAAAAA,CQAAAA,FRAAAA,IBAAAA,KRAAAA,NFAAAA,PSAAAA,SGAAAA,VAAAAA,&zwsp;XLAAAA,ZZAAAA}
</programlisting>

   检查 MCV 列表，我们发现前 6 项满足条件<literal>stringu1 &lt; 'IAAAAA'</literal>，而最后 4 项不满足， 所以 MCV 部分的选择度是：

<programlisting>
selectivity = sum(relevant mvfs)
            = 0.00333333 + 0.003 + 0.003 + 0.003 + 0.003 + 0.003
            = 0.01833333
</programlisting>

   累加所有的 MCF 也告诉我们由 MCV 表示的群体中的比例是 0.03033333，并且因此由直方图表示的 比例是 0.96966667（同样，没有空值，否则我们在这里必须排除它们）。我们可以看到值<literal>IAAAAA</literal>差不多落在第三个直方图桶的结尾。通过使用一些关于不同字符频率的相当漂亮的假设，规划器对小于<literal>IAAAAA</literal>的直方图群体部分得到估计值 0.298387。我们然后组合 MCV 和非 MCV 群体的估计：

<programlisting>
selectivity = mcv_selectivity + histogram_selectivity * histogram_fraction
            = 0.01833333 + 0.298387 * 0.96966667
            = 0.307669

rows        = 10000 * 0.307669
            = 3077  (rounding off)
</programlisting>

   在这个特别的例子中，来自 MCV 列表的纠正相当小，因为列分布实际上很平坦（统计显示这些特殊值比其它值更常见的原因大部分是由于抽样误差）。 在更典型的情况下某些值显著地比其它的更常见，这种复杂的处理过程有助于提高准确度，因为那些最常见值的选择度可以被准确地找到。
  </para>
<!-- pgdoc-cn_end sig_en=e931bb02e2933a3d7c22b220bcc5b9b8 -->

<!-- pgdoc-cn_start sig_en=23090f50c76b12572ec24a4fc0e8ad3c sig_cn_org=None source=14.1 
  <para>
   Now let's consider a case with more than one
   condition in the <literal>WHERE</literal> clause:

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 1000 AND stringu1 = 'xxx';

                                   QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Bitmap Heap Scan on tenk1  (cost=23.80..396.91 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 1000)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..23.80 rows=1007 width=0)
         Index Cond: (unique1 &lt; 1000)
</programlisting>

   The planner assumes that the two conditions are independent, so that
   the individual selectivities of the clauses can be multiplied together:

<programlisting>
selectivity = selectivity(unique1 &lt; 1000) * selectivity(stringu1 = 'xxx')
            = 0.100697 * 0.0014559
            = 0.0001466

rows        = 10000 * 0.0001466
            = 1  (rounding off)
</programlisting>

   Notice that the number of rows estimated to be returned from the bitmap
   index scan reflects only the condition used with the index; this is
   important since it affects the cost estimate for the subsequent heap
   fetches.
  </para>
________________________________________________________-->
  <para>
   现在考虑一个<literal>WHERE</literal>子句中带有多个条件的情况：

<programlisting>
EXPLAIN SELECT * FROM tenk1 WHERE unique1 &lt; 1000 AND stringu1 = 'xxx';

                                   QUERY PLAN
-------------------------------------------------------------------&zwsp;-------------
 Bitmap Heap Scan on tenk1  (cost=23.80..396.91 rows=1 width=244)
   Recheck Cond: (unique1 &lt; 1000)
   Filter: (stringu1 = 'xxx'::name)
   -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..23.80 rows=1007 width=0)
         Index Cond: (unique1 &lt; 1000)
</programlisting>

   规划器假定这两个条件是独立的，因此子句各自的选择度可以被乘在一起：

<programlisting>
selectivity = selectivity(unique1 &lt; 1000) * selectivity(stringu1 = 'xxx')
            = 0.100697 * 0.0014559
            = 0.0001466

rows        = 10000 * 0.0001466
            = 1  (rounding off)
</programlisting>

   需要注意的是，从位图索引扫描中返回的估计行数只反映和索引一起使用的条件； 这一点很重要，因为它会影响后续取堆元组的代价估计。
  </para>
<!-- pgdoc-cn_end sig_en=23090f50c76b12572ec24a4fc0e8ad3c -->

<!-- pgdoc-cn_start sig_en=130eea42e29cb284b00eb2b671604f93 sig_cn_org=None source=14.1 
  <para>
   Finally we will examine a query that involves a join:

<programlisting>
EXPLAIN SELECT * FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 50 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 Nested Loop  (cost=4.64..456.23 rows=50 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.64..142.17 rows=50 width=244)
         Recheck Cond: (unique1 &lt; 50)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.63 rows=50 width=0)
               Index Cond: (unique1 &lt; 50)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..6.27 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</programlisting>

   The restriction on <structname>tenk1</structname>,
   <literal>unique1 &lt; 50</literal>,
   is evaluated before the nested-loop join.
   This is handled analogously to the previous range example.  This time the
   value 50 falls into the first bucket of the
   <structfield>unique1</structfield> histogram:

<programlisting>
selectivity = (0 + (50 - bucket[1].min)/(bucket[1].max - bucket[1].min))/num_buckets
            = (0 + (50 - 0)/(993 - 0))/10
            = 0.005035

rows        = 10000 * 0.005035
            = 50  (rounding off)
</programlisting>

   The restriction for the join is <literal>t2.unique2 = t1.unique2</literal>.
   The operator is just
   our familiar <literal>=</literal>, however the selectivity function is
   obtained from the <structfield>oprjoin</structfield> column of
   <structname>pg_operator</structname>, and is <function>eqjoinsel</function>.
   <function>eqjoinsel</function> looks up the statistical information for both
   <structname>tenk2</structname> and <structname>tenk1</structname>:

<programlisting>
SELECT tablename, null_frac,n_distinct, most_common_vals FROM pg_stats
WHERE tablename IN ('tenk1', 'tenk2') AND attname='unique2';

tablename  | null_frac | n_distinct | most_common_vals
-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 tenk1     |         0 |         -1 |
 tenk2     |         0 |         -1 |
</programlisting>

   In this case there is no <acronym>MCV</acronym> information for
   <structfield>unique2</structfield> because all the values appear to be
   unique, so we use an algorithm that relies only on the number of
   distinct values for both relations together with their null fractions:

<programlisting>
selectivity = (1 - null_frac1) * (1 - null_frac2) * min(1/num_distinct1, 1/num_distinct2)
            = (1 - 0) * (1 - 0) / max(10000, 10000)
            = 0.0001
</programlisting>

   This is, subtract the null fraction from one for each of the relations,
   and divide by the maximum of the numbers of distinct values.
   The number of rows
   that the join is likely to emit is calculated as the cardinality of the
   Cartesian product of the two inputs, multiplied by the
   selectivity:

<programlisting>
rows = (outer_cardinality * inner_cardinality) * selectivity
     = (50 * 10000) * 0.0001
     = 50
</programlisting>
  </para>
________________________________________________________-->
  <para>
   最后我们将检查一个涉及连接的查询：

<programlisting>
EXPLAIN SELECT * FROM tenk1 t1, tenk2 t2
WHERE t1.unique1 &lt; 50 AND t1.unique2 = t2.unique2;

                                      QUERY PLAN
-------------------------------------------------------------------&zwsp;-------------------
 Nested Loop  (cost=4.64..456.23 rows=50 width=488)
   -&gt;  Bitmap Heap Scan on tenk1 t1  (cost=4.64..142.17 rows=50 width=244)
         Recheck Cond: (unique1 &lt; 50)
         -&gt;  Bitmap Index Scan on tenk1_unique1  (cost=0.00..4.63 rows=50 width=0)
               Index Cond: (unique1 &lt; 50)
   -&gt;  Index Scan using tenk2_unique2 on tenk2 t2  (cost=0.00..6.27 rows=1 width=244)
         Index Cond: (unique2 = t1.unique2)
</programlisting>

   在<structname>tenk1</structname>上的限制<literal>unique1 &lt; 50</literal>在嵌套循环连接之前被计算。它的处理类似之前的那个范围查询例子。但是这次值 50 落在<structfield>unique1</structfield>直方图的第一个桶内：

<programlisting>
selectivity = (0 + (50 - bucket[1].min)/(bucket[1].max - bucket[1].min))/num_buckets
            = (0 + (50 - 0)/(993 - 0))/10
            = 0.005035

rows        = 10000 * 0.005035
            = 50  (rounding off)
</programlisting>

   连接的限制是<literal>t2.unique2 = t1.unique2</literal>。操作符是我们熟悉的<literal>=</literal>，然而选择度函数是从<structname>pg_operator</structname>的<structfield>oprjoin</structfield>列获得的，并且是<function>eqjoinsel</function>。<function>eqjoinsel</function>为<structname>tenk2</structname>和<structname>tenk1</structname>查找统计信息：

<programlisting>
SELECT tablename, null_frac,n_distinct, most_common_vals FROM pg_stats
WHERE tablename IN ('tenk1', 'tenk2') AND attname='unique2';

tablename  | null_frac | n_distinct | most_common_vals
-----------+-----------+------------+------------------
 tenk1     |         0 |         -1 |
 tenk2     |         0 |         -1 |
</programlisting>

   在这种情况中，没有<structfield>unique2</structfield>的<acronym>MCV</acronym>信息，因为所有值看上去都是唯一的，因此我们可以为关系和它们的空值部分使用一个只依赖可区分值数目的算法：

<programlisting>
selectivity = (1 - null_frac1) * (1 - null_frac2) * min(1/num_distinct1, 1/num_distinct2)
            = (1 - 0) * (1 - 0) / max(10000, 10000)
            = 0.0001
</programlisting>

   也就是说，从 1 中减去每个表的空值部分，并且除以可区分值的最大数目。连接可能发出的行数的计算是：嵌套循环里的两个输入值的笛卡尔积的势乘以选择度：

<programlisting>
rows = (outer_cardinality * inner_cardinality) * selectivity
     = (50 * 10000) * 0.0001
     = 50
</programlisting>
  </para>
<!-- pgdoc-cn_end sig_en=130eea42e29cb284b00eb2b671604f93 -->

<!-- pgdoc-cn_start sig_en=8b060cb227ed117af5d25ad024a3219a sig_cn_org=None source=14.1 
  <para>
   Had there been MCV lists for the two columns,
   <function>eqjoinsel</function> would have used direct comparison of the MCV
   lists to determine the join selectivity within the part of the column
   populations represented by the MCVs.  The estimate for the remainder of the
   populations follows the same approach shown here.
  </para>
________________________________________________________-->
  <para>
   这里有两列的 MCV 列表，<function>eqjoinsel</function>将使用 MCV 列表的直接比较来决定在由 MCV 表示的列群体部分中的连接选择度。群体剩下部分的估计遵循这里展示的相同方法。
  </para>
<!-- pgdoc-cn_end sig_en=8b060cb227ed117af5d25ad024a3219a -->

<!-- pgdoc-cn_start sig_en=99d315a0a7968d2f8bae3d36320f6cc1 sig_cn_org=None source=14.1 
  <para>
   Notice that we showed <literal>inner_cardinality</literal> as 10000, that is,
   the unmodified size of <structname>tenk2</structname>.  It might appear from
   inspection of the <command>EXPLAIN</command> output that the estimate of
   join rows comes from 50 * 1, that is, the number of outer rows times
   the estimated number of rows obtained by each inner index scan on
   <structname>tenk2</structname>.  But this is not the case: the join relation size
   is estimated before any particular join plan has been considered.  If
   everything is working well then the two ways of estimating the join
   size will produce about the same answer, but due to round-off error and
   other factors they sometimes diverge significantly.
  </para>
________________________________________________________-->
  <para>
   需要注意的是，我们把<literal>inner_cardinality</literal>显示为 10000，也就是未修改的<structname>tenk2</structname>尺寸。它可能出现于EXPLAIN输出检查，连接行的估计来自 50 * 1，即由 outer 行数乘以由<structname>tenk2</structname>上每个 inner 索引扫描的估计行数。但是这不是那种情况： 连接关系尺寸的估计在任何特定的连接计划被考虑之前进行。如果一切顺利，那么两种方式估计的连接尺寸将产生 大概同样的答案，但是由于舍入误差和其它因素它们有时差别显著。
  </para>
<!-- pgdoc-cn_end sig_en=99d315a0a7968d2f8bae3d36320f6cc1 -->

<!-- pgdoc-cn_start sig_en=a178ddc9e9d06f3884ed5d6fc6b5ae83 sig_cn_org=None source=14.1 
  <para>
   For those interested in further details, estimation of the size of
   a table (before any <literal>WHERE</literal> clauses) is done in
   <filename>src/backend/optimizer/util/plancat.c</filename>. The generic
   logic for clause selectivities is in
   <filename>src/backend/optimizer/path/clausesel.c</filename>.  The
   operator-specific selectivity functions are mostly found
   in <filename>src/backend/utils/adt/selfuncs.c</filename>.
  </para>
________________________________________________________-->
  <para>
   如果对更进一步的细节感兴趣，一个表的尺寸（在任何<literal>WHERE</literal>子句之前）的估计在<filename>src/backend/optimizer/util/plancat.c</filename>中完成。子句选择度的一般逻辑在<filename>src/backend/optimizer/path/clausesel.c</filename>中。操作符相关的选择度函数大部分可以在<filename>src/backend/utils/adt/selfuncs.c</filename>中找到。
  </para>
<!-- pgdoc-cn_end sig_en=a178ddc9e9d06f3884ed5d6fc6b5ae83 -->
 </sect1>

 <sect1 id="multivariate-statistics-examples">
<!-- pgdoc-cn_start sig_en=0f3f553a5004e5f64383d0a881a7cbc2 sig_cn_org=None source=14.1 
  <title>Multivariate Statistics Examples</title>
________________________________________________________-->
  <title>多变量统计例子</title>
<!-- pgdoc-cn_end sig_en=0f3f553a5004e5f64383d0a881a7cbc2 -->

<!-- pgdoc-cn_start sig_en=67ea8b948fbb94683fe0cbb5bceff363 sig_cn_org=None source=14.1 
  <indexterm>
   <primary>row estimation</primary>
   <secondary>multivariate</secondary>
  </indexterm>
________________________________________________________-->
  <indexterm>
   <primary>row estimation</primary>
   <secondary>multivariate</secondary>
  </indexterm>
<!-- pgdoc-cn_end sig_en=67ea8b948fbb94683fe0cbb5bceff363 -->

  <sect2 id="functional-dependencies">
<!-- pgdoc-cn_start sig_en=8577035562647587b6eb3b8a2e43d271 sig_cn_org=None source=14.1 
   <title>Functional Dependencies</title>
________________________________________________________-->
   <title>函数依赖</title>
<!-- pgdoc-cn_end sig_en=8577035562647587b6eb3b8a2e43d271 -->

<!-- pgdoc-cn_start sig_en=75e98a579ab75aaf218ad185084b5799 sig_cn_org=None source=14.1 
   <para>
    Multivariate correlation can be demonstrated with a very simple data set
    &mdash; a table with two columns, both containing the same values:

<programlisting>
CREATE TABLE t (a INT, b INT);
INSERT INTO t SELECT i % 100, i % 100 FROM generate_series(1, 10000) s(i);
ANALYZE t;
</programlisting>

    As explained in <xref linkend="planner-stats"/>, the planner can determine
    cardinality of <structname>t</structname> using the number of pages and
    rows obtained from <structname>pg_class</structname>:

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 't';

 relpages | reltuples
-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-&minus;-&minus;-
       45 |     10000
</programlisting>

    The data distribution is very simple; there are only 100 distinct values
    in each column, uniformly distributed.
   </para>
________________________________________________________-->
   <para>
    多元相关性可以用一个非常简单的数据集来演示 &mdash; 一个有两列的表，它们都包含相同的值：

<programlisting>
CREATE TABLE t (a INT, b INT);
INSERT INTO t SELECT i % 100, i % 100 FROM generate_series(1, 10000) s(i);
ANALYZE t;
</programlisting>

    如<xref linkend="planner-stats"/>所述，规划人员可以使用从
	<structname>pg_class</structname>获取的页面和行数来确定
	<structname>t</structname>的基数：

<programlisting>
SELECT relpages, reltuples FROM pg_class WHERE relname = 't';

 relpages | reltuples
----------+-----------
       45 |     10000
</programlisting>

    他的数据分布非常简单；每列中只有100个不同的值，均匀分布。
   </para>
<!-- pgdoc-cn_end sig_en=75e98a579ab75aaf218ad185084b5799 -->

<!-- pgdoc-cn_start sig_en=245dd4daae6882c69b1ff2765707dd06 sig_cn_org=a0851bbd7df74f4d7de1c395408a3158 source=15.7 
   <para>
    The following example shows the result of estimating a <literal>WHERE</literal>
    condition on the <structfield>a</structfield> column:

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1;
                                 QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..170.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: (a = 1)
   Rows Removed by Filter: 9900
</programlisting>

    The planner examines the condition and determines the selectivity
    of this clause to be 1%.  By comparing this estimate and the actual
    number of rows, we see that the estimate is very accurate
    (in fact exact, as the table is very small).  Changing the
    <literal>WHERE</literal> condition to use the <structfield>b</structfield> column, an
    identical plan is generated.  But observe what happens if we apply the same
    condition on both columns, combining them with <literal>AND</literal>:

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                 QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>

    The planner estimates the selectivity for each condition individually,
    arriving at the same 1% estimates as above.  Then it assumes that the
    conditions are independent, and so it multiplies their selectivities,
    producing a final selectivity estimate of just 0.01%.
    This is a significant underestimate, as the actual number of rows
    matching the conditions (100) is two orders of magnitude higher.
   </para>
________________________________________________________-->
   <para>
    以下示例显示了在<structfield>a</structfield>列上估算<literal>WHERE</literal>条件的结果：

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1;
                                 QUERY PLAN
-------------------------------------------------------------------&zwsp;------------
 Seq Scan on t  (cost=0.00..170.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: (a = 1)
   Rows Removed by Filter: 9900
</programlisting>

    规划器检查条件并确定此子句的选择性为1%。通过比较此估计值和实际行数，我们看到估计非常准确
    （实际上是精确的，因为表非常小）。将<literal>WHERE</literal>条件更改为使用<structfield>b</structfield>列，
    生成相同的计划。但是请注意，如果我们在两列上应用相同条件，将它们与<literal>AND</literal>组合：

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                 QUERY PLAN
-------------------------------------------------------------------&zwsp;----------
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>

    规划器分别估算每个条件的选择性，得出与上述相同的1%估计值。然后假设条件是独立的，因此将它们的选择性相乘，
    产生最终的选择性估计仅为0.01%。
    这是一个显著的低估，因为与条件匹配的实际行数（100）高出两个数量级。
</para>
<!-- pgdoc-cn_end sig_en=245dd4daae6882c69b1ff2765707dd06 -->

<!-- pgdoc-cn_start sig_en=2fad9a70db794d2472bc455e1908a57a sig_cn_org=2469e66e1e4a2e6ddd102bf6ddab3f6d source=15.7 
   <para>
    This problem can be fixed by creating a statistics object that
    directs <command>ANALYZE</command> to calculate functional-dependency
    multivariate statistics on the two columns:

<programlisting>
CREATE STATISTICS stts (dependencies) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                  QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..195.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>
   </para>
________________________________________________________-->
   <para>
    这个问题可以通过创建一个统计对象来解决，该对象指导<command>ANALYZE</command>计算两列上的功能依赖多变量统计信息：

<programlisting>
CREATE STATISTICS stts (dependencies) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                  QUERY PLAN
-------------------------------------------------------------------&zwsp;------------
 Seq Scan on t  (cost=0.00..195.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=2fad9a70db794d2472bc455e1908a57a -->
  </sect2>

  <sect2 id="multivariate-ndistinct-counts">
<!-- pgdoc-cn_start sig_en=5c0fd2d18dad56541934bcd43f413d61 sig_cn_org=None source=14.1 
   <title>Multivariate N-Distinct Counts</title>
________________________________________________________-->
   <title>N 个不同变量的计数</title>
<!-- pgdoc-cn_end sig_en=5c0fd2d18dad56541934bcd43f413d61 -->

<!-- pgdoc-cn_start sig_en=b397663c6b5810b3726247f58e790e7c sig_cn_org=b2331b1ac83590a6dda41eec7ac16283 source=15.7 
   <para>
    A similar problem occurs with estimation of the cardinality of sets of
    multiple columns, such as the number of groups that would be generated by
    a <command>GROUP BY</command> clause.  When <command>GROUP BY</command>
    lists a single column, the n-distinct estimate (which is visible as the
    estimated number of rows returned by the HashAggregate node) is very
    accurate:
<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a;
                                       QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 HashAggregate  (cost=195.00..196.00 rows=100 width=12) (actual rows=100 loops=1)
   Group Key: a
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=4) (actual rows=10000 loops=1)
</programlisting>
    But without multivariate statistics, the estimate for the number of
    groups in a query with two columns in <command>GROUP BY</command>, as
    in the following example, is off by an order of magnitude:
<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a, b;
                                       QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 HashAggregate  (cost=220.00..230.00 rows=1000 width=16) (actual rows=100 loops=1)
   Group Key: a, b
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=8) (actual rows=10000 loops=1)
</programlisting>
    By redefining the statistics object to include n-distinct counts for the
    two columns, the estimate is much improved:
<programlisting>
DROP STATISTICS stts;
CREATE STATISTICS stts (dependencies, ndistinct) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a, b;
                                       QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-
 HashAggregate  (cost=220.00..221.00 rows=100 width=16) (actual rows=100 loops=1)
   Group Key: a, b
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=8) (actual rows=10000 loops=1)
</programlisting>
   </para>
________________________________________________________-->
   <para>
    估计多列集合的基数时也会出现类似的问题，比如通过<command>GROUP BY</command>子句生成的组数。
    当<command>GROUP BY</command>列出单个列时，n-distinct估计值（可通过HashAggregate节点返回的行数估计值查看）非常准确：
<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a;
                                       QUERY PLAN
-------------------------------------------------------------------&zwsp;----------------------
 HashAggregate  (cost=195.00..196.00 rows=100 width=12) (actual rows=100 loops=1)
   Group Key: a
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=4) (actual rows=10000 loops=1)
</programlisting>
    但是在没有多变量统计信息的情况下，对于具有两列的<command>GROUP BY</command>查询中组数的估计，如下例所示，会有一个数量级的偏差：
<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a, b;
                                       QUERY PLAN
-------------------------------------------------------------------&zwsp;-------------------------
 HashAggregate  (cost=220.00..230.00 rows=1000 width=16) (actual rows=100 loops=1)
   Group Key: a, b
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=8) (actual rows=10000 loops=1)
</programlisting>
    通过重新定义统计对象以包括两列的n-distinct计数，估计值得到了很大的改善：
<programlisting>
DROP STATISTICS stts;
CREATE STATISTICS stts (dependencies, ndistinct) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT COUNT(*) FROM t GROUP BY a, b;
                                       QUERY PLAN
-------------------------------------------------------------------&zwsp;-------------------------
 HashAggregate  (cost=220.00..221.00 rows=100 width=16) (actual rows=100 loops=1)
   Group Key: a, b
   -&gt;  Seq Scan on t  (cost=0.00..145.00 rows=10000 width=8) (actual rows=10000 loops=1)
</programlisting>
   </para>
<!-- pgdoc-cn_end sig_en=b397663c6b5810b3726247f58e790e7c -->

  </sect2>

  <sect2 id="mcv-lists">
<!-- pgdoc-cn_start sig_en=ade37cb85036c67119fc010e232024d0 sig_cn_org=None source=14.1 
   <title>MCV Lists</title>
________________________________________________________-->
   <title>MCV 列表</title>
<!-- pgdoc-cn_end sig_en=ade37cb85036c67119fc010e232024d0 -->

<!-- pgdoc-cn_start sig_en=172da4c61fd0afbcb3736696dd5748c5 sig_cn_org=None source=14.1 
   <para>
    As explained in <xref linkend="functional-dependencies"/>, functional
    dependencies are very cheap and efficient type of statistics, but their
    main limitation is their global nature (only tracking dependencies at
    the column level, not between individual column values).
   </para>
________________________________________________________-->
   <para>
    如 <xref linkend="functional-dependencies"/>中所述，函数依赖是非常廉价和高效的统计类型，但它们的主要限制是其全局特性（仅跟踪列级别的依赖项，而不是在单个列值之间）。
   </para>
<!-- pgdoc-cn_end sig_en=172da4c61fd0afbcb3736696dd5748c5 -->

<!-- pgdoc-cn_start sig_en=b864a9069d2d3618b30bd95e01f3e8c8 sig_cn_org=None source=14.1 
   <para>
    This section introduces multivariate variant of <acronym>MCV</acronym>
    (most-common values) lists, a straightforward extension of the per-column
    statistics described in <xref linkend="row-estimation-examples"/>.  These
    statistics address the limitation by storing individual values, but it is
    naturally more expensive, both in terms of building the statistics in
    <command>ANALYZE</command>, storage and planning time.
   </para>
________________________________________________________-->
   <para>
    本节介绍<acronym>MCV</acronym>（最常见值）列表的多变量变体, <xref linkend="row-estimation-examples"/> 中描述的每列统计数据的简单扩展。  
	这些统计数据通过存储单独的值来解决这个限制，但是就构建<command>ANALYZE</command>中的统计数据、存储和规划时间而言，它的成本自然更高。
   </para>
<!-- pgdoc-cn_end sig_en=b864a9069d2d3618b30bd95e01f3e8c8 -->

<!-- pgdoc-cn_start sig_en=3d5cecc1cafbeae8c7e49bc36e868cf4 sig_cn_org=None source=14.1 
   <para>
    Let's look at the query from <xref linkend="functional-dependencies"/>
    again, but this time with a <acronym>MCV</acronym> list created on the
    same set of columns (be sure to drop the functional dependencies, to
    make sure the planner uses the newly created statistics).

<programlisting>
DROP STATISTICS stts;
CREATE STATISTICS stts2 (mcv) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                   QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..195.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>

    The estimate is as accurate as with the functional dependencies, mostly
    thanks to the table being fairly small and having a simple distribution
    with a low number of distinct values. Before looking at the second query,
    which was not handled by functional dependencies particularly well,
    let's inspect the <acronym>MCV</acronym> list a bit.
   </para>
________________________________________________________-->
   <para>
    让我们再看看来自<xref linkend="functional-dependencies"/>的查询，但这次在相同列集上创建了<acronym>MCV</acronym>列表（请确保删除函数依赖，以确保规划器使用新创建的统计数据）。

<programlisting>
DROP STATISTICS stts;
CREATE STATISTICS stts2 (mcv) ON a, b FROM t;
ANALYZE t;
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 1;
                                   QUERY PLAN
-------------------------------------------------------------------&zwsp;------------
 Seq Scan on t  (cost=0.00..195.00 rows=100 width=8) (actual rows=100 loops=1)
   Filter: ((a = 1) AND (b = 1))
   Rows Removed by Filter: 9900
</programlisting>

    The estimate is as accurate as with the functional dependencies, mostly
    thanks to the table being fairly small and having a simple distribution
    with a low number of distinct values. Before looking at the second query,
    which was not handled by functional dependencies particularly well,
    let's inspect the <acronym>MCV</acronym> list a bit.
    估计值与函数依赖一样准确，这主要是由于表相当小而且具有少量不同值的简单分布。
    在查看第二个查询之前，这个函数依赖处理得不是很好，让我们先检查一下<acronym>MCV</acronym>列表。
   </para>
<!-- pgdoc-cn_end sig_en=3d5cecc1cafbeae8c7e49bc36e868cf4 -->

<!-- pgdoc-cn_start sig_en=163f018d266181eeba2df066462e8c5c sig_cn_org=cfc777bb088c42919dbcea770cac737b source=15.7 
   <para>
    Inspecting the <acronym>MCV</acronym> list is possible using
    <function>pg_mcv_list_items</function> set-returning function.

<programlisting>
SELECT m.* FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid),
                pg_mcv_list_items(stxdmcv) m WHERE stxname = 'stts2';
 index |  values  | nulls | frequency | base_frequency
-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;+-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-+-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;
     0 | {0, 0}   | {f,f} |      0.01 |         0.0001
     1 | {1, 1}   | {f,f} |      0.01 |         0.0001
   ...
    49 | {49, 49} | {f,f} |      0.01 |         0.0001
    50 | {50, 50} | {f,f} |      0.01 |         0.0001
   ...
    97 | {97, 97} | {f,f} |      0.01 |         0.0001
    98 | {98, 98} | {f,f} |      0.01 |         0.0001
    99 | {99, 99} | {f,f} |      0.01 |         0.0001
(100 rows)
</programlisting>

    This confirms there are 100 distinct combinations in the two columns, and
    all of them are about equally likely (1% frequency for each one).  The
    base frequency is the frequency computed from per-column statistics, as if
    there were no multi-column statistics. Had there been any null values in
    either of the columns, this would be identified in the
    <structfield>nulls</structfield> column.
   </para>
________________________________________________________-->
   <para>
    检查<acronym>MCV</acronym>列表可以使用<function>pg_mcv_list_items</function>返回集函数。

<programlisting>
SELECT m.* FROM pg_statistic_ext join pg_statistic_ext_data on (oid = stxoid),
                pg_mcv_list_items(stxdmcv) m WHERE stxname = 'stts2';
 index |  values  | nulls | frequency | base_frequency
-------+----------+-------+-----------+----------------
     0 | {0, 0}   | {f,f} |      0.01 |         0.0001
     1 | {1, 1}   | {f,f} |      0.01 |         0.0001
   ...
    49 | {49, 49} | {f,f} |      0.01 |         0.0001
    50 | {50, 50} | {f,f} |      0.01 |         0.0001
   ...
    97 | {97, 97} | {f,f} |      0.01 |         0.0001
    98 | {98, 98} | {f,f} |      0.01 |         0.0001
    99 | {99, 99} | {f,f} |      0.01 |         0.0001
(100 rows)
</programlisting>

    这证实了这两列中有100个不同的组合，而且它们都是大致相等的（每个组合的频率为1%）。基础频率是从每列统计数据计算出的频率，就好像没有多列统计数据一样。如果任一列中有任何空值，这将在<structfield>nulls</structfield>列中标识出来。
</para>
<!-- pgdoc-cn_end sig_en=163f018d266181eeba2df066462e8c5c -->

<!-- pgdoc-cn_start sig_en=9f9a651c487bef44ba13557fe8dfed00 sig_cn_org=None source=14.1 
   <para>
    When estimating the selectivity, the planner applies all the conditions
    on items in the <acronym>MCV</acronym> list, and then sums the frequencies
    of the matching ones. See <function>mcv_clauselist_selectivity</function>
    in <filename>src/backend/statistics/mcv.c</filename> for details.
   </para>
________________________________________________________-->
   <para>
    在估计选择性时，规划器对<acronym>MCV</acronym>列表中的项目应用所有条件，然后对匹配项的频率求和。
    详情请参阅<filename>src/backend/statistics/mcv.c</filename>中的<function>mcv_clauselist_selectivity</function>。
   </para>
<!-- pgdoc-cn_end sig_en=9f9a651c487bef44ba13557fe8dfed00 -->

<!-- pgdoc-cn_start sig_en=606c7e1f8eb11908932c0fd9eb706259 sig_cn_org=None source=14.1 
   <para>
    Compared to functional dependencies, <acronym>MCV</acronym> lists have two
    major advantages. Firstly, the list stores actual values, making it possible
    to decide which combinations are compatible.

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 10;
                                 QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=0 loops=1)
   Filter: ((a = 1) AND (b = 10))
   Rows Removed by Filter: 10000
</programlisting>

    Secondly, <acronym>MCV</acronym> lists handle a wider range of clause types,
    not just equality clauses like functional dependencies. For example,
    consider the following range query for the same table:

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a &lt;= 49 AND b &gt; 49;
                                QUERY PLAN
-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&minus;-&zwsp;-&minus;-&minus;-&minus;-&minus;
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=0 loops=1)
   Filter: ((a &lt;= 49) AND (b &gt; 49))
   Rows Removed by Filter: 10000
</programlisting>

   </para>
________________________________________________________-->
   <para>
    与函数依赖相比，<acronym>MCV</acronym>列表有两大主要优点。
    首先，列表存储实际值，从而可以决定哪些组合是兼容的。

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a = 1 AND b = 10;
                                 QUERY PLAN
-------------------------------------------------------------------&zwsp;--------
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=0 loops=1)
   Filter: ((a = 1) AND (b = 10))
   Rows Removed by Filter: 10000
</programlisting>

    第二，<acronym>MCV</acronym> 列表处理更广泛的子句类型，而不仅仅是类似函数依赖的相等子句。
    例如，请考虑对同一表的以下范围查询：

<programlisting>
EXPLAIN (ANALYZE, TIMING OFF) SELECT * FROM t WHERE a &lt;= 49 AND b &gt; 49;
                                QUERY PLAN
-------------------------------------------------------------------&zwsp;--------
 Seq Scan on t  (cost=0.00..195.00 rows=1 width=8) (actual rows=0 loops=1)
   Filter: ((a &lt;= 49) AND (b &gt; 49))
   Rows Removed by Filter: 10000
</programlisting>

   </para>
<!-- pgdoc-cn_end sig_en=606c7e1f8eb11908932c0fd9eb706259 -->

  </sect2>

 </sect1>

 <sect1 id="planner-stats-security">
<!-- pgdoc-cn_start sig_en=965ac13b6d03cb03417fc6112c8967fe sig_cn_org=None source=14.1 
  <title>Planner Statistics and Security</title>
________________________________________________________-->
  <title>规划器统计和安全</title>
<!-- pgdoc-cn_end sig_en=965ac13b6d03cb03417fc6112c8967fe -->

<!-- pgdoc-cn_start sig_en=c1d58efd8a59a1ec4527e9bdbde6c031 sig_cn_org=None source=14.1 
  <para>
   Access to the table <structname>pg_statistic</structname> is restricted to
   superusers, so that ordinary users cannot learn about the contents of the
   tables of other users from it.  Some selectivity estimation functions will
   use a user-provided operator (either the operator appearing in the query or
   a related operator) to analyze the stored statistics.  For example, in order
   to determine whether a stored most common value is applicable, the
   selectivity estimator will have to run the appropriate <literal>=</literal>
   operator to compare the constant in the query to the stored value.
   Thus the data in <structname>pg_statistic</structname> is potentially
   passed to user-defined operators.  An appropriately crafted operator can
   intentionally leak the passed operands (for example, by logging them
   or writing them to a different table), or accidentally leak them by showing
   their values in error messages, in either case possibly exposing data from
   <structname>pg_statistic</structname> to a user who should not be able to
   see it.
  </para>
________________________________________________________-->
  <para>
   对表<structname>pg_statistic</structname>的访问仅限于超级用户，
   以便普通用户无法从中了解其他用户的表的内容。
   一些选择性估算函数将使用用户提供的操作符（出现在查询中的操作符或相关操作符）
   来分析所存储的统计。例如，为了确定存储的最常用值是否适用，
   选择性估计器将必须运行适当的<literal>=</literal>
   运算符来将查询中的常量与存储的值进行比较。因此，
   <structname>pg_statistic</structname>中的数据可能会传递给用户定义的运算符。
   适当制作的操作符可以故意泄漏传递的操作数（例如，通过记录它们或将它们写入不同的表），
   或者通过在错误消息中显示它们的值来意外泄漏它们，无论哪种情况都可能暴露
   <structname>pg_statistic</structname>中的数据给一个不应该能够看到它的用户。
  </para>
<!-- pgdoc-cn_end sig_en=c1d58efd8a59a1ec4527e9bdbde6c031 -->

<!-- pgdoc-cn_start sig_en=7c83c43fa57d122f2d9ef6e3c9d75244 sig_cn_org=None source=14.1 
  <para>
   In order to prevent this, the following applies to all built-in selectivity
   estimation functions.  When planning a query, in order to be able to use
   stored statistics, the current user must either
   have <literal>SELECT</literal> privilege on the table or the involved
   columns, or the operator used must be <literal>LEAKPROOF</literal> (more
   accurately, the function that the operator is based on).  If not, then the
   selectivity estimator will behave as if no statistics are available, and
   the planner will proceed with default or fall-back assumptions.
  </para>
________________________________________________________-->
  <para>
   为了防止这种情况，以下内容适用于所有内置的选择性估计函数。在规划查询时，
   为了能够使用存储的统计信息，当前用户必须在表或相关列上具有
   <literal>SELECT</literal>权限，或者使用的操作符必须是
   <literal>LEAKPROOF</literal>（更准确地说，是操作符所基于的函数）。
   如果不是，那么选择性估计器将表现得好像没有统计数据可用，
   并且规划器将继续进行默认或回退假设。
  </para>
<!-- pgdoc-cn_end sig_en=7c83c43fa57d122f2d9ef6e3c9d75244 -->

<!-- pgdoc-cn_start sig_en=228d9a9d9bcc16ffd1360b726a4335a2 sig_cn_org=None source=14.1 
  <para>
   If a user does not have the required privilege on the table or columns,
   then in many cases the query will ultimately receive a permission-denied
   error, in which case this mechanism is invisible in practice.  But if the
   user is reading from a security-barrier view, then the planner might wish
   to check the statistics of an underlying table that is otherwise
   inaccessible to the user.  In that case, the operator should be leak-proof
   or the statistics will not be used.  There is no direct feedback about
   that, except that the plan might be suboptimal.  If one suspects that this
   is the case, one could try running the query as a more privileged user,
   to see if a different plan results.
  </para>
________________________________________________________-->
  <para>
   如果用户对表或列没有所需的权限，那么在很多情况下，查询最终会收到权限被拒绝的错误，
   在这种情况下，这种机制在实践中是不可见的。但是，如果用户正在从安全屏障视图读取数据，
   则规划器可能希望检查用户无法访问的基础表的统计数据。在这种情况下，
   操作符应该是防漏的，否则统计数据将不会被使用。没有直接的反馈意见，
   除非计划可能是次优的。如果有人怀疑是这种情况，
   可以尝试将查询作为更有特权的用户来运行，以查看是否产生了不同的计划。
  </para>
<!-- pgdoc-cn_end sig_en=228d9a9d9bcc16ffd1360b726a4335a2 -->

<!-- pgdoc-cn_start sig_en=3eba7ebbaa1053b7f96b095f6933ce86 sig_cn_org=None source=14.1 
  <para>
   This restriction applies only to cases where the planner would need to
   execute a user-defined operator on one or more values
   from <structname>pg_statistic</structname>.  Thus the planner is permitted
   to use generic statistical information, such as the fraction of null values
   or the number of distinct values in a column, regardless of access
   privileges.
  </para>
________________________________________________________-->
  <para>
   此限制仅适用于规划器需要对<structname>pg_statistic</structname>
   中的一个或多个值执行用户定义的运算符的情况。因此，无论访问权限如何，
   规划器都可以使用通用的统计信息，例如列中空值的比例或列中不同值的数量。
  </para>
<!-- pgdoc-cn_end sig_en=3eba7ebbaa1053b7f96b095f6933ce86 -->

<!-- pgdoc-cn_start sig_en=ac7bb3c936e5058a6398ee106084f544 sig_cn_org=None source=14.1 
  <para>
   Selectivity estimation functions contained in third-party extensions that
   potentially operate on statistics with user-defined operators should follow
   the same security rules.  Consult the PostgreSQL source code for guidance.
  </para>
________________________________________________________-->
  <para>
   可能对用户定义的操作符进行统计操作的第三方扩展中包含的选择性估计函数，
   应遵循相同的安全规则。请参考PostgreSQL源代码获取指导。
  </para>
<!-- pgdoc-cn_end sig_en=ac7bb3c936e5058a6398ee106084f544 -->
 </sect1>
</chapter>
